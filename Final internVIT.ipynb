{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee77ae8-6fb5-45b1-bbc5-ad1f4fcbcf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting constants\n",
      "  Downloading constants-2023.2.0.tar.gz (5.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting flash_attn\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m702.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting decord\n",
      "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m827.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.4.0)\n",
      "Collecting tox (from constants)\n",
      "  Downloading tox-4.18.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "INFO: pip is looking at multiple versions of constants to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting constants\n",
      "  Downloading constants-0.6.0.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.1.0+cu118)\n",
      "Collecting einops (from flash_attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash_attn) (1.3.0)\n",
      "Downloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: constants, flash_attn\n",
      "  Building wheel for constants (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for constants: filename=constants-0.6.0-py3-none-any.whl size=5457 sha256=a191aff659ef5923187995403c46502619945e642cb0eacb5c4f6ae4217c52a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/96/3c/386c2342a8a1bdd317f2f250bd076c13938c6f598c4a40ec14\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=188977699 sha256=d16f6008f2b7727718653bfd087a20f3e18e2a4c8e91b9f38da2439f3b0bf529\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
      "Successfully built constants flash_attn\n",
      "Installing collected packages: pytz, constants, tzdata, tqdm, kiwisolver, imageio, fsspec, fonttools, einops, decord, cycler, contourpy, pandas, matplotlib, huggingface_hub, flash_attn\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed constants-0.6.0 contourpy-1.3.0 cycler-0.12.1 decord-0.6.0 einops-0.8.0 flash_attn-2.6.3 fonttools-4.53.1 fsspec-2024.9.0 huggingface_hub-0.24.7 imageio-2.35.1 kiwisolver-1.4.7 matplotlib-3.9.2 pandas-2.2.2 pytz-2024.2 tqdm-4.66.5 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U huggingface_hub constants pandas matplotlib flash_attn imageio decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8eedb6f-be07-497a-b8d2-5493fe6f2677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 26 files:   0%|                                 | 0/26 [00:00<?, ?it/s]Downloading 'README.md' to 'InternVL2-8B/.cache/huggingface/download/README.md.0cce1c1628271be22543fb971765a8fa31b4b7bb.incomplete'\n",
      "Downloading 'added_tokens.json' to 'InternVL2-8B/.cache/huggingface/download/added_tokens.json.35f5893c8e29d6102945a953529819a2d56c62a9.incomplete'\n",
      "Downloading 'config.json' to 'InternVL2-8B/.cache/huggingface/download/config.json.2e9a7c19dc3d65029a8bab70b6cf998e552a94dd.incomplete'\n",
      "Downloading 'configuration_internvl_chat.py' to 'InternVL2-8B/.cache/huggingface/download/configuration_internvl_chat.py.b5a518b7883535e2038fcd2d2fdd32f3c14da5ee.incomplete'\n",
      "Downloading 'conversation.py' to 'InternVL2-8B/.cache/huggingface/download/conversation.py.2fe37ad08c18c49fd5a4d7e0aa9be10fbeead22c.incomplete'\n",
      "\n",
      "README.md:   0%|                                    | 0.00/53.2k [00:00<?, ?B/s]\u001b[ADownloading 'configuration_internlm2.py' to 'InternVL2-8B/.cache/huggingface/download/configuration_internlm2.py.282b13b1e2066ecc074ecae87b35a19d251f0ed7.incomplete'\n",
      "README.md: 100%|███████████████████████████| 53.2k/53.2k [00:00<00:00, 17.1MB/s]\n",
      "Downloading 'configuration_intern_vit.py' to 'InternVL2-8B/.cache/huggingface/download/configuration_intern_vit.py.ac60112c79abc35627a5b6b58e760c2f78e71839.incomplete'\n",
      "Download complete. Moving file to InternVL2-8B/README.md\n",
      "\n",
      "Downloading '.gitattributes' to 'InternVL2-8B/.cache/huggingface/download/.gitattributes.3ecf72ff46e87246d8fc73fcaf99995ea09063b2.incomplete'\n",
      "added_tokens.json: 100%|████████████████████████| 179/179 [00:00<00:00, 866kB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/added_tokens.json\n",
      "\n",
      "config.json: 100%|█████████████████████████| 3.95k/3.95k [00:00<00:00, 20.1MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/config.json\n",
      "\n",
      "conversation.py: 100%|█████████████████████| 15.0k/15.0k [00:00<00:00, 49.6MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/conversation.py\n",
      "\n",
      "configuration_internvl_chat.py: 100%|██████| 3.85k/3.85k [00:00<00:00, 30.5MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/configuration_internvl_chat.py\n",
      "\n",
      "configuration_intern_vit.py: 100%|█████████| 5.55k/5.55k [00:00<00:00, 32.9MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/configuration_intern_vit.py\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.58k/1.58k [00:00<00:00, 12.7MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/.gitattributes\n",
      "Fetching 26 files:   4%|▉                        | 1/26 [00:01<00:34,  1.40s/it]Downloading 'examples/image1.jpg' to 'InternVL2-8B/.cache/huggingface/download/examples/image1.jpg.fd9891ef7e00774157a9dcd726b2ea9fa0c5ecff.incomplete'\n",
      "Downloading 'examples/image2.jpg' to 'InternVL2-8B/.cache/huggingface/download/examples/image2.jpg.25948c75fc4424e29de99aabea4709eb29ff1eb9.incomplete'\n",
      "Downloading 'examples/red-panda.mp4' to 'InternVL2-8B/.cache/huggingface/download/examples/red-panda.mp4.d921c07bb97224d65a37801541d246067f0d506f08723ffa1ad85c217907ccb8.incomplete'\n",
      "Downloading 'generation_config.json' to 'InternVL2-8B/.cache/huggingface/download/generation_config.json.d45dc4fdf649b1096e6d30f54fa59c1366ddecfb.incomplete'\n",
      "Downloading 'model-00001-of-00004.safetensors' to 'InternVL2-8B/.cache/huggingface/download/model-00001-of-00004.safetensors.3a18c6c843dd1c046a7052129ac7ff5d3fa38e95149ea6ee763066dc1cc6579c.incomplete'\n",
      "\n",
      "configuration_internlm2.py: 100%|██████████| 7.00k/7.00k [00:00<00:00, 19.1MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/configuration_internlm2.py\n",
      "\n",
      "examples/image2.jpg:   0%|                           | 0.00/126k [00:00<?, ?B/s]\u001b[ADownloading 'model-00003-of-00004.safetensors' to 'InternVL2-8B/.cache/huggingface/download/model-00003-of-00004.safetensors.9d31a1bd34e26858251c02741d450f64937b59bf3e45a2efede61a10c2086768.incomplete'\n",
      "\n",
      "\n",
      "examples/image1.jpg: 100%|██████████████████| 78.1k/78.1k [00:00<00:00, 162MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/examples/image1.jpg\n",
      "examples/image2.jpg: 100%|███████████████████| 126k/126k [00:00<00:00, 10.4MB/s]\n",
      "Download complete. Moving file to InternVL2-8B/examples/image2.jpg\n",
      "\n",
      "generation_config.json: 100%|███████████████████| 115/115 [00:00<00:00, 875kB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/generation_config.json\n",
      "Downloading 'model-00004-of-00004.safetensors' to 'InternVL2-8B/.cache/huggingface/download/model-00004-of-00004.safetensors.5f20c98a99d6fcf5c01b70194b80984ad0b49220f365f7c415af7629743a5397.incomplete'\n",
      "Downloading 'model-00002-of-00004.safetensors' to 'InternVL2-8B/.cache/huggingface/download/model-00002-of-00004.safetensors.e1967d2442fe5a38aba96e7ad7a18459962171591e5b7438aa0efa15db93b375.incomplete'\n",
      "Downloading 'modeling_intern_vit.py' to 'InternVL2-8B/.cache/huggingface/download/modeling_intern_vit.py.588c3de46ce4748444ddce4a1bb72cb8de74996f.incomplete'\n",
      "Downloading 'modeling_internlm2.py' to 'InternVL2-8B/.cache/huggingface/download/modeling_internlm2.py.7c8c24d873f6ecd152d00fd65371e23ead981e1d.incomplete'\n",
      "Downloading 'model.safetensors.index.json' to 'InternVL2-8B/.cache/huggingface/download/model.safetensors.index.json.8b024ee06fb58c2607a1c54a04b8ee0749d14f2c.incomplete'\n",
      "\n",
      "modeling_intern_vit.py: 100%|██████████████| 18.1k/18.1k [00:00<00:00, 59.3MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/modeling_intern_vit.py\n",
      "\n",
      "modeling_internlm2.py: 100%|████████████████| 61.2k/61.2k [00:00<00:00, 128MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/modeling_internlm2.py\n",
      "\n",
      "model.safetensors.index.json: 100%|█████████| 51.2k/51.2k [00:00<00:00, 125MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/model.safetensors.index.json\n",
      "Downloading 'modeling_internvl_chat.py' to 'InternVL2-8B/.cache/huggingface/download/modeling_internvl_chat.py.1147bb38202f9d2e41926904caa0b0eadb39d05d.incomplete'\n",
      "Downloading 'preprocessor_config.json' to 'InternVL2-8B/.cache/huggingface/download/preprocessor_config.json.dfd7e50d9d4e67cd679b16b337b419a0c6cfa849.incomplete'\n",
      "Downloading 'special_tokens_map.json' to 'InternVL2-8B/.cache/huggingface/download/special_tokens_map.json.cbf34a50d27c43ed8d1e2823b800b4e6f66e637a.incomplete'\n",
      "\n",
      "preprocessor_config.json: 100%|████████████████| 287/287 [00:00<00:00, 1.75MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/preprocessor_config.json\n",
      "\n",
      "modeling_internvl_chat.py: 100%|███████████| 15.6k/15.6k [00:00<00:00, 48.2MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/modeling_internvl_chat.py\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 844/844 [00:00<00:00, 5.21MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/special_tokens_map.json\n",
      "Downloading 'tokenization_internlm2.py' to 'InternVL2-8B/.cache/huggingface/download/tokenization_internlm2.py.1be581da37ef678de65f2737493fc0ed7160446e.incomplete'\n",
      "Downloading 'tokenization_internlm2_fast.py' to 'InternVL2-8B/.cache/huggingface/download/tokenization_internlm2_fast.py.aa0fccbd0f1d029d79e19821f2edcb01b594537c.incomplete'\n",
      "\n",
      "tokenization_internlm2.py: 100%|███████████| 8.79k/8.79k [00:00<00:00, 32.1MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/tokenization_internlm2.py\n",
      "\n",
      "tokenization_internlm2_fast.py: 100%|██████| 7.79k/7.79k [00:00<00:00, 36.7MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/tokenization_internlm2_fast.py\n",
      "Downloading 'tokenizer_config.json' to 'InternVL2-8B/.cache/huggingface/download/tokenizer_config.json.1f32946df0f56d92ddbc1df79cabb4477b622480.incomplete'\n",
      "Downloading 'tokenizer.model' to 'InternVL2-8B/.cache/huggingface/download/tokenizer.model.f868398fc4e05ee1e8aeba95ddf18ddcc45b8bce55d5093bead5bbf80429b48b.incomplete'\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████| 4.00k/4.00k [00:00<00:00, 33.1MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/tokenizer_config.json\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.94G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "red-panda.mp4: 100%|████████████████████████| 1.87M/1.87M [00:00<00:00, 120MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/examples/red-panda.mp4\n",
      "Fetching 26 files:  42%|██████████▏             | 11/26 [00:02<00:02,  5.92it/s]\n",
      "model-00001-of-00004.safetensors:   1%|     | 41.9M/4.94G [00:00<00:11, 411MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|     | 83.9M/4.94G [00:00<00:15, 317MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|     | 31.5M/4.92G [00:00<00:21, 225MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model:   0%|                              | 0.00/1.48M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.model: 100%|█████████████████████| 1.48M/1.48M [00:00<00:00, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/tokenizer.model\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   0%|     | 21.0M/4.92G [00:00<00:26, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|     | 62.9M/4.92G [00:00<00:21, 226MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   1%|     | 52.4M/4.92G [00:00<00:19, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   1%|    | 10.5M/1.38G [00:00<00:27, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 126M/4.94G [00:00<00:19, 242MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   2%|     | 94.4M/4.92G [00:00<00:21, 229MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   2%|    | 21.0M/1.38G [00:00<00:19, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   2%|     | 83.9M/4.92G [00:00<00:22, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 126M/4.92G [00:00<00:20, 231MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 157M/4.94G [00:00<00:25, 189MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   3%|    | 41.9M/1.38G [00:00<00:14, 92.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   2%|▏     | 115M/4.92G [00:00<00:25, 187MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 157M/4.92G [00:00<00:20, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 136M/4.92G [00:00<00:25, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   5%|▏    | 62.9M/1.38G [00:00<00:12, 109MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▏     | 189M/4.92G [00:00<00:20, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 157M/4.92G [00:00<00:25, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 189M/4.94G [00:01<00:32, 146MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▎     | 220M/4.92G [00:00<00:20, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   6%|▎    | 83.9M/1.38G [00:00<00:10, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   4%|▏     | 178M/4.92G [00:00<00:26, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 252M/4.92G [00:01<00:20, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   8%|▍     | 105M/1.38G [00:00<00:09, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   4%|▏     | 199M/4.92G [00:01<00:27, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎     | 210M/4.94G [00:01<00:37, 127MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 283M/4.92G [00:01<00:19, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 126M/1.38G [00:01<00:09, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   4%|▎     | 220M/4.92G [00:01<00:27, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▍     | 315M/4.92G [00:01<00:19, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  11%|▋     | 147M/1.38G [00:01<00:08, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 231M/4.94G [00:01<00:40, 115MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 241M/4.92G [00:01<00:29, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 346M/4.92G [00:01<00:19, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  12%|▋     | 168M/1.38G [00:01<00:08, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 252M/4.94G [00:01<00:42, 111MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 262M/4.92G [00:01<00:31, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 377M/4.92G [00:01<00:19, 238MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  14%|▊     | 189M/1.38G [00:01<00:09, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   6%|▎     | 283M/4.92G [00:01<00:30, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 409M/4.92G [00:01<00:19, 237MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎     | 273M/4.94G [00:01<00:40, 116MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   6%|▎     | 304M/4.92G [00:01<00:28, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 440M/4.92G [00:01<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  15%|▉     | 210M/1.38G [00:01<00:09, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎     | 294M/4.94G [00:02<00:39, 117MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 336M/4.92G [00:01<00:25, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  17%|█     | 231M/1.38G [00:01<00:09, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▍     | 315M/4.94G [00:02<00:39, 118MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 367M/4.92G [00:02<00:23, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 503M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  18%|█     | 252M/1.38G [00:02<00:09, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   8%|▍     | 388M/4.92G [00:02<00:24, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 535M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 336M/4.94G [00:02<00:40, 114MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   8%|▍     | 409M/4.92G [00:02<00:25, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  20%|█▏    | 273M/1.38G [00:02<00:08, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 566M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 430M/4.92G [00:02<00:25, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 357M/4.94G [00:02<00:42, 107MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  21%|█▎    | 294M/1.38G [00:02<00:08, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 598M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 451M/4.92G [00:02<00:26, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 629M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  23%|█▎    | 315M/1.38G [00:02<00:08, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 377M/4.94G [00:02<00:43, 105MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:02<00:26, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 661M/4.92G [00:02<00:18, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  24%|█▍    | 336M/1.38G [00:02<00:08, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 493M/4.92G [00:02<00:27, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 398M/4.94G [00:03<00:42, 108MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  14%|▊     | 692M/4.92G [00:02<00:17, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  10%|▋     | 514M/4.92G [00:02<00:26, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  26%|█▌    | 357M/1.38G [00:02<00:08, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 724M/4.92G [00:03<00:17, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▌     | 419M/4.94G [00:03<00:41, 109MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  11%|▋     | 545M/4.92G [00:03<00:21, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  27%|█▋    | 377M/1.38G [00:03<00:07, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 755M/4.92G [00:03<00:17, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 566M/4.92G [00:03<00:24, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 440M/4.94G [00:03<00:42, 107MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 786M/4.92G [00:03<00:17, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  29%|█▋    | 398M/1.38G [00:03<00:07, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 587M/4.92G [00:03<00:25, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|▉     | 818M/4.92G [00:03<00:17, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 461M/4.94G [00:03<00:42, 105MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  30%|█▊    | 419M/1.38G [00:03<00:07, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 608M/4.92G [00:03<00:26, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|█     | 849M/4.92G [00:03<00:17, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  32%|█▉    | 440M/1.38G [00:03<00:07, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 629M/4.92G [00:03<00:27, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 482M/4.94G [00:03<00:42, 104MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█     | 881M/4.92G [00:03<00:17, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 650M/4.92G [00:03<00:25, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  33%|██    | 461M/1.38G [00:03<00:06, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 493M/4.94G [00:03<00:43, 102MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|█     | 912M/4.92G [00:03<00:17, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 671M/4.92G [00:03<00:26, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  35%|██    | 482M/1.38G [00:03<00:06, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|█▏    | 944M/4.92G [00:04<00:16, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 514M/4.94G [00:04<00:42, 103MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 692M/4.92G [00:04<00:27, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 524M/4.94G [00:04<00:42, 103MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  36%|██▏   | 503M/1.38G [00:03<00:06, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 975M/4.92G [00:04<00:16, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  15%|▊     | 713M/4.92G [00:04<00:28, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|█    | 1.01G/4.92G [00:04<00:16, 238MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 545M/4.94G [00:04<00:39, 110MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  38%|██▎   | 524M/1.38G [00:04<00:07, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  21%|█    | 1.04G/4.92G [00:04<00:16, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 734M/4.92G [00:04<00:29, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 566M/4.94G [00:04<00:39, 112MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  40%|██▎   | 545M/1.38G [00:04<00:06, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.07G/4.92G [00:04<00:16, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 755M/4.92G [00:04<00:29, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  41%|██▍   | 566M/1.38G [00:04<00:06, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.10G/4.92G [00:04<00:16, 237MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 587M/4.94G [00:04<00:40, 107MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 776M/4.92G [00:04<00:29, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  43%|██▌   | 587M/1.38G [00:04<00:06, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.13G/4.92G [00:04<00:16, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 608M/4.94G [00:05<00:41, 104MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 797M/4.92G [00:04<00:31, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 1.16G/4.92G [00:04<00:16, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  44%|██▋   | 608M/1.38G [00:04<00:05, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 619M/4.94G [00:05<00:41, 104MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  17%|▉     | 818M/4.92G [00:04<00:31, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 1.20G/4.92G [00:05<00:15, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  46%|██▋   | 629M/1.38G [00:04<00:05, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 640M/4.94G [00:05<00:41, 103MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  25%|█▏   | 1.23G/4.92G [00:05<00:15, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  17%|█     | 839M/4.92G [00:05<00:32, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  47%|██▊   | 650M/1.38G [00:05<00:05, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 650M/4.94G [00:05<00:42, 102MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.26G/4.92G [00:05<00:15, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  49%|██▉   | 671M/1.38G [00:05<00:05, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  17%|█     | 860M/4.92G [00:05<00:32, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 661M/4.94G [00:05<00:42, 100MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.29G/4.92G [00:05<00:15, 233MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 671M/4.94G [00:05<00:42, 99.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  50%|███   | 692M/1.38G [00:05<00:04, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  18%|█     | 881M/4.92G [00:05<00:34, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.32G/4.92G [00:05<00:15, 233MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 682M/4.94G [00:05<00:44, 95.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  52%|███   | 713M/1.38G [00:05<00:04, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.35G/4.92G [00:05<00:15, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  18%|█     | 902M/4.92G [00:05<00:32, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 692M/4.94G [00:05<00:46, 91.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  53%|███▏  | 734M/1.38G [00:05<00:04, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.38G/4.92G [00:05<00:15, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 703M/4.94G [00:06<00:46, 90.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 923M/4.92G [00:05<00:34, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  55%|███▎  | 755M/1.38G [00:05<00:04, 145MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 713M/4.94G [00:06<00:46, 90.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.42G/4.92G [00:06<00:15, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  56%|███▍  | 776M/1.38G [00:05<00:04, 146MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▋    | 724M/4.94G [00:06<00:46, 91.3MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.45G/4.92G [00:06<00:14, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 944M/4.92G [00:06<00:36, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▋    | 734M/4.94G [00:06<00:46, 91.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  58%|███▍  | 797M/1.38G [00:06<00:03, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  30%|█▌   | 1.48G/4.92G [00:06<00:15, 228MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▊    | 744M/4.94G [00:06<00:45, 92.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 965M/4.92G [00:06<00:35, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  59%|███▌  | 818M/1.38G [00:06<00:03, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.51G/4.92G [00:06<00:14, 228MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▊    | 755M/4.94G [00:06<00:45, 91.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 986M/4.92G [00:06<00:32, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  61%|███▋  | 839M/1.38G [00:06<00:03, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.54G/4.92G [00:06<00:14, 229MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▊    | 765M/4.94G [00:06<00:45, 90.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  20%|█    | 1.01G/4.92G [00:06<00:30, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  62%|███▋  | 860M/1.38G [00:06<00:03, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.57G/4.92G [00:06<00:14, 230MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▊    | 786M/4.94G [00:06<00:42, 97.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.03G/4.92G [00:06<00:31, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  64%|███▊  | 881M/1.38G [00:06<00:03, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.60G/4.92G [00:06<00:14, 227MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▊    | 797M/4.94G [00:07<00:41, 99.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.64G/4.92G [00:07<00:14, 228MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  65%|███▉  | 902M/1.38G [00:06<00:03, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.05G/4.92G [00:06<00:32, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|▉     | 818M/4.94G [00:07<00:39, 103MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.67G/4.92G [00:07<00:14, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  67%|████  | 923M/1.38G [00:07<00:03, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.07G/4.92G [00:07<00:31, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  35%|█▋   | 1.70G/4.92G [00:07<00:13, 231MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█     | 839M/4.94G [00:07<00:38, 107MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.09G/4.92G [00:07<00:29, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█     | 860M/4.94G [00:07<00:33, 122MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  35%|█▊   | 1.73G/4.92G [00:07<00:13, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.11G/4.92G [00:07<00:26, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  68%|████  | 944M/1.38G [00:07<00:03, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 881M/4.94G [00:07<00:30, 131MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.76G/4.92G [00:07<00:13, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.15G/4.92G [00:07<00:19, 195MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  70%|████▏ | 965M/1.38G [00:07<00:03, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.79G/4.92G [00:07<00:13, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.18G/4.92G [00:07<00:17, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 902M/4.94G [00:07<00:31, 127MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  71%|████▎ | 986M/1.38G [00:07<00:03, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.82G/4.92G [00:07<00:13, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  25%|█▏   | 1.22G/4.92G [00:07<00:17, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█     | 923M/4.94G [00:08<00:33, 121MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.86G/4.92G [00:07<00:13, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  25%|█▎   | 1.25G/4.92G [00:07<00:16, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  73%|███▋ | 1.01G/1.38G [00:07<00:03, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.89G/4.92G [00:08<00:12, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.30G/4.92G [00:08<00:13, 277MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▏    | 944M/4.94G [00:08<00:35, 113MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  75%|███▋ | 1.03G/1.38G [00:07<00:02, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.35G/4.92G [00:08<00:11, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.92G/4.92G [00:08<00:12, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  76%|███▊ | 1.05G/1.38G [00:08<00:02, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.39G/4.92G [00:08<00:10, 344MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▏    | 965M/4.94G [00:08<00:37, 106MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  40%|█▉   | 1.95G/4.92G [00:08<00:12, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  78%|███▉ | 1.07G/1.38G [00:08<00:02, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.44G/4.92G [00:08<00:09, 353MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  40%|██   | 1.98G/4.92G [00:08<00:12, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  79%|███▉ | 1.09G/1.38G [00:08<00:02, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  30%|█▌   | 1.48G/4.92G [00:08<00:10, 339MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|▉    | 986M/4.94G [00:08<00:40, 98.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|██   | 2.01G/4.92G [00:08<00:12, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.52G/4.92G [00:08<00:10, 335MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  81%|████ | 1.11G/1.38G [00:08<00:01, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.04G/4.92G [00:08<00:12, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█    | 1.01G/4.94G [00:08<00:38, 101MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.56G/4.92G [00:08<00:09, 348MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  82%|████ | 1.13G/1.38G [00:08<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.08G/4.92G [00:08<00:12, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.60G/4.92G [00:08<00:09, 342MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.03G/4.94G [00:09<00:38, 103MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.11G/4.92G [00:09<00:12, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.65G/4.92G [00:08<00:09, 352MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  84%|████▏| 1.15G/1.38G [00:08<00:01, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.69G/4.92G [00:09<00:09, 356MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.14G/4.92G [00:09<00:11, 233MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.05G/4.94G [00:09<00:37, 104MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  85%|████▎| 1.17G/1.38G [00:09<00:01, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  35%|█▊   | 1.73G/4.92G [00:09<00:08, 360MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.17G/4.92G [00:09<00:11, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.07G/4.94G [00:09<00:36, 107MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.77G/4.92G [00:09<00:08, 369MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  87%|████▎| 1.20G/1.38G [00:09<00:01, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|██▏  | 2.20G/4.92G [00:09<00:11, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  37%|█▊   | 1.81G/4.92G [00:09<00:08, 357MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  88%|████▍| 1.22G/1.38G [00:09<00:01, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|██▎  | 2.23G/4.92G [00:09<00:11, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.09G/4.94G [00:09<00:37, 102MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.86G/4.92G [00:09<00:08, 343MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  90%|████▍| 1.24G/1.38G [00:09<00:01, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.26G/4.92G [00:09<00:11, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.10G/4.94G [00:09<00:38, 100MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.90G/4.92G [00:09<00:09, 332MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.11G/4.94G [00:09<00:38, 99.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  91%|████▌| 1.26G/1.38G [00:09<00:00, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.30G/4.92G [00:09<00:11, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.94G/4.92G [00:09<00:08, 342MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.33G/4.92G [00:09<00:10, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  93%|████▋| 1.28G/1.38G [00:09<00:00, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  40%|██   | 1.98G/4.92G [00:09<00:08, 336MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.36G/4.92G [00:10<00:10, 240MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  95%|████▊| 1.31G/1.38G [00:09<00:00, 157MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.02G/4.92G [00:10<00:08, 327MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.13G/4.94G [00:10<00:49, 76.7MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.39G/4.92G [00:10<00:10, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  97%|████▊| 1.33G/1.38G [00:10<00:00, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.07G/4.92G [00:10<00:08, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors:  98%|████▉| 1.35G/1.38G [00:10<00:00, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.42G/4.92G [00:10<00:10, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.14G/4.94G [00:10<00:52, 71.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.11G/4.92G [00:10<00:08, 316MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00004-of-00004.safetensors: 100%|████▉| 1.37G/1.38G [00:10<00:00, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors: 100%|█████| 1.38G/1.38G [00:10<00:00, 133MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/model-00004-of-00004.safetensors\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|▉   | 1.15G/4.94G [00:10<00:51, 73.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.15G/4.92G [00:10<00:08, 308MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|▉   | 1.17G/4.94G [00:10<00:39, 96.3MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.49G/4.92G [00:10<00:10, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  45%|██▏  | 2.19G/4.92G [00:10<00:08, 313MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.21G/4.94G [00:10<00:28, 132MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.52G/4.92G [00:10<00:10, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  45%|██▎  | 2.23G/4.92G [00:10<00:08, 313MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▎   | 1.24G/4.94G [00:11<00:23, 159MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.55G/4.92G [00:10<00:10, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.28G/4.92G [00:10<00:08, 313MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.27G/4.94G [00:11<00:20, 180MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.58G/4.92G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.32G/4.92G [00:11<00:08, 312MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.61G/4.92G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.30G/4.94G [00:11<00:18, 194MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.36G/4.92G [00:11<00:07, 325MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.64G/4.92G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.33G/4.94G [00:11<00:17, 205MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.40G/4.92G [00:11<00:07, 319MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.67G/4.92G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.36G/4.94G [00:11<00:16, 213MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  50%|██▍  | 2.44G/4.92G [00:11<00:07, 327MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  55%|██▊  | 2.71G/4.92G [00:11<00:09, 236MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.39G/4.94G [00:11<00:16, 220MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.49G/4.92G [00:11<00:07, 325MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.74G/4.92G [00:11<00:09, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▍   | 1.43G/4.94G [00:11<00:15, 225MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.53G/4.92G [00:11<00:07, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.77G/4.92G [00:11<00:09, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▍   | 1.46G/4.94G [00:11<00:15, 229MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 2.57G/4.92G [00:11<00:07, 334MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▌   | 1.49G/4.94G [00:12<00:14, 231MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.80G/4.92G [00:11<00:09, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.61G/4.92G [00:11<00:06, 331MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.52G/4.94G [00:12<00:14, 233MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.83G/4.92G [00:12<00:08, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.65G/4.92G [00:12<00:06, 323MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.55G/4.94G [00:12<00:14, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.69G/4.92G [00:12<00:06, 337MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.86G/4.92G [00:12<00:08, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.74G/4.92G [00:12<00:06, 337MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.58G/4.94G [00:12<00:14, 237MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.89G/4.92G [00:12<00:08, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.78G/4.92G [00:12<00:06, 328MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.61G/4.94G [00:12<00:14, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  60%|██▉  | 2.93G/4.92G [00:12<00:08, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.82G/4.92G [00:12<00:06, 333MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.65G/4.94G [00:12<00:13, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  60%|███  | 2.96G/4.92G [00:12<00:08, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.86G/4.92G [00:12<00:06, 326MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.68G/4.94G [00:12<00:13, 237MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|███  | 2.99G/4.92G [00:12<00:08, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▋   | 1.71G/4.94G [00:13<00:13, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:12<00:06, 308MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|███  | 3.02G/4.92G [00:12<00:08, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▊   | 1.74G/4.94G [00:13<00:13, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.95G/4.92G [00:12<00:06, 313MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.05G/4.92G [00:13<00:07, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.77G/4.94G [00:13<00:13, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  61%|███  | 2.99G/4.92G [00:13<00:06, 309MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.08G/4.92G [00:13<00:07, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.02G/4.92G [00:13<00:06, 309MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.80G/4.94G [00:13<00:13, 238MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.11G/4.92G [00:13<00:07, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.05G/4.92G [00:13<00:06, 309MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.84G/4.94G [00:13<00:13, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.15G/4.92G [00:13<00:07, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.09G/4.92G [00:13<00:05, 326MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.87G/4.94G [00:13<00:13, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|███▏ | 3.18G/4.92G [00:13<00:07, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.14G/4.92G [00:13<00:05, 326MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.90G/4.94G [00:13<00:12, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|███▎ | 3.21G/4.92G [00:13<00:07, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  65%|███▏ | 3.18G/4.92G [00:13<00:05, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.93G/4.94G [00:13<00:12, 234MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 3.24G/4.92G [00:13<00:07, 239MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  65%|███▎ | 3.22G/4.92G [00:13<00:05, 315MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.27G/4.92G [00:13<00:06, 241MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.96G/4.94G [00:14<00:13, 229MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.26G/4.92G [00:13<00:05, 329MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.30G/4.92G [00:14<00:06, 239MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|██   | 1.99G/4.94G [00:14<00:12, 231MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.30G/4.92G [00:14<00:04, 328MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.33G/4.92G [00:14<00:06, 238MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.02G/4.94G [00:14<00:12, 233MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.34G/4.92G [00:14<00:04, 317MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.37G/4.92G [00:14<00:06, 237MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.06G/4.94G [00:14<00:12, 234MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.39G/4.92G [00:14<00:04, 318MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.09G/4.94G [00:14<00:12, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.40G/4.92G [00:14<00:06, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  70%|███▍ | 3.44G/4.92G [00:14<00:04, 353MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 2.12G/4.94G [00:14<00:11, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  70%|███▍ | 3.43G/4.92G [00:14<00:06, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 3.49G/4.92G [00:14<00:03, 369MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.15G/4.94G [00:14<00:11, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  70%|███▌ | 3.46G/4.92G [00:14<00:06, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.53G/4.92G [00:14<00:03, 346MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.18G/4.94G [00:15<00:11, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.49G/4.92G [00:14<00:06, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.58G/4.92G [00:14<00:04, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|██▏  | 2.21G/4.94G [00:15<00:11, 237MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.52G/4.92G [00:15<00:06, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.62G/4.92G [00:15<00:04, 305MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|██▎  | 2.24G/4.94G [00:15<00:11, 238MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.55G/4.92G [00:15<00:05, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.65G/4.92G [00:15<00:04, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 2.28G/4.94G [00:15<00:11, 239MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.59G/4.92G [00:15<00:05, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  75%|███▋ | 3.68G/4.92G [00:15<00:04, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.31G/4.94G [00:15<00:11, 237MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.62G/4.92G [00:15<00:05, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.71G/4.92G [00:15<00:04, 279MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.34G/4.94G [00:15<00:11, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.74G/4.92G [00:15<00:04, 281MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.65G/4.92G [00:15<00:05, 232MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 2.37G/4.94G [00:15<00:10, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.77G/4.92G [00:15<00:04, 269MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███▋ | 3.68G/4.92G [00:15<00:05, 232MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.40G/4.94G [00:15<00:10, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.81G/4.92G [00:15<00:04, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.71G/4.92G [00:15<00:05, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.84G/4.92G [00:15<00:04, 267MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.43G/4.94G [00:16<00:10, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.74G/4.92G [00:16<00:05, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.87G/4.92G [00:15<00:03, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 2.46G/4.94G [00:16<00:10, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.77G/4.92G [00:16<00:04, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.90G/4.92G [00:16<00:03, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.50G/4.94G [00:16<00:10, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.81G/4.92G [00:16<00:04, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  80%|███▉ | 3.93G/4.92G [00:16<00:03, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.53G/4.94G [00:16<00:10, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.84G/4.92G [00:16<00:04, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  81%|████ | 3.96G/4.92G [00:16<00:03, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.56G/4.94G [00:16<00:10, 237MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.87G/4.92G [00:16<00:04, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.00G/4.92G [00:16<00:03, 272MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.59G/4.94G [00:16<00:09, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.03G/4.92G [00:16<00:03, 273MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.90G/4.92G [00:16<00:04, 232MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|██▋  | 2.62G/4.94G [00:16<00:09, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.06G/4.92G [00:16<00:03, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  80%|███▉ | 3.93G/4.92G [00:16<00:04, 231MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.65G/4.94G [00:17<00:09, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.09G/4.92G [00:16<00:03, 253MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.96G/4.92G [00:16<00:04, 228MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.68G/4.94G [00:17<00:09, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.13G/4.92G [00:16<00:02, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  81%|████ | 4.00G/4.92G [00:17<00:04, 222MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|██▋  | 2.72G/4.94G [00:17<00:09, 237MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  85%|████▏| 4.16G/4.92G [00:17<00:02, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.03G/4.92G [00:17<00:04, 216MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.75G/4.94G [00:17<00:09, 232MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  85%|████▎| 4.19G/4.92G [00:17<00:02, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.06G/4.92G [00:17<00:03, 223MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.78G/4.94G [00:17<00:09, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.23G/4.92G [00:17<00:02, 253MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.09G/4.92G [00:17<00:03, 227MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.26G/4.92G [00:17<00:02, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.81G/4.94G [00:17<00:09, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.12G/4.92G [00:17<00:03, 228MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.29G/4.92G [00:17<00:02, 268MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.84G/4.94G [00:17<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.15G/4.92G [00:17<00:03, 230MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 4.32G/4.92G [00:17<00:02, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.87G/4.94G [00:17<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|████▎| 4.18G/4.92G [00:17<00:03, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.35G/4.92G [00:17<00:02, 253MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.90G/4.94G [00:18<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.38G/4.92G [00:17<00:02, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.22G/4.92G [00:18<00:03, 233MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.94G/4.94G [00:18<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  90%|████▍| 4.41G/4.92G [00:18<00:01, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.25G/4.92G [00:18<00:02, 233MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|███  | 2.97G/4.94G [00:18<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  90%|████▌| 4.45G/4.92G [00:18<00:01, 270MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.28G/4.92G [00:18<00:02, 234MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|███  | 3.00G/4.94G [00:18<00:08, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 4.48G/4.92G [00:18<00:01, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.31G/4.92G [00:18<00:02, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|███  | 3.03G/4.94G [00:18<00:08, 236MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.51G/4.92G [00:18<00:01, 257MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.34G/4.92G [00:18<00:02, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|███  | 3.06G/4.94G [00:18<00:07, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.54G/4.92G [00:18<00:01, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 4.37G/4.92G [00:18<00:02, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.09G/4.94G [00:18<00:07, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  93%|████▋| 4.57G/4.92G [00:18<00:01, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|████▍| 4.40G/4.92G [00:18<00:02, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.12G/4.94G [00:19<00:07, 235MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.60G/4.92G [00:18<00:01, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|████▌| 4.44G/4.92G [00:18<00:02, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.63G/4.92G [00:18<00:01, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 3.16G/4.94G [00:19<00:07, 235MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|████▌| 4.47G/4.92G [00:19<00:01, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  95%|████▋| 4.67G/4.92G [00:19<00:00, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▏ | 3.19G/4.94G [00:19<00:08, 197MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.50G/4.92G [00:19<00:01, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.70G/4.92G [00:19<00:00, 254MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.73G/4.92G [00:19<00:00, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.53G/4.92G [00:19<00:01, 235MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▏ | 3.21G/4.94G [00:19<00:11, 152MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 4.76G/4.92G [00:19<00:00, 254MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.56G/4.92G [00:19<00:01, 239MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.59G/4.92G [00:19<00:01, 243MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 4.79G/4.92G [00:19<00:00, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▎ | 3.23G/4.94G [00:19<00:12, 141MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 4.82G/4.92G [00:19<00:00, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 4.62G/4.92G [00:19<00:01, 239MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 4.85G/4.92G [00:19<00:00, 274MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|████▋| 4.66G/4.92G [00:19<00:01, 238MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.25G/4.94G [00:20<00:14, 117MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 4.89G/4.92G [00:19<00:00, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:19<00:00, 246MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/model-00002-of-00004.safetensors\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.27G/4.94G [00:20<00:14, 118MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 4.72G/4.92G [00:20<00:00, 241MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.75G/4.92G [00:20<00:00, 238MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.78G/4.92G [00:20<00:00, 237MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██▋ | 3.29G/4.94G [00:20<00:17, 95.7MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|████▉| 4.81G/4.92G [00:20<00:00, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.84G/4.92G [00:20<00:00, 243MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.88G/4.92G [00:20<00:00, 255MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██▋ | 3.31G/4.94G [00:21<00:22, 72.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.34G/4.94G [00:21<00:15, 100MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|████▉| 4.91G/4.92G [00:21<00:00, 171MB/s]\u001b[A\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:21<00:00, 232MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/model-00003-of-00004.safetensors\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 3.41G/4.94G [00:21<00:09, 154MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███▍ | 3.45G/4.94G [00:21<00:07, 193MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███▌ | 3.48G/4.94G [00:21<00:06, 216MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.51G/4.94G [00:21<00:06, 219MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.54G/4.94G [00:21<00:05, 234MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.58G/4.94G [00:21<00:05, 250MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.61G/4.94G [00:22<00:05, 265MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.64G/4.94G [00:22<00:04, 277MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.67G/4.94G [00:22<00:04, 283MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 3.70G/4.94G [00:22<00:04, 287MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.73G/4.94G [00:22<00:04, 295MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.77G/4.94G [00:22<00:03, 311MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.83G/4.94G [00:22<00:03, 355MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.88G/4.94G [00:22<00:02, 383MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.92G/4.94G [00:22<00:02, 388MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████ | 3.96G/4.94G [00:23<00:02, 389MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.01G/4.94G [00:23<00:02, 391MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.05G/4.94G [00:23<00:02, 392MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.09G/4.94G [00:23<00:02, 391MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.13G/4.94G [00:23<00:02, 392MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.17G/4.94G [00:23<00:01, 392MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.23G/4.94G [00:23<00:01, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.28G/4.94G [00:23<00:01, 430MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.33G/4.94G [00:23<00:01, 440MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.38G/4.94G [00:24<00:01, 451MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 4.44G/4.94G [00:24<00:01, 457MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.49G/4.94G [00:24<00:00, 462MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.54G/4.94G [00:24<00:00, 464MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.59G/4.94G [00:24<00:00, 464MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.65G/4.94G [00:24<00:00, 450MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.70G/4.94G [00:24<00:00, 438MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.75G/4.94G [00:24<00:00, 446MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 4.80G/4.94G [00:24<00:00, 452MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.85G/4.94G [00:25<00:00, 458MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████| 4.94G/4.94G [00:25<00:00, 195MB/s]\u001b[A\n",
      "Download complete. Moving file to InternVL2-8B/model-00001-of-00004.safetensors\n",
      "Fetching 26 files: 100%|████████████████████████| 26/26 [00:27<00:00,  1.05s/it]\n",
      "/workspace/InternVL2-8B\n"
     ]
    }
   ],
   "source": [
    "!mkdir pretrained && cd pretrained\n",
    "!huggingface-cli download --resume-download --local-dir-use-symlinks False OpenGVLab/InternVL2-8B --local-dir InternVL2-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b2d3ca-93f5-4544-9560-6fe741a988c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import constants\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import time\n",
    "from time import time as timer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "def create_placeholder_image(image_save_path):\n",
    "    try:\n",
    "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "        placeholder_image.save(image_save_path)\n",
    "    except Exception as e:\n",
    "        return\n",
    "\n",
    "def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "    if not isinstance(image_link, str):\n",
    "        return\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            return\n",
    "        except:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
    "\n",
    "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    if allow_multiprocessing:\n",
    "        download_image_partial = partial(\n",
    "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
    "\n",
    "        with multiprocessing.Pool(64) as pool:\n",
    "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    else:\n",
    "        for image_link in tqdm(image_links, total=len(image_links)):\n",
    "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4fdefa-4de0-4f1f-987d-96dba68ad57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263859/263859 [06:03<00:00, 726.45it/s] \n",
      "100%|██████████| 131187/131187 [02:54<00:00, 751.35it/s] \n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER = 'dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "\n",
    "download_images(train['image_link'], 'dataset/train')\n",
    "download_images(test['image_link'], 'dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44498c84-6de6-4bd3-9f9d-a7fb4c5fff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Entity Name   Count\n",
      "0                    item_weight  102786\n",
      "1                    item_volume    7682\n",
      "2                        voltage    9466\n",
      "3                        wattage    7755\n",
      "4  maximum_weight_recommendation    3263\n",
      "5                         height   43597\n",
      "6                          depth   45127\n",
      "7                          width   44183\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACYK0lEQVR4nOzdeZxO9f//8ec1Y8zYZgwyDGLsa3ayL8laUSpE2Ul2WZM1yyd7ZM9WKEuSfQ+JLGPJkkoh0aAwYx3MvH5/+M35zmVpkWtm8LjfbnNjznmfc72vc+a6rvO83stxmZkJAAAAAAA8cF7xXQEAAAAAAB5VhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AwCPD5XKpf//+8V0NPIQ2btwol8uljRs3xndVAACPGEI3AMBjZs6cKZfLdc+fb7/99l/vc8WKFf84WG/dulX9+/fXhQsX/vXj/JWKFSvK5XLp+eefv2PdsWPH5HK5NGLEiAf6mHHp559/VuvWrZU1a1b5+fnJ399fZcqU0QcffKCrV6/Gd/UkSRMmTNDMmTPjuxp/KUuWLM7fupeXl1KmTKkCBQqoVatW2r59+3/a95AhQ7R48eIHU9H/6NChQ+rfv7+OHTsW31UBgAQpUXxXAADw6Bs4cKBCQkLuWJ49e/Z/va8VK1Zo/Pjxdw3eV69eVaJE//fRtnXrVg0YMEBNmjRRypQp//Vj/Z1ly5YpNDRURYsWfeD7ji/Lly/XK6+8Il9fX73xxhvKnz+/rl+/ri1btqhbt246ePCgpkyZEt/V1IQJE5QmTRo1adLkgeyvfPnyunr1qhInTvxA9hejUKFCevvttyVJFy9e1Pfff68FCxZo6tSp6ty5s0aNGnVf+x0yZIhefvll1alT5wHW9v4cOnRIAwYMUMWKFZUlS5b4rg4AJDiEbgCAx9WoUUPFihXz+OP4+fl5/DFiPPnkk7p48aIGDBigJUuWxNnjetLRo0dVv359Zc6cWRs2bFD69OmddW3bttWRI0e0fPnyeKyh53h5eXnk7ydDhgxq1KiR27L3339fr732mkaPHq0cOXKoTZs2D/xxAQAJB93LAQDxLnaX7ClTpihbtmzy9fVV8eLFtXPnTqdckyZNNH78eEly66YeI/aY7v79+6tbt26SpJCQEKfssWPHVKFCBRUsWPCudcmVK5eqVav2t3VOkSKFOnfurKVLl2r37t1/WfbcuXPq2rWrChQooOTJk8vf3181atTQvn373MrFjCueP3++BgwYoAwZMihFihR6+eWXFR4ersjISHXq1Elp06ZV8uTJ1bRpU0VGRt7xeLNnz1bRokWVJEkSpUqVSvXr19eJEyf+9jkNGzZMly5d0rRp09wCd4zs2bOrY8eOzu83b97Ue++955yvLFmy6J133rmjTvcaa58lSxa3luqY4QjffPONunTpoieeeELJkiXTiy++qLNnz7ptd/DgQW3atMk5rxUrVpQk3bhxQwMGDFCOHDnk5+en1KlTq2zZslq7du1fPve7jemuWLGi8ufPr0OHDqlSpUpKmjSpMmTIoGHDhv3lvv5OkiRJ9MknnyhVqlQaPHiwzMxZN2LECJUuXVqpU6dWkiRJVLRoUS1cuNBte5fLpcuXL2vWrFnO8485jsePH9dbb72lXLlyKUmSJEqdOrVeeeWVO7p+/9PjdPjwYb388stKlSqV/Pz8VKxYMbcvmWbOnKlXXnlFklSpUiWnPoyNB4D/Q0s3AMDjwsPD9ccff7gtc7lcSp06tduyuXPn6uLFi2rdurVcLpeGDRuml156Sb/88ot8fHzUunVrnTp1SmvXrtUnn3zyl4/50ksv6ccff9Snn36q0aNHK02aNJKkJ554Qq+//rpatmypAwcOKH/+/M42O3fu1I8//qh33333Hz2vjh07avTo0erfv/9ftnb/8ssvWrx4sV555RWFhITo9OnTmjx5sipUqKBDhw4pODjYrfzQoUOVJEkS9ezZU0eOHNG4cePk4+MjLy8vnT9/Xv3799e3336rmTNnKiQkRH379nW2HTx4sPr06aNXX31VLVq00NmzZzVu3DiVL19ee/bs+ctu9kuXLlXWrFlVunTpf/T8W7RooVmzZunll1/W22+/re3bt2vo0KH6/vvv9cUXX/yjfdxN+/btFRgYqH79+unYsWMaM2aM2rVrp3nz5kmSxowZo/bt2yt58uTq3bu3JCkoKEjSrS9bhg4dqhYtWqhEiRKKiIjQrl27tHv3bj377LP/ui7nz59X9erV9dJLL+nVV1/VwoUL1aNHDxUoUEA1atS47+eYPHlyvfjii5o2bZoOHTqkfPnySZI++OADvfDCC2rYsKGuX7+uzz77TK+88oqWLVumWrVqSZI++eQT5/m1atVKkpQtWzZJt/6Gt27dqvr16ytjxow6duyYJk6cqIoVK+rQoUNKmjTpPz5OBw8eVJkyZZQhQwb17NlTyZIl0/z581WnTh19/vnnevHFF1W+fHl16NBBY8eO1TvvvKM8efJIkvMvAECSAQDgITNmzDBJd/3x9fV1yh09etQkWerUqe3cuXPO8i+//NIk2dKlS51lbdu2tXt9fEmyfv36Ob8PHz7cJNnRo0fdyl24cMH8/PysR48ebss7dOhgyZIls0uXLv3l86pQoYLly5fPzMwGDBhgkiw0NNTtuQwfPtwpf+3aNYuKinLbx9GjR83X19cGDhzoLPvqq69MkuXPn9+uX7/uLG/QoIG5XC6rUaOG2z5KlSplmTNndn4/duyYeXt72+DBg93K7d+/3xIlSnTH8tjCw8NNktWuXfsvn3uMvXv3miRr0aKF2/KuXbuaJNuwYYOz7PbzEiNz5szWuHFj5/eYv5cqVapYdHS0s7xz587m7e1tFy5ccJbly5fPKlSocMc+CxYsaLVq1fpHzyG2mGP/1VdfOcsqVKhgkuzjjz92lkVGRlq6dOmsbt26f7vPzJkz/2VdRo8ebZLsyy+/dJZduXLFrcz169ctf/78VrlyZbflyZIlczt299rezGzbtm13PI9/cpyeeeYZK1CggF27ds1ZFh0dbaVLl7YcOXI4yxYsWHDHsQMA/B+6lwMAPG78+PFau3at28/KlSvvKFevXj0FBgY6v5crV07SrZbiBykgIEC1a9fWp59+6nTtjYqK0rx581SnTh0lS5bsH++rY8eOCgwM1IABA+5ZxtfXV15eXs7j/Pnnn0qePLly5cp1167pb7zxhnx8fJzfS5YsKTNTs2bN3MqVLFlSJ06c0M2bNyVJixYtUnR0tF599VX98ccfzk+6dOmUI0cOffXVV/esY0REhKRb3eb/iRUrVkiSunTp4rY8ZtKw/zL2u1WrVm7DBsqVK6eoqCgdP378b7dNmTKlDh48qJ9++um+Hz+25MmTu43JTpw4sUqUKPFA/iaTJ08u6dYEazGSJEni/P/8+fMKDw9XuXLl/nYIw922v3Hjhv78809lz55dKVOmdNvH3x2nc+fOacOGDXr11Vd18eJF52/pzz//VLVq1fTTTz/p5MmT/+r5AsDjiu7lAACPK1GixD+aSO3JJ590+z0mgJ8/f/6B1+mNN97QvHnz9PXXX6t8+fJat26dTp8+rddff/1f7ScgIECdOnVSv379tGfPHrcvDWJER0frgw8+0IQJE3T06FFFRUU5627vYi/deRwCAgIkSZkyZbpjeXR0tMLDw5U6dWr99NNPMjPlyJHjrnWNHeRv5+/vL8k9AP6V48ePy8vL644Z6NOlS6eUKVP+o4B8L//l72DgwIGqXbu2cubMqfz586t69ep6/fXX9dRTT91XXTJmzOj2BUBMfb777rv72l9sly5dkuT+RceyZcs0aNAg7d27121s/O11uJerV69q6NChmjFjhk6ePOk2Xjw8PNz5/98dpyNHjsjM1KdPH/Xp0+euj3XmzBllyJDhnz9hAHhMEboBAAmGt7f3XZfHDg4PSrVq1RQUFKTZs2erfPnymj17ttKlS6cqVar8633FjO0eMGCAxowZc8f6IUOGqE+fPmrWrJnee+89pUqVSl5eXurUqZOio6PvKH+v4/B3xyc6Oloul0srV668a9mYltW78ff3V3BwsA4cOHDPMnfzT8Pg3cT+8iG2//J3UL58ef3888/68ssvtWbNGn300UcaPXq0Jk2apBYtWvzrOnrybzLmWMd8cfH111/rhRdeUPny5TVhwgSlT59ePj4+mjFjhubOnfuP9tm+fXvNmDFDnTp1UqlSpRQQECCXy6X69eu7/a393XGKKdu1a9d7Tix4P7f8A4DHEaEbAPBQ+Tch76/Kent767XXXtPMmTP1/vvva/HixWrZsuU9Q9ZfiWnt7t+/vxo3bnzH+oULF6pSpUqaNm2a2/ILFy44E7w9CNmyZZOZKSQkRDlz5vzX2z/33HOaMmWKtm3bplKlSv1l2cyZMys6Olo//fST26RZp0+f1oULF5Q5c2ZnWWBgoC5cuOC2/fXr1/X777//6zrG+KtzmypVKjVt2lRNmzbVpUuXVL58efXv3/++QrenXLp0SV988YUyZcrkHL/PP/9cfn5+Wr16tXx9fZ2yM2bMuGP7ez3/hQsXqnHjxho5cqSz7Nq1a3ccf+mvj1PWrFkl3eod8XdfRP2XL14A4HHAmG4AwEMlZrz13ULEvy37+uuv6/z582rdurUuXbp0x/2U/41OnTopZcqUGjhw4B3rvL2972gZXbBgwQMfE/vSSy/J29tbAwYMuOPxzEx//vnnX27fvXt3JUuWTC1atNDp06fvWP/zzz/rgw8+kCTVrFlTku5o2R81apQkOTNtS7e+DNi8ebNbuSlTptyzpfufSJYs2V3P6+3PMXny5MqePftdb60WX65evarXX39d586dU+/evZ3Q6u3tLZfL5XZcjh07psWLF9+xj3s9/7v9rY0bN+6OY/13xylt2rSqWLGiJk+efNcvR2Lfwu3fvCYB4HFESzcAwONWrlypw4cP37G8dOnSTovaP1W0aFFJUocOHVStWjV5e3urfv36f1m2d+/eql+/vnx8fPT88887IaFw4cLKnz+/FixYoDx58qhIkSL/qi6xBQQEqGPHjnedUO25557TwIED1bRpU5UuXVr79+/XnDlz/vVz/zvZsmXToEGD1KtXLx07dkx16tRRihQpdPToUX3xxRdq1aqVunbt+pfbz507V/Xq1VOePHn0xhtvKH/+/Lp+/bq2bt2qBQsWOPeDLliwoBo3bqwpU6bowoULqlChgnbs2KFZs2apTp06qlSpkrPfFi1a6M0331TdunX17LPPat++fVq9evV/auUvWrSoJk6cqEGDBil79uxKmzatKleurLx586pixYoqWrSoUqVKpV27dmnhwoVq167dfT/Wf3Hy5EnNnj1b0q3W7UOHDmnBggUKCwvT22+/rdatWztla9WqpVGjRql69ep67bXXdObMGY0fP17Zs2e/Ywx50aJFtW7dOo0aNUrBwcEKCQlRyZIl9dxzz+mTTz5RQECA8ubNq23btmndunV3zB3wT47T+PHjVbZsWRUoUEAtW7ZU1qxZdfr0aW3btk2//fabc5/5QoUKydvbW++//77Cw8Pl6+urypUrK23atJ46rADwcImPKdMBAI+Hv7plmCSbMWOGmd39NlsxdNvtpm7evGnt27e3J554wlwul9vtw24va2b23nvvWYYMGczLy+uutw8bNmyYSbIhQ4b84+cV+5ZhsZ0/f94CAgLuesuwt99+29KnT29JkiSxMmXK2LZt26xChQput72KuW3VggUL3PYbcxx37tzptrxfv34myc6ePeu2/PPPP7eyZctasmTJLFmyZJY7d25r27at/fDDD//o+f3444/WsmVLy5IliyVOnNhSpEhhZcqUsXHjxrndPurGjRs2YMAACwkJMR8fH8uUKZP16tXLrYyZWVRUlPXo0cPSpEljSZMmtWrVqtmRI0fuecuw25/n3W7nFRYWZrVq1bIUKVKYJOc4Dho0yEqUKGEpU6a0JEmSWO7cuW3w4MFut2C7m3vdMuxu57lx48Zut2q7l8yZMzt/6y6Xy/z9/S1fvnzWsmVL2759+123mTZtmuXIkcN8fX0td+7cNmPGDOc8x3b48GErX768JUmSxCQ5x/H8+fPWtGlTS5MmjSVPntyqVatmhw8fvuNY/9Pj9PPPP9sbb7xh6dKlMx8fH8uQIYM999xztnDhQrdyU6dOtaxZs5q3tze3DwOA27jMPDA7DQAAD4kPPvhAnTt31rFjx+6YNRsAAOC/InQDAB5bZqaCBQsqderUf3kPawAAgPvFmG4AwGPn8uXLWrJkib766ivt379fX375ZXxXCQAAPKJo6QYAPHaOHTumkJAQpUyZUm+99ZYGDx4c31UCAACPKEI3AAAAAAAewn26AQAAAADwEEI3AAAAAAAewkRqcSg6OlqnTp1SihQp5HK54rs6AAAAAID7ZGa6ePGigoOD5eV17/ZsQnccOnXqlDJlyhTf1QAAAAAAPCAnTpxQxowZ77me0B2HUqRIIenWSfH394/n2gAAAAAA7ldERIQyZcrk5Lx7IXTHoZgu5f7+/oRuAAAAAHgE/N3QYSZSAwAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADwkUXxXAAlL+IAB8V2FR0ZAv37xXQUAAAAA8YyWbgAAAAAAPITQDQAAAACAhxC6AQAAAADwkHgN3Zs3b9bzzz+v4OBguVwuLV682G29malv375Knz69kiRJoipVquinn35yK3Pu3Dk1bNhQ/v7+SpkypZo3b65Lly65lfnuu+9Urlw5+fn5KVOmTBo2bNgddVmwYIFy584tPz8/FShQQCtWrPjXdQEAAAAAILZ4Dd2XL19WwYIFNX78+LuuHzZsmMaOHatJkyZp+/btSpYsmapVq6Zr1645ZRo2bKiDBw9q7dq1WrZsmTZv3qxWrVo56yMiIlS1alVlzpxZoaGhGj58uPr3768pU6Y4ZbZu3aoGDRqoefPm2rNnj+rUqaM6derowIED/6ouAAAAAADE5jIzi+9KSJLL5dIXX3yhOnXqSLrVshwcHKy3335bXbt2lSSFh4crKChIM2fOVP369fX9998rb9682rlzp4oVKyZJWrVqlWrWrKnffvtNwcHBmjhxonr37q2wsDAlTpxYktSzZ08tXrxYhw8fliTVq1dPly9f1rJly5z6PP300ypUqJAmTZr0j+ryT0RERCggIEDh4eHy9/d/IMftQWP28geH2csBAACAR9c/zXcJdkz30aNHFRYWpipVqjjLAgICVLJkSW3btk2StG3bNqVMmdIJ3JJUpUoVeXl5afv27U6Z8uXLO4FbkqpVq6YffvhB58+fd8rEfpyYMjGP80/qAgAAAADA7RLsfbrDwsIkSUFBQW7Lg4KCnHVhYWFKmzat2/pEiRIpVapUbmVCQkLu2EfMusDAQIWFhf3t4/xdXe4mMjJSkZGRzu8RERF/8YwBAAAAAI+aBNvS/SgYOnSoAgICnJ9MmTLFd5UAAAAAAHEowYbudOnSSZJOnz7ttvz06dPOunTp0unMmTNu62/evKlz5865lbnbPmI/xr3KxF7/d3W5m169eik8PNz5OXHixN88awAAAADAoyTBhu6QkBClS5dO69evd5ZFRERo+/btKlWqlCSpVKlSunDhgkJDQ50yGzZsUHR0tEqWLOmU2bx5s27cuOGUWbt2rXLlyqXAwECnTOzHiSkT8zj/pC534+vrK39/f7cfAAAAAMDjI15D96VLl7R3717t3btX0q0Jy/bu3atff/1VLpdLnTp10qBBg7RkyRLt379fb7zxhoKDg50ZzvPkyaPq1aurZcuW2rFjh7755hu1a9dO9evXV3BwsCTptddeU+LEidW8eXMdPHhQ8+bN0wcffKAuXbo49ejYsaNWrVqlkSNH6vDhw+rfv7927dqldu3aSdI/qgsAAAAAALeL14nUdu3apUqVKjm/xwThxo0ba+bMmerevbsuX76sVq1a6cKFCypbtqxWrVolPz8/Z5s5c+aoXbt2euaZZ+Tl5aW6detq7NixzvqAgACtWbNGbdu2VdGiRZUmTRr17dvX7V7epUuX1ty5c/Xuu+/qnXfeUY4cObR48WLlz5/fKfNP6gIAAAAAQGwJ5j7djwPu0/144T7dAAAAwKProb9PNwAAAAAADztCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQxJ06I6KilKfPn0UEhKiJEmSKFu2bHrvvfdkZk4ZM1Pfvn2VPn16JUmSRFWqVNFPP/3ktp9z586pYcOG8vf3V8qUKdW8eXNdunTJrcx3332ncuXKyc/PT5kyZdKwYcPuqM+CBQuUO3du+fn5qUCBAlqxYoVnnjgAAAAA4JGQoEP3+++/r4kTJ+rDDz/U999/r/fff1/Dhg3TuHHjnDLDhg3T2LFjNWnSJG3fvl3JkiVTtWrVdO3aNadMw4YNdfDgQa1du1bLli3T5s2b1apVK2d9RESEqlatqsyZMys0NFTDhw9X//79NWXKFKfM1q1b1aBBAzVv3lx79uxRnTp1VKdOHR04cCBuDgYAAAAA4KHjstjNxgnMc889p6CgIE2bNs1ZVrduXSVJkkSzZ8+WmSk4OFhvv/22unbtKkkKDw9XUFCQZs6cqfr16+v7779X3rx5tXPnThUrVkyStGrVKtWsWVO//fabgoODNXHiRPXu3VthYWFKnDixJKlnz55avHixDh8+LEmqV6+eLl++rGXLljl1efrpp1WoUCFNmjTpHz2fiIgIBQQEKDw8XP7+/g/kGD1o4QMGxHcVHhkB/frFdxUAAAAAeMg/zXcJuqW7dOnSWr9+vX788UdJ0r59+7RlyxbVqFFDknT06FGFhYWpSpUqzjYBAQEqWbKktm3bJknatm2bUqZM6QRuSapSpYq8vLy0fft2p0z58uWdwC1J1apV0w8//KDz5887ZWI/TkyZmMe5m8jISEVERLj9AAAAAAAeH4niuwJ/pWfPnoqIiFDu3Lnl7e2tqKgoDR48WA0bNpQkhYWFSZKCgoLctgsKCnLWhYWFKW3atG7rEyVKpFSpUrmVCQkJuWMfMesCAwMVFhb2l49zN0OHDtUAWo4BAAAA4LGVoFu658+frzlz5mju3LnavXu3Zs2apREjRmjWrFnxXbV/pFevXgoPD3d+Tpw4Ed9VAgAAAADEoQTd0t2tWzf17NlT9evXlyQVKFBAx48f19ChQ9W4cWOlS5dOknT69GmlT5/e2e706dMqVKiQJCldunQ6c+aM235v3rypc+fOOdunS5dOp0+fdisT8/vflYlZfze+vr7y9fX9t08bAAAAAPCISNAt3VeuXJGXl3sVvb29FR0dLUkKCQlRunTptH79emd9RESEtm/frlKlSkmSSpUqpQsXLig0NNQps2HDBkVHR6tkyZJOmc2bN+vGjRtOmbVr1ypXrlwKDAx0ysR+nJgyMY8DAAAAAMDtEnTofv755zV48GAtX75cx44d0xdffKFRo0bpxRdflCS5XC516tRJgwYN0pIlS7R//3698cYbCg4OVp06dSRJefLkUfXq1dWyZUvt2LFD33zzjdq1a6f69esrODhYkvTaa68pceLEat68uQ4ePKh58+bpgw8+UJcuXZy6dOzYUatWrdLIkSN1+PBh9e/fX7t27VK7du3i/LgAAAAAAB4OCbp7+bhx49SnTx+99dZbOnPmjIKDg9W6dWv17dvXKdO9e3ddvnxZrVq10oULF1S2bFmtWrVKfn5+Tpk5c+aoXbt2euaZZ+Tl5aW6detq7NixzvqAgACtWbNGbdu2VdGiRZUmTRr17dvX7V7epUuX1ty5c/Xuu+/qnXfeUY4cObR48WLlz58/bg4GAAAAAOChk6Dv0/2o4T7djxfu0w0AAAA8uh6J+3QDAAAAAPAwI3QDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQugEAAAAA8BBCNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhCT50nzx5Uo0aNVLq1KmVJEkSFShQQLt27XLWm5n69u2r9OnTK0mSJKpSpYp++uknt32cO3dODRs2lL+/v1KmTKnmzZvr0qVLbmW+++47lStXTn5+fsqUKZOGDRt2R10WLFig3Llzy8/PTwUKFNCKFSs886QBAAAAAI+EBB26z58/rzJlysjHx0crV67UoUOHNHLkSAUGBjplhg0bprFjx2rSpEnavn27kiVLpmrVqunatWtOmYYNG+rgwYNau3atli1bps2bN6tVq1bO+oiICFWtWlWZM2dWaGiohg8frv79+2vKlClOma1bt6pBgwZq3ry59uzZozp16qhOnTo6cOBA3BwMAAAAAMBDx2VmFt+VuJeePXvqm2++0ddff33X9Wam4OBgvf322+rataskKTw8XEFBQZo5c6bq16+v77//Xnnz5tXOnTtVrFgxSdKqVatUs2ZN/fbbbwoODtbEiRPVu3dvhYWFKXHixM5jL168WIcPH5Yk1atXT5cvX9ayZcucx3/66adVqFAhTZo06R89n4iICAUEBCg8PFz+/v73fVw8KXzAgPiuwiMjoF+/+K4CAAAAAA/5p/kuQbd0L1myRMWKFdMrr7yitGnTqnDhwpo6daqz/ujRowoLC1OVKlWcZQEBASpZsqS2bdsmSdq2bZtSpkzpBG5JqlKliry8vLR9+3anTPny5Z3ALUnVqlXTDz/8oPPnzztlYj9OTJmYxwEAAAAA4HYJOnT/8ssvmjhxonLkyKHVq1erTZs26tChg2bNmiVJCgsLkyQFBQW5bRcUFOSsCwsLU9q0ad3WJ0qUSKlSpXIrc7d9xH6Me5WJWX83kZGRioiIcPsBAAAAADw+7it0Z82aVX/++ecdyy9cuKCsWbP+50rFiI6OVpEiRTRkyBAVLlxYrVq1UsuWLf9xd+74NnToUAUEBDg/mTJliu8qAQAAAADi0H2F7mPHjikqKuqO5ZGRkTp58uR/rlSM9OnTK2/evG7L8uTJo19//VWSlC5dOknS6dOn3cqcPn3aWZcuXTqdOXPGbf3Nmzd17tw5tzJ320fsx7hXmZj1d9OrVy+Fh4c7PydOnPj7Jw0AAAAAeGQk+jeFlyxZ4vx/9erVCggIcH6PiorS+vXrlSVLlgdWuTJlyuiHH35wW/bjjz8qc+bMkqSQkBClS5dO69evV6FChSTdGsy+fft2tWnTRpJUqlQpXbhwQaGhoSpatKgkacOGDYqOjlbJkiWdMr1799aNGzfk4+MjSVq7dq1y5crlzJReqlQprV+/Xp06dXLqsnbtWpUqVeqe9ff19ZWvr+9/PxAAAAAAgIfSvwrdderUkSS5XC41btzYbZ2Pj4+yZMmikSNHPrDKde7cWaVLl9aQIUP06quvaseOHZoyZYpzKy+Xy6VOnTpp0KBBypEjh0JCQtSnTx8FBwc7dc2TJ4+qV6/udEu/ceOG2rVrp/r16ys4OFiS9Nprr2nAgAFq3ry5evTooQMHDuiDDz7Q6NGjnbp07NhRFSpU0MiRI1WrVi199tln2rVrl9ttxQAAAAAAiO1fhe7o6GhJt1qYd+7cqTRp0nikUjGKFy+uL774Qr169dLAgQMVEhKiMWPGqGHDhk6Z7t276/Lly2rVqpUuXLigsmXLatWqVfLz83PKzJkzR+3atdMzzzwjLy8v1a1bV2PHjnXWBwQEaM2aNWrbtq2KFi2qNGnSqG/fvm738i5durTmzp2rd999V++8845y5MihxYsXK3/+/B49BgAAAACAh1eCvk/3o4b7dD9euE83AAAA8Oj6p/nuX7V0x7Z+/XqtX79eZ86ccVrAY0yfPv1+dwsAAAAAwCPjvkL3gAEDNHDgQBUrVkzp06eXy+V60PUCAAAAAOChd1+he9KkSZo5c6Zef/31B10fAAAAAAAeGfd1n+7r16+rdOnSD7ouAAAAAAA8Uu4rdLdo0UJz58590HUBAAAAAOCRcl/dy69du6YpU6Zo3bp1euqpp+Tj4+O2ftSoUQ+kcgAAAAAAPMzuK3R/9913KlSokCTpwIEDbuuYVA0AAAAAgFvuK3R/9dVXD7oeAAAAAAA8cu5rTDcAAAAAAPh799XSXalSpb/sRr5hw4b7rhAAAAAAAI+K+wrdMeO5Y9y4cUN79+7VgQMH1Lhx4wdRLwAAAAAAHnr3FbpHjx591+X9+/fXpUuX/lOFAAAAAAB4VDzQMd2NGjXS9OnTH+QuAQAAAAB4aD3Q0L1t2zb5+fk9yF0CAAAAAPDQuq/u5S+99JLb72am33//Xbt27VKfPn0eSMUAAAAAAHjY3VfoDggIcPvdy8tLuXLl0sCBA1W1atUHUjEAAAAAAB529xW6Z8yY8aDrAQAAAADAI+e+QneM0NBQff/995KkfPnyqXDhwg+kUgAAAAAAPAruK3SfOXNG9evX18aNG5UyZUpJ0oULF1SpUiV99tlneuKJJx5kHQEAAAAAeCjd1+zl7du318WLF3Xw4EGdO3dO586d04EDBxQREaEOHTo86DoCAAAAAPBQuq+W7lWrVmndunXKkyePsyxv3rwaP348E6kBAAAAAPD/3VdLd3R0tHx8fO5Y7uPjo+jo6P9cKQAAAAAAHgX3FborV66sjh076tSpU86ykydPqnPnznrmmWceWOUAAAAAAHiY3Vfo/vDDDxUREaEsWbIoW7ZsypYtm0JCQhQREaFx48Y96DoCAAAAAPBQuq8x3ZkyZdLu3bu1bt06HT58WJKUJ08eValS5YFWDgAAAACAh9m/aunesGGD8ubNq4iICLlcLj377LNq37692rdvr+LFiytfvnz6+uuvPVVXAAAAAAAeKv8qdI8ZM0YtW7aUv7//HesCAgLUunVrjRo16oFVDgAAAACAh9m/Ct379u1T9erV77m+atWqCg0N/c+VAgAAAADgUfCvQvfp06fvequwGIkSJdLZs2f/c6UAAAAAAHgU/KvQnSFDBh04cOCe67/77julT5/+P1cKAAAAAIBHwb8K3TVr1lSfPn107dq1O9ZdvXpV/fr103PPPffAKgcAAAAAwMPsX90y7N1339WiRYuUM2dOtWvXTrly5ZIkHT58WOPHj1dUVJR69+7tkYoCAAAAAPCw+VehOygoSFu3blWbNm3Uq1cvmZkkyeVyqVq1aho/fryCgoI8UlEAAAAAAB42/yp0S1LmzJm1YsUKnT9/XkeOHJGZKUeOHAoMDPRE/QAAAAAAeGj969AdIzAwUMWLF3+QdQEAAAAA4JHyryZSAwAAAAAA/xyhGwAAAAAADyF0AwAAAADgIYRuAAAAAAA8hNANAAAAAICH3Pfs5QAAAADiR/iAAfFdhUdGQL9+8V0FPOJo6QYAAAAAwENo6QYAAACAB4ieCA/Oo9ATgZZuAAAAAAA8hJZuAAAA3BWtdQ/Oo9BaB+D+0NINAAAAAICHELoBAAAAAPAQQjcAAAAAAB5C6AYAAAAAwEMI3QAAAAAAeAihGwAAAAAAD3moQvf//vc/uVwuderUyVl27do1tW3bVqlTp1by5MlVt25dnT592m27X3/9VbVq1VLSpEmVNm1adevWTTdv3nQrs3HjRhUpUkS+vr7Knj27Zs6cecfjjx8/XlmyZJGfn59KliypHTt2eOJpAgAAAAAeEQ9N6N65c6cmT56sp556ym15586dtXTpUi1YsECbNm3SqVOn9NJLLznro6KiVKtWLV2/fl1bt27VrFmzNHPmTPXt29cpc/ToUdWqVUuVKlXS3r171alTJ7Vo0UKrV692ysybN09dunRRv379tHv3bhUsWFDVqlXTmTNnPP/kAQAAAAAPpYcidF+6dEkNGzbU1KlTFRgY6CwPDw/XtGnTNGrUKFWuXFlFixbVjBkztHXrVn377beSpDVr1ujQoUOaPXu2ChUqpBo1aui9997T+PHjdf36dUnSpEmTFBISopEjRypPnjxq166dXn75ZY0ePdp5rFGjRqlly5Zq2rSp8ubNq0mTJilp0qSaPn163B4MAAAAAMBD46EI3W3btlWtWrVUpUoVt+WhoaG6ceOG2/LcuXPrySef1LZt2yRJ27ZtU4ECBRQUFOSUqVatmiIiInTw4EGnzO37rlatmrOP69evKzQ01K2Ml5eXqlSp4pS5m8jISEVERLj9AAAAAAAeH4niuwJ/57PPPtPu3bu1c+fOO9aFhYUpceLESpkypdvyoKAghYWFOWViB+6Y9THr/qpMRESErl69qvPnzysqKuquZQ4fPnzPug8dOlQDBgz4Z08UAAAAAPDISdAt3SdOnFDHjh01Z84c+fn5xXd1/rVevXopPDzc+Tlx4kR8VwkAAAAAEIcSdOgODQ3VmTNnVKRIESVKlEiJEiXSpk2bNHbsWCVKlEhBQUG6fv26Lly44Lbd6dOnlS5dOklSunTp7pjNPOb3vyvj7++vJEmSKE2aNPL29r5rmZh93I2vr6/8/f3dfgAAAAAAj48EHbqfeeYZ7d+/X3v37nV+ihUrpoYNGzr/9/Hx0fr1651tfvjhB/36668qVaqUJKlUqVLav3+/2yzja9eulb+/v/LmzeuUib2PmDIx+0icOLGKFi3qViY6Olrr1693ygAAAAAAcLsEPaY7RYoUyp8/v9uyZMmSKXXq1M7y5s2bq0uXLkqVKpX8/f3Vvn17lSpVSk8//bQkqWrVqsqbN69ef/11DRs2TGFhYXr33XfVtm1b+fr6SpLefPNNffjhh+revbuaNWumDRs2aP78+Vq+fLnzuF26dFHjxo1VrFgxlShRQmPGjNHly5fVtGnTODoaAAAAAICHTYIO3f/E6NGj5eXlpbp16yoyMlLVqlXThAkTnPXe3t5atmyZ2rRpo1KlSilZsmRq3LixBg4c6JQJCQnR8uXL1blzZ33wwQfKmDGjPvroI1WrVs0pU69ePZ09e1Z9+/ZVWFiYChUqpFWrVt0xuRoAAAAAADEeutC9ceNGt9/9/Pw0fvx4jR8//p7bZM6cWStWrPjL/VasWFF79uz5yzLt2rVTu3bt/nFdAQAAAACPtwQ9phsAAAAAgIcZoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA9J0KF76NChKl68uFKkSKG0adOqTp06+uGHH9zKXLt2TW3btlXq1KmVPHly1a1bV6dPn3Yr8+uvv6pWrVpKmjSp0qZNq27duunmzZtuZTZu3KgiRYrI19dX2bNn18yZM++oz/jx45UlSxb5+fmpZMmS2rFjxwN/zgAAAACAR0eCDt2bNm1S27Zt9e2332rt2rW6ceOGqlatqsuXLztlOnfurKVLl2rBggXatGmTTp06pZdeeslZHxUVpVq1aun69evaunWrZs2apZkzZ6pv375OmaNHj6pWrVqqVKmS9u7dq06dOqlFixZavXq1U2bevHnq0qWL+vXrp927d6tgwYKqVq2azpw5EzcHAwAAAADw0EkU3xX4K6tWrXL7febMmUqbNq1CQ0NVvnx5hYeHa9q0aZo7d64qV64sSZoxY4by5Mmjb7/9Vk8//bTWrFmjQ4cOad26dQoKClKhQoX03nvvqUePHurfv78SJ06sSZMmKSQkRCNHjpQk5cmTR1u2bNHo0aNVrVo1SdKoUaPUsmVLNW3aVJI0adIkLV++XNOnT1fPnj3j8KgAAAAAAB4WCbql+3bh4eGSpFSpUkmSQkNDdePGDVWpUsUpkzt3bj355JPatm2bJGnbtm0qUKCAgoKCnDLVqlVTRESEDh486JSJvY+YMjH7uH79ukJDQ93KeHl5qUqVKk4ZAAAAAABul6BbumOLjo5Wp06dVKZMGeXPn1+SFBYWpsSJEytlypRuZYOCghQWFuaUiR24Y9bHrPurMhEREbp69arOnz+vqKiou5Y5fPjwPescGRmpyMhI5/eIiIh/8YwBAAAAAA+7h6alu23btjpw4IA+++yz+K7KPzZ06FAFBAQ4P5kyZYrvKgEAAAAA4tBDEbrbtWunZcuW6auvvlLGjBmd5enSpdP169d14cIFt/KnT59WunTpnDK3z2Ye8/vflfH391eSJEmUJk0aeXt737VMzD7uplevXgoPD3d+Tpw48e+eOAAAAADgoZagQ7eZqV27dvriiy+0YcMGhYSEuK0vWrSofHx8tH79emfZDz/8oF9//VWlSpWSJJUqVUr79+93m2V87dq18vf3V968eZ0ysfcRUyZmH4kTJ1bRokXdykRHR2v9+vVOmbvx9fWVv7+/2w8AAAAA4PGRoMd0t23bVnPnztWXX36pFClSOGOwAwIClCRJEgUEBKh58+bq0qWLUqVKJX9/f7Vv316lSpXS008/LUmqWrWq8ubNq9dff13Dhg1TWFiY3n33XbVt21a+vr6SpDfffFMffvihunfvrmbNmmnDhg2aP3++li9f7tSlS5cuaty4sYoVK6YSJUpozJgxunz5sjObOQAAAAAAt0vQoXvixImSpIoVK7otnzFjhpo0aSJJGj16tLy8vFS3bl1FRkaqWrVqmjBhglPW29tby5YtU5s2bVSqVCklS5ZMjRs31sCBA50yISEhWr58uTp37qwPPvhAGTNm1EcffeTcLkyS6tWrp7Nnz6pv374KCwtToUKFtGrVqjsmVwMAAAAAIEaCDt1m9rdl/Pz8NH78eI0fP/6eZTJnzqwVK1b85X4qVqyoPXv2/GWZdu3aqV27dn9bJwAAAAAApAQ+phsAAAAAgIcZoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA8hdAMAAAAA4CGEbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDCN0AAAAAAHgIoRsAAAAAAA9JFN8VAIBHQfiAAfFdhUdGQL9+8V0FAACAB4aWbgAAAAAAPITQDQAAAACAhxC6AQAAAADwEEI3AAAAAAAeQugGAAAAAMBDmL0ceIgwQ/aDwwzZjxdeOw8Orx0AAP4dWroBAAAAAPAQQjcAAAAAAB5C6AYAAAAAwEMI3QAAAAAAeAihGwAAAAAADyF0AwAAAADgIYRuAAAAAAA8hNANAAAAAICHELoBAAAAAPAQQjcAAAAAAB5C6AYAAAAAwEMI3QAAAAAAeEii+K4AAAB4fIUPGBDfVXhkBPTrF99VAADcBS3dAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4AAAAAADyE0A0AAAAAgIcQuv+l8ePHK0uWLPLz81PJkiW1Y8eO+K4SAAAAACCBInT/C/PmzVOXLl3Ur18/7d69WwULFlS1atV05syZ+K4aAAAAACABInT/C6NGjVLLli3VtGlT5c2bV5MmTVLSpEk1ffr0+K4aAAAAACABShTfFXhYXL9+XaGhoerVq5ezzMvLS1WqVNG2bdvuuk1kZKQiIyOd38PDwyVJERERnq3sfxBx7Vp8V+GR4fLAeeb8PDgP+vxwbh4cXjsJG6+dhIvXTsLGayfh4rWTsHni/DwoMbnOzP6ynMv+rgQkSadOnVKGDBm0detWlSpVylnevXt3bdq0Sdu3b79jm/79+2vAgAFxWU0AAAAAQBw6ceKEMmbMeM/1tHR7UK9evdSlSxfn9+joaJ07d06pU6eWy+WKx5o93CIiIpQpUyadOHFC/v7+8V0dxMK5Sdg4PwkX5yZh4/wkXJybhI3zk3Bxbh4MM9PFixcVHBz8l+UI3f9QmjRp5O3trdOnT7stP336tNKlS3fXbXx9feXr6+u2LGXKlJ6q4mPH39+fN4kEinOTsHF+Ei7OTcLG+Um4ODcJG+cn4eLc/HcBAQF/W4aJ1P6hxIkTq2jRolq/fr2zLDo6WuvXr3frbg4AAAAAQAxauv+FLl26qHHjxipWrJhKlCihMWPG6PLly2ratGl8Vw0AAAAAkAARuv+FevXq6ezZs+rbt6/CwsJUqFAhrVq1SkFBQfFdtceKr6+v+vXrd0fXfcQ/zk3CxvlJuDg3CRvnJ+Hi3CRsnJ+Ei3MTt5i9HAAAAAAAD2FMNwAAAAAAHkLoBgAAAADAQwjdAAAAAAB4CKEbAAAAAAAPIXQDAAAAAOAhhG4kGNHR0c7/mVQfAIDHF9cEAB4lhG4kCFFRUfLyuvXnePPmTblcrniuEZDwxb4Q5aI0YYkdGAD8Ozdv3nSuCW7cuME1AYCHHqEb8W7FihXavn27JKljx45q3LhxPNcISPiio6PdLkRv3LgRj7VBbNHR0U5g2L17t3bv3q09e/bEc60QG1+KJFzLly/Xt99+K+nWNcHrr7/Ol4oJyM2bN+O7CvgLMe9tV69e1eXLl+O5NojNZbyTIR6ZmQoXLqxz586pdOnSWrNmjTZv3qz8+fPHd9Ug9/BwOzOj9SGexD4vY8eO1a5du/Tjjz+qYcOGev7555UlS5b4reBjLPbronfv3lq4cKF8fHx08uRJNWnSRF27dlWGDBniuZaPt9ivn/nz5+vcuXNKlSqVXn311XiuGcxMxYsXV1hYmMqUKaO1a9dyTZBAXLx4USlSpHB+X7BggU6dOqUsWbLoueeek7e3dzzW7vG2du1alS9fXr6+vpKkJUuWaMyYMbpy5YqqV6+uXr16OesQjwxIANKnT28+Pj42c+bM+K4K/r+oqCjn/9OnT7c2bdpYmzZtbOLEifFYK8TWo0cPS58+vfXr188mTJhgLpfLWrdubefOnYvvqj32hg8fbmnSpLGtW7eamVmvXr3M5XJZaGhoPNfs8RYdHe38v2fPnpY8eXIrVqyYuVwua9asmZ05cyYea4cYwcHB5uPjYzNmzIjvqsDMXnrpJWvRooX98ccfZnbr/Sxp0qRWokQJc7lc1rJlS/vxxx/juZaPpx9//NFcLpe1a9fOzMw2b95s/v7+1r59e+vcubMlT57c6tWrZ7///ns81xSJ4jv04/F27do1XbhwQU888YQCAwM1ZMgQZc2aVWXKlJGXl5dbi4TRshqnYo579+7dNWfOHNWtW1fJkiXTW2+9pV9++UXDhg2L5xo+3r799lstXLhQixYt0tNPP63du3fL5XKpdOnSCgwMjO/qPfZ2796t9957T6VKldLChQs1adIkjR8/XkWKFNGNGzfk4+MT31V8LMV8hhw/flzffPONvv76a2XNmlX79+9XjRo1dPnyZY0dO1Zp06aN55o+nq5du6bw8HClTZtWqVOn1uDBg5U1a1aVLVuWa4J4VLt2bTVt2lT+/v5q0KCBvv32W23cuFHFixfXpk2b9OKLLyoyMlK9e/dWzpw547u6j5UcOXLo888/V6NGjZQkSRIVKVJEvXv3Vvfu3SVJjRo10jPPPKP27dvrww8/VFBQUDzX+DEW36kfj58bN27cc12xYsUse/bs9vXXX9vNmzed5devX4+LquE2X331lYWEhNg333xjZmaLFi0yX19fmzRpUjzXDBs2bLAyZcqYmdm8efMsefLkTi+E8PBw55zB82K3npqZXbx40UJCQmzZsmW2ZcsWt3MTGRlpXbt25fzEo6FDh1rNmjWtXr16dvnyZWf5zp07zd/f3+rVq2enT5+Oxxo+Xv7qmqBkyZKWNWtW27Rpk9s1QWRkZFxUDWbOcZ8/f765XC5r2LChNWjQwK5du+aU+eqrryxVqlTWuHFjWrzjSHR0tEVHRzu9EhcvXmy+vr7m7+9v/fv3dysbGhpqAQEBVr9+fTt58mR8VBdmRuhGnDlx4oTb77Nnz7aePXva/Pnz7YcffnCWFytWzHLlymXr16+38PBwe/75561NmzZxXV2Y2SeffGLlypUzs1uBO3ny5DZ58mQzuxXsvvrqq3is3eMjdlf/GBs2bLCQkBCbPHmyBQQE2IQJE5x1K1eutOeee85++eWXuKzmY+/KlSvO/9955x17+umnzc/Pz6ZPn+4s/+OPP6xy5cr2wQcfxEcVYbe+pPLz87Ns2bJZWFiYmf3fa2zXrl0WGBhozz77LMM0POzXX391+/2TTz6x7t2726effmqHDx92lpcsWdJy5Mhha9eutQsXLtjzzz9vrVu3juvqPrZif6m4ZMkSc7lclilTJufzJWb9xo0bLW3atPb888/fcW7x4MS8V129etVZ9tNPP1lUVJStXLnS/P39rW7dunbp0iUz+7/zs3v3bnO5XNa4cWO3L7AQdwjdiBNvv/22vfLKK3bo0CEzuzUeKGXKlFa6dGlLkyaNNWzY0C3AlS5d2jJmzGi5c+e2/Pnz09IdT1avXm21a9e2adOmWfLkyd1auFevXm3NmjW748sUPFixL3hmzZplu3fvtqioKLty5Yq99NJL5u3tbX379nXKXL161Z5//nl79dVX7xrW8eDEPr4TJkywsmXL2qlTp8zM7Msvv7SnnnrKKlWq5LxGzpw5YzVq1LAyZcpw0RNH7vUaWLp0qSVOnNg6dOjgtJrGvNa2bt1qzz77LK8fD+ratavVrVvXDhw4YGa3vqRKmTKllS1b1tKkSWMNGjSw9evXO+XLlStnGTJksFy5cnFNEEfWrVtnP/30k5ndumYbP368mf1f8O7YseMdcyCsXr3aatSowWvHw3799Vdr0KCBHTt2zBYvXmzJkye377//3sxunR9fX1/r2LGj0xsh5r1t3759bl9oIW4RuhEnxo4da0WLFrUWLVrYihUr7KWXXrJt27aZ2a0uMRUrVrQ6deq4Be/p06fbjBkznK5nf9UFDf/NvT4gt2/fbtmzZzcvLy8bMWKEs/zKlStWo0YNa9q06R1da/HgxD4vZ8+eNZfLZc8//7zt37/fzMyWLVtmZcuWtRIlSthnn31mU6dOtapVq1r+/Pmd1wsXP54R+7iuXbvWhg8fbi6Xy+rVq2fnz583M7Px48db8eLFLVOmTFa6dGkrWrSoFS1a1AkMBG/Pin2Ovv/+e9u6datduHDB6VK+YMEC8/Hxsc6dO98RvO+2Dzw448ePt2LFilnz5s1t+fLlVrduXeeaYOnSpVaxYkWrXbu2W/CeOXOmzZo1i2uCOPDbb79ZxYoVrWTJktasWTNLlCiR7d2711kf09W8S5cudvbsWTPjtROXFi1aZOXLl7cSJUqYr6+vzZ0718zMrat54sSJrWPHjvd8b0PcI3TDo2K/yKdPn24lSpSwBg0aWK1atdy6YsZ8yL744ou2cePGO/bDxannxD5HkydPtgEDBtj//vc/Z9nHH39sLpfLOnXqZAsWLLDVq1dblSpV7KmnnnIuengz96wePXpYhw4dLH/+/JY4cWIrX768MyRj+fLl9vrrr1vKlCmtfPny1qhRI0JdHOrevbtlypTJ+vfvb/Xr17fAwECrUqWKhYeHm5nZjh07nNfV7NmznXNCYPCs22cpz5Ytm/n7+1v27NmtefPmdvToUTO7Fbx9fX3t7bffdhujCs+4vedOiRIlrH79+lazZk238fXLly+3SpUqWZ06dWzDhg137If3Ns/76quvLEOGDObr62tLliwxs1tj6WOCXUzw7tatG3MgxIFJkyZZ9+7dnd/79etnLpfLChUq5LRex4zzNrsVvJMlS2bNmzdnDoQEgtANj7o9jE2aNMmyZ89uQUFBtm/fPrd1S5cutWeeecbKly9/xzp4Xp8+fSwwMNDKly9vmTJlsoIFCzrBYdKkSVauXDlLkSKFlSlTxmrXrk2wiyNjxoyxwMBA+/bbb+3AgQO2detWCw4OttKlS7vNhXDq1Cm3lgVCneft2LHDUqdObevWrXOWbd++3dKnT29Vq1a1P//8867b8ZqJO2PGjLHUqVPbypUr7aeffrLhw4db5cqVrWbNms6400WLFpnL5bKxY8fGc20ffbdfE0ydOtVy5MhhadOmtT179ritW7FihVWpUsXKlSt3xzp4TsznyO7du61IkSJWsmRJK1++vBPsrl+/7ryHLViwgNdOHLh48aJ17drVsmfPbv369TOzW19a9erVy2rUqGG1atWynTt3mtmt8xfzOluwYIEFBQU5c1cgfhG6ESdi7lVrdqvlNG/evNa0aVNnPFeMBQsWWLt27eiWFAdiH+OoqChr0qSJ7dy50yIjI23v3r1WqFAhy507t9NV9uzZs3b06FH7448/nDd0gp3nNWvWzBo1auS27Pjx45YuXTqrUqWK7d27944LWXoexI2vvvrKgoKCnNlgY477+vXrzcfHxxo2bOiMeeQ9zfNu7yV17do1e/HFF61Pnz5uy+fPn28lSpSw999/31m2adMm3s88LPb7UuzZ++fMmWP58uWzxo0bO0NnYixatMjat2/P6ycO3H6MIyMj7eLFi7Z27VqrUqWKlS5d+q7jgbds2cJrJw789ttv1q9fP8uXL59bb8TPPvvMqlSpYrVq1bLQ0FBn+c6dOy0qKsouXrwYH9XFXRC64RGx37zXrVtn+fPntw8//NBZNmXKFCtSpIi1aNHCDh48+Lf7wIMV+9geOHDAvv32W3v++efdWk4PHjxohQsXtrx58zrBOzaCnWfFdBOrXbu21ahRw1ke0wX2ww8/NJfLZbVq1XJa7Dgncev333+3FClSuM0cb2Z28uRJy5Ejh/n4+NgLL7wQT7V7vAwePNjq1Knj1r3SzOz555+3Jk2a3FH+jTfesJIlS96xnPDgGXe7Jog9g/+0adOsSJEi1rx58zuC9932gQcr9rFdtWqVffnll7ZixQpnWcywsnLlyjnBu0GDBjZjxgynDK8dz4iOjnZ6FuzcudO6d+9uTzzxhNuXhvPnz7eqVatazZo1bfXq1da/f38LDAx0xtsjYSB044GL/eY9d+5ca9WqlaVOndqyZs3qdnE6efJkK1q0qLVu3dptgg7Ene7du1vq1KktX758ljRp0jtuAXbo0CErVqyYPfHEE3xb6mH3uqBctmyZJUuWzKZOneq2fPbs2dayZUsLCgqy119/PS6q+Ni617m5du2adenSxYoXL+5MZGN263Z6zZo1s1WrVlmKFCncvnCEZxw+fNi56I/dGtexY0fLmzev2xeKZrdmm69YsaLbOGJ4RuzXz5w5c5xrgpCQELfXxkcffWRFixa1li1b0p08DsX+kqpz586WMmVKy5o1q/n5+VmNGjVs9+7dZnYrjFevXt2eeOIJK1OmjGXKlIlZ5OPQggULrHz58vbcc89ZQECApUmTxu1+3IsWLbLnnnvOMmTIYFmzZrUdO3bEY21xN4RuPDC3X5j26tXL0qZNa+PHj7cPP/zQihcvbkWLFrUxY8Y4ZaZOnWoZM2Z06yoDz4l9jpYvX2558uSxxYsX26JFi6xUqVKWM2fOO7qP7du3z5o0acI4VA+KfV5+/vlnO3DggBMgIiIirGvXrhYSEmITJkyw69evW1hYmNWsWdMmT55sS5cutaRJk/LFlYfEPjcff/yxDRw40Dp06ODcBuzQoUPWuHFjy5Ejh3Xu3NmmTZtmlSpVstKlS1tERISVKFHCevToEV/Vf+Td3rK9ePFiS5s2rc2fP9/MbnWRzZkzp5UsWdJ27dpl58+ft0uXLlnFihWtfv368VXtx8LdrgmeeOIJmzhxok2YMMFKlixpRYsWtVGjRjllpk2bZpkyZbKhQ4fGdXUfS7FfOz/99JPlzZvXdu3aZadOnbLvv//ecufObeXKlXNuHRYaGmpjxoyxd955x/mM4trAM2If171791qyZMls4sSJdubMGTt8+LC1bdvWcuXK5Ra8jx49avv27XOGPCFhIXTjgbh06ZLb70eOHLGcOXPa559/7iz78ccf7Y033rB8+fK53e958eLFvGnHsWnTptmAAQNs8ODBzrI//vjDnn76acuVK9c97+PIeXrwYl+Y9u3b13LlymXp0qWzXLly2cKFCy0yMtJOnjxp7777rvn6+tqTTz5pmTJlsgIFCtjNmzftq6++sqxZs3K/dA/r0aOHBQcHW506daxs2bKWIUMGW7p0qZnd+qJk9OjRFhISYsWLF7fq1as7s8VWrFjRCRB0/3/wYre0nTt3zo4ePWqvv/66FShQwObNm2dmt97bChQoYNmzZ7eQkBArVqyYFShQwNmW8/LgRUREuP3+888/W65cuWzBggXOsiNHjljjxo0tb968br3glixZwmdNHBsxYoS98sor9sYbb1hUVJTzuRQWFmaZMmW6Z28qztODN2LEiDt64Hz22WeWM2dOt9fVsWPHrFWrVpYqVSobOXJkXFcT94HQjf+sZcuW1qFDB7dlZ8+etSeffNI++ugjt+VHjx61jBkzWvbs2W3cuHFu63jz9pyYi8qYf/Ply2cul8saNWrkFvr+/PNPK1WqlOXLl++OSe7gWQMGDLD06dPb4sWLLTIy0ipUqGA5cuSwiRMnOuO4Dx8+bNOnT7dFixY5rQxdu3a1p59+2v7444/4rP4jbeLEiZYxY0any+uGDRvM5XJZUFCQLVy40HldXbt2ze22U926dbPg4GA7cuRIfFT7kbdw4UKbM2eOmZm1b9/eSpcubWa3Zl1u2rSp5cmTx2nxjo6Otk8//dQ++OADmzp1Kvd69qDWrVtb27Zt3Zb9+eefljlzZps8ebLb8l9//dUyZ85sWbNmdesFZ8Y1QVy5ePGivf3225Y8eXLnNWRmdvXqVTO7NV44KCjIjh8/zjnxsJ9++snKlSt3x3CYjRs3WsaMGZ172cfYt2+fBQQEmJ+fn1sjChImQjf+k6ioKFu2bJnTYhDTuvP7779byZIlrX379nblyhW3LoCvvvqqlS1b1qpUqWKrV6+Ot7o/jmLfS7NGjRqWJk0aW7dunduF57lz5yxbtmzWoEGD+KjiYyN261poaKiVKlXKmbhmzZo15u/vbyVLlrRUqVLZxIkT7wjVhw8ftjZt2lhAQABdyx+w2BeWkZGRNmDAAJs2bZqZmX3xxRfm7+9vs2bNsnr16lm6dOls0aJFbnMe7Nixw9q2bWsZMmRwxkPiwWvWrJm5XC6rWbOmBQYG2nfffees27NnjxO8Y1q8b0eAePCioqJsxYoVzjVBTHA7ffq0lSpVytq0aWOXL192uyaoX7++c02wcuXKeKv74+Juc1QcP37cue/z7bf/WrhwoeXKlYt7cceBmzdvOp8lW7ZscXqRfv/995YvXz7r0KGDW9fxo0ePWq1atWzw4MF29OjR+Kgy/gVCN+7b7V3ypk+fbuXLl3dmuv7ss8/M5XLZkCFDnPs9X7161V599VWbNm2aFShQwDp37hzX1X5sTZo0yRo2bOgWAkqXLm0hISG2adMmtwvQiIgILkg9KPZFT3R0tJ07d85mzZplN27csI0bN1ratGltypQpZnbrHOXKlcuGDRvmfBhHRkbaZ599Zm+88YZb0MB/F/vvfs2aNXbjxg3btWuXnTx50n744QfLkyePM+vyli1bzOVymZeXl9vtqq5du2YLFy7kIigO5M+f3xIlSnTXeUH27NljzZo1s/z589vs2bPjoXaPl9uvCWbMmGFlypRxvjD8/PPPzeVy2YABA+zChQtmduu18uqrr9r06dOtYMGC1r59+ziv9+Mk9mfP4cOH7ZtvvrE///zTbt68aVevXrUePXqYt7e3DR8+3H7++Wc7duyYVatWzSpWrMjs8R4W+/Vz6tQpq1SpkuXIkcMJ3nPmzLFkyZJZu3btbP369Xb69Gnr2bOnVa1alZ5uDwlCNx6I6Ohomzp1qhUvXtxeeOEF+/PPP83s1gzl3t7e9txzz1nDhg2tdOnSli9fPjMza9u2rVWoUIFwF0emTp1q2bJls7Zt27rNDBsTvDdv3nzHueDcPHjr16+3sLAwMzPr2bOn9e7d28zMec00aNDA2rVr5xz7+vXrW4YMGaxBgwZuH8rXr1+/Yy4F/DdLly61MmXKmNmtWXzz5cvnnBczsy+//NKKFy9uP//8s5nd6vL3zjvvWP/+/Z3eIowPjhuRkZF27do1e/755+2ll16ypEmT2uzZs52W1Rh79uyxF154gZ478WDatGlWokQJe+6555xbF02bNs0SJUpkNWvWtAYNGrhdE3To0MHKly9Pl38PuH3CwXfeecfy5Mlj6dKls2LFitmbb75pp0+ftj///NN69epl3t7eliJFCmvfvr1VrVrVeV0RvD1v9+7d1qpVK1uwYIGVLl3aChcu7Hzh/umnn1qRIkUsKCjIsmXLZqlTp6Y31UPES8B9iI6Odvvd5XKpcePG6tKli8LCwvTGG2/o/PnzatWqlVauXKmQkBBdvnxZhQoV0u7duyVJv/32m/LkySMvL/4MHyQzu+P8SFKLFi00YMAArVu3TpMnT9bevXslSd98840yZsyoatWqaf/+/W7beHt7x0WVHxsRERF64403VKdOHbVs2VITJkxQ/fr1JUmpUqVSVFSUzp49q2TJksnlckmSvLy89OWXX2r27NlyuVwyM0mSj4+PkiVLFm/P5VH0xBNP6JdfflHOnDk1ffp0ff7550qVKpVzzMPCwnT48GH98ccfOn78uEaMGKGLFy+qX79+SpQokW7evOmcNzx4sd/XEidOLF9fXy1ZskSff/65XnvtNbVq1UqLFi1SZGSkUy5LliyaMWOGZs+eHR9Vfmzc7TMn5prgjz/+0BtvvKE///xTzZo10+rVq5UjRw5FRkaqSJEizjXBr7/+qty5c3NN4AGx35dGjhypjz76SB9++KF+//135c6dWwsXLtSRI0eUKlUqdejQQX369FGiRImUMWNGrV69Wn5+foqMjOTcxIGNGzcqNDRUISEhGjZsmKKjo1WhQgVdunRJ9evX14IFC7Rs2TKNGzdOe/fuVeHCheO7yvin4jn04yEU+5vO1atX27x582zevHlOq9u8efPs6aeftlq1atm5c+fM7P/GepvdGtvVq1cvS506tR08eDBuK/+Y2bx5sx0/ftxt2SeffGK5cuWyli1b2v79+53lrVu3pmXbQ9asWeN8U33p0iVLliyZJUuWzNauXXtH2caNG1vmzJmtVatWVqpUKcubN69zXmhl8IzYx/X11183l8tlJUuWdJbFfl1UqlTJfHx8LHPmzFawYEHuUxtHYp+jDRs22KJFi2z9+vV25coVZ3mLFi0sefLkNmPGDGes43PPPXfXfeDBiX1cV61aZZ9++qnNnTvXec9bsGCBlSpVymrUqOG0eMd+3YSFhXFN4CG9e/d2G6N98eJFe+6555zZ4lesWGEpUqRwJriLjIy0GzduWFhYmL377ruWIkWKOybExYMV0wMh9ntZzBwHZmbbtm2zQoUKWZEiRejd9pAjdOO+de/e3TJmzGiVKlWy4OBgq1Spkq1bt86ioqLsk08+sdKlS9sLL7zgBG+zW4G7W7duljVrVrcuzvjvevToYe+9957z+5YtW8zPz8/effdd++2339zKzpw503x8fOytt96y7du3u60jeD9Yc+bMMZfLZZMmTbILFy7Y8ePHLUWKFBYcHGzly5d3bvUVu+tfy5Yt7aWXXrJGjRo5F6cEBs+I/dr4+uuv7dtvv7XZs2dbSEiIVapUyTkvsbstL1++3O22RnSH9azYr42ePXta+vTprVChQpY4cWJ76623bNeuXc76Nm3aWKpUqSxXrlx8KRLHYq4JnnnmGcuQIYNVqFDB1qxZY9HR0TZnzhwrU6aMW1dzs1vXBD169OCawAPOnz9vFStWtPLly9v06dOd5RUrVrR9+/bZ6tWrLXny5M4tXCMjI23KlCm2efNmM7s1rrhv377mcrlsxowZ8fEUHhurVq2yRo0aOZMLHz9+3LJmzerMVbFp0yYrUaKEZcuW7Y7bieHhQejGffnoo48sffr0tnPnTjMzGz9+vHl7ezszj968edPmzp1r2bJls+7du7tt+9tvv7nNvoj/7o8//rB69epZqVKlbPTo0c7yIUOGWObMma1v375u93GOioqynDlzWooUKWzEiBHxUOPHS+/evS1x4sRu96I9e/asZcuWzcqUKXPHlyK3I9R5xoYNG+zZZ5+1LVu2WMeOHc3lcjkT0mzdutUyZ85slSpVctvm888/d+u5w5dUnhX7+L7//vuWIUMG27p1q5nden/z9va2Ro0auQXv1atX2/Lly/lSJA7FXBPEnIdJkyaZt7e3c0eGqKgo++yzzyxHjhzWtWtXt21PnjzJNcEDFvNF1enTp+3ll1+2ypUr29SpU83MrE6dOpYrVy4LCAhw7spgduvarFKlSm4t27/99psNGjTIDh8+HLdP4DESHR1tLVu2NJfLZalSpbJ+/frZL7/8YoMHD7aXX37ZvvvuO4uOjrZVq1ZZxYoV7ZdffonvKuM+EbpxX7p06eLcm3vevHkWEBDgBIpLly45s1+vXr2ai9I48uuvv1qbNm2sZMmSNmzYMGd5zIVq7OD9+++/W/v27W327NmcHw+KfWzfeecd8/LysokTJ1pERISZ3brdR7Zs2ax8+fJ29OhRi4yMtHr16tmgQYOc7ZiYy3N27txp5cqVs2zZsllgYKAdOnTIbf22bdssS5YsVqZMGdu6das9++yzVqFCBXodxIFhw4Y5XSmjoqLs999/t4YNGzqzkH/++eeWMmVK69ChgwUEBNjLL79sO3bsuGM/vL/Fja5duzozj3/22Wd3vSaIioqyNWvWcE7iQOxjvHXrVqtQoYIVL17cFi1aZAcPHrQSJUpYgQIFzOzWDPLnz5+3GjVqWLly5ZhQNQ7c/rm+fft2a9CggQ0ePNiZ2K5FixaWJ08eGzlypJndGpJBK/fDjdCNv3X7m8ONGzfslVdesbFjx1poaKglT57cJk6caGa33pw/+OCDO7oi8abtWTHn6Ndff7U333zTSpYsacOHD3fWv//++xYSEmINGza0UaNGWfXq1a1KlSrOdpwfz4l9bHv16mWJEiWyiRMnOuMdjx07Zjly5LAMGTJYoUKFLFeuXHSJjQMxf/s9e/Y0Hx8fK1u2rG3YsOGOcvv27bMCBQpYrly5rGzZss654csQz9mwYYNlyZLFXn75ZWecY3h4uK1cudIuXLhgu3btssyZMzu3bhs+fLglTZrUateubd9//318Vv2xcPvfflRUlL366qs2atSoO64JoqKi7IMPPnBrUTXjMyeudOnSxWrXrm0lSpSwFClSWK5cuWzixIn26aefWsaMGS1nzpxWunRpZ5bsmPc3zo/nrV+/3ul9EBUVZe3atbNmzZpZRESETZgwwVq0aGEul8tcLpfTuwcPN0I3/rFRo0bZTz/9ZGZmU6ZMMT8/P/Py8rK5c+c6ZS5evGhVqlSxPn36xFc1HysxFz+xL4KOHj1qrVu3viN4T5s2zWrVqmUFChSw5557jvDgQX/VEtq9e3fz9vZ2C97Xrl2z9957z0aNGuV0haVLrGfFnKPPP//cvvjiC3vmmWesZs2atmzZsruW3bdvn7MN58azrly5YjNmzLASJUpYnTp1nNadmNfLwIEDrWbNmk5L+PDhw61q1ar26quv0gvBw2KHsZ9//tlOnz5tZrd6vPn5+ZnL5brjmuDZZ591bo2IuDNr1iwLDAy00NBQ++OPP+zkyZNWpUoVq1Chgk2fPt1OnDhhQ4YMsQEDBthHH33EcIw4dPPmTRsyZIi5XC57/fXXbcuWLRYdHW1FihSxgQMHmtmtLxrbtWtnGTJkcK698XAjdOMfuXbtmlWqVMmqVatmly5dsvPnz1uzZs0sODjYNm/ebFevXrWff/7ZqlevbkWLFuVNOw7Evrj87bff7OzZs3b+/HkzuzUJx5tvvmklSpRwC97nzp2zCxcuOEGb8/TgxT4vH3/8sfXs2dP69OljCxcudJbHBO+YydVuRyuDZ8Q+N7f/7W/bts0qVqxoNWvWdMahmtkdLXSEOs+K3cvjo48+shIlSljDhg3d7hPcrl07q1Klip08edKioqKsdu3atmDBAmc7ztGDN2HCBLeJznr27Gn58uWz1KlTW7du3WzJkiXWrVs3Cw4OdmaVP3LkCNcE8ahv375WpkwZi4qKcj7zT5w4YcWLF7fs2bO7fSbF4LMnbu3bt8+qVq1qpUuXto4dO9rKlSutdu3a9s033zhlYq7r8PBzmf3/G5ACsURHR99xP8Yvv/xSY8eOVZs2bfTyyy9ry5Ytmjx5sj777DNlypRJ/v7+Sp48ub766iv5+PgoKiqK+zx7iJk5993s37+/Fi9erMuXLytx4sQaOnSoXnjhBZ06dUrvvfee9u7dq1deeUVdunRx28fdzjEenG7dumnGjBl65plndOjQIUVFRal48eKaNWuWJKlnz54aM2aMhgwZojZt2ihJkiTxXONHW+y/90mTJmnv3r2KiIjQyy+/rKpVqyp58uTavn27evXqpUSJEunZZ5/V5s2btXPnTp06dYrXShyI/b42btw47dixQ998842OHTumevXqadq0aUqaNKmWLFmi+vXrK1++fIqIiJCPj4/27t2rRIkSue0DD8bRo0dVvnx51ahRQ927d9ehQ4f01ltv6cMPP9R3332nVatW6cknn1SRIkV08uRJTZgwQcHBwQoMDFSKFCm0YcMGrgniUMxr4H//+58+//xzbd68WUmSJNGNGzfk4+Oj9evXq3bt2sqSJYsGDx6s2rVr87qJR6dPn9aaNWs0atQo/fTTT0qbNq1ee+01DRo0KL6rhgeM0I2/NGbMGKVLl07169dXVFSUGjdurJ9//lnbtm2TJF26dEl79uzR77//rrRp06pcuXLy9vbWzZs3lShRoniu/aNv0KBBGjNmjCZOnKjr169ry5Ytmjp1qj744AO1bdtWx44d07Bhw7RmzRoNHjxY9erVi+8qPxbWrVunJk2aaN68eSpTpowuXryo+fPna8SIEapQoYImTZokSWrfvr327dunTZs2ccETR3r27Klp06apWbNm+uGHH3Tq1ClVqFBB7777rgICArRr1y6NHj1aP//8s1KmTKmlS5fKx8eHi9I4NHToUP3vf//Txx9/rNSpU2vx4sVau3atsmfPro8//ljJkiXT8uXLtWfPHrlcLvXo0UOJEiUi1HnQ3r171aJFC5UrV05eXl7KmzevmjdvLklasmSJxo0bp8DAQLVs2VLBwcE6dOiQnnjiCZUvX15eXl5cE8SDgwcPqlChQnr33XfVr18/Z/mKFSs0efJk5c+fX++99x5fKCYQN27cUI8ePfThhx8qMDBQR44cUYoUKeK7WniQ4quJHQnfd99950ziMGDAANu4caNduXLFsmfPbp06dbrndnRPihsRERFWpkwZ+/DDD92Wx4wT2rZtm5ndGnc3bNgwzosH3T4ufsGCBZYlSxZnDKrZrfFZI0aMsOLFi9uRI0fu2Jax9Z4R+7hOmzbNsmbNaqGhoWZmtmTJEvPy8rJ8+fJZ+/btLTw83MxuDcP4888/GYYRDy5evGhVq1a1oUOHOsuuXbtmEydOtJCQEHvttdfuOoMv58jzQkNDrVixYhYYGOh2a0qzW6+lypUrW506dZzPnhh89sSfGTNmmI+Pj3Xt2tV27NhhR44csZo1a1rPnj2dMgzHiH+xP6fWrl1rx44di8fawFP4eguO6Ohot98LFCig7t27K2XKlDpx4oQmTJigDh06qGfPntqxY4c2bNhw1/3Q0uAZt5+fS5cu6eeff5a/v7+kW9+Smpl69eqlatWqaeLEibp586ayZs2qbt26ydvbW1FRUfFR9UdeTAvojBkzNHHiRKVKlUpeXl7av3+/U8bf3181atTQ7t279csvv7hta7SiekzMcb106ZJSpEihRo0aqUiRIlq8eLEaN26s0aNHq2bNmpozZ44GDBig8PBwBQYGKlWqVHK5XIqOjqaFLg4lT55cN2/e1OHDh51lvr6+evPNN1WoUCF9+umnev7553Xt2jW37ThHnlekSBFNnz5dgYGBWrFihdv72/PPP6+3335bR44c0ZdffinpVjdniWuC+NSkSRN9+umn+vjjj/XSSy+pYsWK+v333zVw4EBJt84RLd3xL+Y6QJKqVKmizJkzx3ON4Am80uCIeeNdu3atDh48KEnq2rWr6tatq5CQEHXu3FnHjh3TO++8o8OHD+uzzz6748IHnhNzfj7++GNJUvr06fX0009rypQpOn/+vDNmTpJSpUol6c4LUS5+POfatWtasGCB1q1bp0KFCilx4sSaMmWKjh496pRJkSKF8ufPf8f4bQK3Z3366afq1q2bypUrp7Zt2+rUqVPq37+/evfurQ4dOqhjx47y9fXVggULNHXqVLdtuSD1nNu/SJSkmzdvqkSJEvr5558VGhrqVqZo0aKqXLmyChYsqMSJE8dlVfH/FShQQIsWLdIff/yhcePGOdcKklSzZk1NnjzZGYvK+1rCULduXe3Zs0eLFi3SJ598op07d8rHx0c3b97kHCUgnItHH1cTcJiZjh07phdffFE9evTQ8OHDlSZNGuXLl08///yzChcurLVr16pr16564okn9OOPP8rX1ze+q/1YCQsLU7du3TR06FBJUuPGjSVJb7/9tq5cueKMazx16pTSpEkTn1V9rJiZ/Pz8NGTIEK1atUoHDx7Uxx9/rC+//FK9evXS5MmTtXnzZrVo0UKJEiVSqVKl4rvKjzS7baqSH3/8UTt27FBERITSpk2rH374QREREapRo4Yk6cyZMypbtqz69Olzx4SD8IzYE9t9/fXX2rJli3744QclSpRIbdu21e+//67evXtry5Ytun79uq5cuaLQ0FDVrFlTI0eOlJeX111DOzyvYMGCmjZtmkJDQ/XBBx/o0KFDzrrSpUvTqyoBCg4OVvHixVWxYkXn/NA7BIhbTKSGOxw4cEBffPGFPv74Y+XLl09dunRRkyZN1KBBAw0ePFiS9MMPPyhHjhzy8vKia2wcunbtmjp37qyzZ89q4cKFunnzpiZOnKg5c+bo1KlTevrpp3X06FFduXJF+/bt40PVQ+72N29mioyMVNu2bRUVFaWZM2dq48aNGj58uPbt26dUqVIpKChIK1asYCZfD4p9bs6dO+f0+ihRooQCAgK0du1ahYaGqlGjRmrSpIlq166tbt26KU2aNJo+fbpcLhfnJg716NFDU6ZMUUBAgM6dO6ePPvpIr776qo4fP64XXnhBXl5eunz5spIlS6arV6/qwIEDzFKeQOzZs0etW7dW5syZNWzYMIWEhMR3lQAgwSJ0w03MhczVq1d1/PhxNWnSRClTppTL5VJoaKjmzJmjZ5991inPbac8517Hdt++fSpRooSmTZumRo0aKSoqSvv27dMXX3yhP/74Q0FBQXr33XeVKFEiZoz1sHHjxsnb21uNGjVyxtbPnj1bb775pr766isVL15c4eHhioyM1OXLl5UlSxa5XC7OSxwYMmSIvvnmG7Vp00bPPfecDh8+rBdffFFvvvmm2rVrpw4dOmj16tW6cuWKMmXKpC1btjBLeRyIfXy/++47vfLKK/r444/lcrm0ePFivf/++5o4caJatWqls2fP6ptvvtH+/fuVIkUKtWvXjlnKE5gdO3Zo0qRJ+uijj7gWAIC/QOjG3xo2bJi2bt2qJUuWqG/fvurfv398V+mxsnHjRmXJkkVZsmRxlnXu3Fk//fSTpk6dqvTp0991Oy5MPevKlSvq3bu3Jk6cqGeffVaFChXSe++9J+nW5DVhYWFauHChkidP7rYdX1R5XlRUlBo0aKCFCxcqWbJk6tChg15++WUtXLhQR48e1YgRIxQYGKiffvpJ4eHhTpdYvgyJO8OGDdPly5d18+ZNpwdVVFSUBg8erAEDBmjy5Mlq0aLFHdvxvpbwxHyRwnsbANwbVxe4p5iLm+7du+vEiROqWbOmmjVrFt/Veqx8//33qly5sipVqqSnnnpKgwYNUrJkyVSnTh01bNhQR48eVfr06XXjxg35+Pi4bcuFqWclTZpUo0ePVtu2bTV9+nQtXLhQn376qdq2bauMGTPq/PnzOnbsmPLnz++2HRelnuft7a02bdooSZIkevrppzV//nz9+eefOn/+vHbs2KEvvvhCbdu21VNPPeVswxjHuHP16lXt379fc+bM0csvvyzpVnDz9vZW7969JUlt27Z1hmvExvtawhMz8zLvbQBwb7R04y/draslrUFx68CBA9q0aZNGjx6txIkTq06dOnr77bfVrVs3/fLLL1q/fj0XovHs5s2bunnzpnr16qWjR49q48aNioiI0P/+9z917949vqv32Bg9erTMTF26dFF0dLRatGghl8ulSZMm6dNPP9XXX3+tadOmSbrVtfn2L0TgGXdrAT179qwGDx6siRMnasmSJapWrZpbi2n37t21fft2bd68me7+AICHHqH7MXK3C59/0h3s9uDNmMe4E/tYm5kGDhyob7/9Vt98842KFi2q7du3a9WqVSpfvnw81/TxFvs8HT16VJs2bdLnn3+uL774gi+o4siNGzc0bNgw9evXT6+88oqaN2+uSpUqqUSJEqpfv766deumGzduqEePHjp48KBWrFjBl1VxIPZnzC+//KILFy4oS5YsCgwMVFRUlFq1aqW5c+dq+fLleuaZZ9yCt8vl4j72AIBHAqH7MRH7wmfjxo2KiopS1qxZ/3a20dvDBLOTxo/Y4xgvX76s+fPna8KECUqWLBkt3QnEvYIBPUPi1sGDB9WnTx+dPHlS+fLl0zPPPKPFixerV69eKlKkiKT/O1eMD/as2K+J3r17a9WqVTpy5IhKlSqlrFmzaty4cbpy5YrefvttzZ49W8uWLVPlypXvuQ8AAB5WhO7HTK9evfThhx8qbdq0OnPmjGbNmqWXXnrprmVjX+xMmDBBS5Ys0fTp0xUcHByXVcb/d/vF56lTp5Q+fXrCQwJFWIg/f/zxh77++msNGTJE3333nVKkSKFOnTrp3XffdcpwfuLO//73P40cOVLz5s1TsWLF9NZbb2nJkiVau3atSpYsqfPnz6tHjx766KOPtHPnThUtWjS+qwwAwAPFrBePuJjvVMxM33//vdatW6e1a9dqyZIlateunerVq6cZM2bcdbuYC9IpU6aoe/fuat68OYE7HsXuZi5JwcHBTjdMAnfCQ6CLP2nSpNGLL76onTt3qlu3brpy5YrWr1/vVobz43lmpvDwcG3atEljxoxR5cqV9e2332rx4sUaNWqUSpYsqevXryswMFAjRozQkCFDVLBgwfiuNgAADxx9Hh9hsbuUX716VdHR0apevbqefvppSdLQoUPl6+urli1byuVyqUmTJpLcA/fkyZPVvXt3ffzxx/dsEcf9ud8x9rcjPAB3inkfGzRokF544QWn9ZQW7rjjcrnk5+eniIgI5c6dW0uXLtVrr72mESNGqEWLFrp+/bo+/vhj5cqVS+XKlVPPnj0lMSQDAPDo4VPtERYT3vr166ctW7boxx9/VEhIiH7//Xfn3s4x99x+8803dfnyZbVt29a5IJ00aZJ69uyp6dOnE7gfsAc5xp4AAdwp9gRcJUqUkMQ9nj3tbl8a3rx5U15eXurVq5dCQ0M1bNgwvfnmm5Kk3377TQsWLHC+8I1B4AYAPGroXv4Iio6Odv7/0UcfafLkySpXrpyqVq2qLVu2aNasWYqIiHDK9O/fX23bttW8efOcrsufffaZevbsqY8++kh169aN8+fwqIu5MO3Vq5eef/55tWrVSk899ZQWLVp0z21uH2Pfpk0bnTp1Kk7qCzyMbv9CisDtObED948//qhz584pIiJCyZIl09ChQ7Vr1y4VLVpUbdq00c2bNxUeHq727dsrMjJSr776ajzXHgAAz+Lr5EdQzIXPrl27dODAAU2cOFEvvviiJCl37tzq0aOHEiVKpFatWsnf31+SNHLkSLdQlzhxYs2bN0/VqlWLnyfxiIo5xmamw4cPO2PsU6RIodmzZ6tevXqaMmWKmjZtetftpP8bYz9jxgzG2ANIEGI+d3r37q05c+YoceLEKl++vLp06aKyZcs6XcorVKjgbBMeHq6dO3fK29ubXggAgEcaofsRtX37dlWsWFGJEiVym5imW7dukqQePXrIy8tLzZo1U8qUKSXJmZTLy8uL7uQewBh7AI+ylStX6tNPP9XEiRO1Y8cOffvtt2rRooWmTZumZs2aqUiRIk6PqixZsqhFixZKlCgRY7gBAI88PuUeEbFbUF0ul0qWLKlRo0apV69e2rRpkypXrqzMmTNLuhW8vby81LVrV6VPn14NGjRw9vNvJ/HCP8cYewCPktvHcN+4cUNNmjRRjRo1VKNGDa1atUpjx45V06ZNNWXKFBUqVEj58+d3C9hRUVEEbgDAI4+E9QiIjo52gtm1a9d09epVSVKbNm00YMAArVmzRh999JFOnDjhbPP2229r9uzZeuWVV+Klzo8TxtgDeBTFBO5x48apS5cumjlzpiIjI5311atXV4cOHZQ6dWq1adNGe/fuvSNg06UcAPA4cFnMVT0eSrFbGsaMGaN169bpypUrSp8+vWbMmKHEiRNrzJgxGjFihJo2barWrVsrY8aMbvuga1/c2LVrl2bPnq0KFSo4Y+yHDx+uHj16aNiwYW5j7CX3buWLFi1SsmTJGGMPIN7F/tzp06ePJkyYoMKFC+v48eM6c+aMtm/frty5czvl16xZoz59+qhgwYKaMmVKfFUbAIB4Q9J6yMWeBXvGjBl65513lClTJr322msKCwvT0qVL1alTJ7lcLo0aNUoRERHq3bu30qZN6+yDwO15jLEH8KiI+dz5/fffdf36da1cuVIlSpTQzp071bdvX1WtWlVr1qxxgnfVqlUVEBCg4sWLx2e1AQCIN3QvfwQcPnxYy5Yt09y5c9WhQwf5+fnJx8dHr7zyipImTSpJ6tixo5o1a6bjx4/riSeeiOcaP/piOpDE/Bszxt7b21ubNm3S8ePHnbLdunXTsGHD1LVrV61cudJtP4yxB5AQLViwQBkyZNCSJUvk6+srSSpevLiGDBmip556StWqVdOPP/7olC9ZsqS8vLzchtsAAPC44Ir+IRRz0RIT6E6fPq3Lly+rcuXKWrp0qV599VUNHz5cb775pi5evKgZM2ZIujWB1xdffOFMuAbPYIw9gEddyZIl9frrr+vIkSP6888/neWFCxfWoEGDVLBgQRUoUEC//vqr23Z8kQgAeBzRr/ghc/78eQUGBkqStm7dqjJlyih37tzKnDmz+vfvr1GjRmnkyJFq1aqVJOnHH3/U/PnzlT9/fhUvXtxthnM8eH83xr5jx44yM40YMUKS3MbYv/baa5IYYw8gYbl9lnJJevLJJzV48GBFRETo5Zdf1qZNm1SgQAFJUqFChfTuu+8qV65cypAhQ3xUGQCABIWJ1B4iS5cu1fz58zVs2DD973//07hx43T69Gm5XC41b95cq1atUocOHTR8+HBJt1pZ69atq8SJE+vzzz+nhSEO3W2MfenSpbV06VIlTZpUH3zwgUaNGqU6dercMcYeABKK2F/Szp07V2FhYcqQIYPq1asn6VZPq5YtW+qbb77Rpk2blD9//jv2ERUVxSzlAIDHGs1pD4H3339fDRs2VKJEibRmzRrt27dPp06d0oEDB5zx2e+9956OHDmiPXv2qHfv3sqQIYMWLlyos2fPavfu3c5YOoK358UeY1+5cmWtXLnyrmPsL1y4oD179jDGHkCCFRO4+/btq5EjR6po0aLasmWLVq1apUGDBilDhgyaOnWqWrVqpWeeeUarVq1S4cKF3fZB4AYAPO5IYAncjz/+qD179igoKEg1atRQ7dq1dfDgQZUpU0ZJkiRxyj311FP6+OOPlTdvXi1atEjLli1T9uzZtWfPHvn4+OjmzZsEbg9hjD2AR03s97VLly7pu+++07p16/TVV19p27Ztmj9/vjp16qQTJ04oKChIU6dOVc6cOfXOO+/Ec80BAEh4aOlO4HLmzKlPP/1ULpdLq1evVnR0tObMmaMePXpowIABevvtt1WgQAGZmYoWLaoiRYro+vXr8vb2dsYFM0bYcxhjD+BRE7tX1M8//6wrV64oc+bMypEjh7y9vVWyZElt2bJFZcuWlcvl0siRI5UpUyYtWbJEAQEB8Vx7AAASHpo+HwIul0u///67OnXqpOjoaNWpU0ezZ8/Whg0bNHLkSB08eNAJbcuXL5evr68Tss2MwO0hS5cuVYcOHfT777+rY8eOKleunM6ePStvb2/5+/tr6NChat26tRO4r127pr59+8rPz09FixZ19kPgBpCQxATubt26qVq1aipXrpw+/vhj7dq1yylTuHBhbdmyRatXr1aTJk105swZBQYGclswAADugonUHiK7d+9Wq1atVLBgQY0YMUKHDh1Sw4YNVaZMGdWpU0ezZs3Srl279Pvvv0sizHlKzBj7/fv3q0mTJgoKCtKpU6e0efNm5c2bV5L03XffqUGDBkqfPr1Klix5xxh7Hx8fxtgDSFBi97pZvny53n77bfXv3183b95Ujx49VKJECfXq1UslSpRwttmxY4d69eqltWvX8n4GAMA98An5EClSpIimTp2q3bt3q2vXrsqbN68+++wz/fTTTxo0aJAuXbqkEydOELY9iDH2AB5VMZ8dK1eu1JIlS9SiRQvVr19fjRo10hdffKGDBw9q2LBh2rFjh7NNiRIltH79elq4AQD4C7R0P4T27NmjZs2aqWjRovrf//6npEmTKiwsTFmyZJGXlxdjuD0spjVo9erVWrBggapUqaIePXqoUqVKbmPsY8ZrM8YewMPi1KlTqlmzpg4fPqymTZtq4sSJzrodO3aoUaNGKly4sNq3b6+yZcvGY00BAHh40NT2ECpcuLCmT5+uvXv36s0339SZM2eUNWtWp6WBQOdZjLEH8KiI+d495t/g4GBNmzZNpUuX1rZt27R06VKnbIkSJTRnzhytXLlSq1atipf6AgDwMKKl+yG2Y8cOTZo0SR999BFdleMBY+wBPMxizysRHh6upEmTKjo6Wr6+vtq+fbt69OihFClSqE2bNqpZs6az3ffff6+cOXNy/20AAP4hQvdDLqYbM5NyxY+Yrv5FihTRiBEj9MMPP6hDhw6KjIxUYGCg1q5dKx8fH24LBiBBif2Z8f7772v16tW6cuWKgoKCNGbMGIWEhGjHjh3q3r27UqRIobZt26p69epu+4iKiiJ4AwDwDxC6HwEEuvjFGHsAD6s+ffpo4sSJ6t+/v86cOaOvv/5a+/bt07Jly1S6dGlt3bpVffr00ZUrVzR69Gg9/fTT8V1lAAAeOoRu4AHYs2ePWrZsqSxZsmjEiBHKkiWLJNEDAUCC9dtvv6lmzZrq06ePXnnlFUnSxYsX1bp1a61Zs0aHDx9WmjRptGXLFn322WcaO3Ys72cAANwHPj2BB6Bw4cKaMGGC/P399eSTTzrLuUAFkFDc/h37xYsXdfToUWXIkEHSrS8JU6RIodGjRys4OFjTp09XdHS0ypYtqw8//JDbggEAcJ9IBMADUqJECU2bNo0LUwAJTnR0tDMM6Y8//pAk5cmTR3nz5tXs2bN18+ZNeXl5ycwUGBioZMmSKTw8/I4vDvkiEQCAf49PT+ABirk3NxemABKK2MNchg0bpoEDB2rr1q2SpOeee0779u3T2LFjJf3fXRa8vLwUEBAQPxUGAOARw5huAAAeAz169NC0adM0ceJEPf3008qUKZMiIiLUs2dPffvtt/L391eZMmW0adMmXbhwQXv37mUSSAAAHgBCNwAAj7gNGzaoZcuW+uSTT1S6dGlJ/9cCfunSJS1dulSLFi3S9evXlSFDBo0dO1aJEiXitmAAADwAfIUNAMAj7vTp0/Lx8VG2bNmcZTFdyZMnT64GDRqoQYMGbrc45HaHAAA8GAw8BQDgERUVFSVJOnv2rK5du6bAwEBJ0o0bN5zQvXz5cm3ZskWS3EI2gRsAgAeD0A0AwCPi9jsnxHQNf/nll3XhwgW1a9dOkuTj4yNJunTpkiZNmqR9+/bFbUUBAHiMMKYbAIBHQOxZymfOnKm9e/fq6tWrqlSpkurXr69Zs2apQ4cOql69ut566y1duXJFY8eO1cmTJ7V7925atgEA8BA+YQEAeATEBO7u3bvr008/VfXq1ZUqVSq99tprCgsLU7NmzZQxY0a1b99er7/+upInT66QkBCFhoYyaRoAAB5E6AYA4BGxZs0azZs3T/Pnz1epUqW0atUqDR8+XAEBAfL399czzzyjPXv26Pjx4/L19dWTTz4pl8vFpGkAAHgQY7oBAHhI3T6G+/Tp08qXL59KlSqlzz//XK+88oomTZqkpk2b6sKFC9q1a5d8fX2VM2dOZc6cWS6XS9HR0QRuAAA8iNANAMBDyMycLuWTJk3Snj17FBAQoMjISM2cOVNNmzbV8OHD1apVK0nSpk2bNGrUKJ0+fdptPzH7AAAAnsEnLQAAD5no6Gjnll9jx47VwIEDFRUVpYwZM+rSpUt688039c477+jNN9+UJF29elVTp05V0qRJlTZt2visOgAAjx36kwEA8JCJaZ3ev3+/Dh06pLFjx6pYsWKSpIYNG+rEiRP6/ffftXr1arlcLo0cOVJhYWFavHixXC6XzMwJ7QAAwLMI3QAAPIRWrlyp+vXry9fXVzVr1nSWd+jQQdeuXdO6des0YcIElSxZUqlTp9auXbuYpRwAgHjAfboBAHhIdevWTWPGjFGbNm3Ur18/pU6d2ll3+fJlnTx5Uk888YRSpkzJLOUAAMQTPnkBAHjIxLRWDx8+XDdv3tSiRYuUK1cuNWzYUClTppQkJUuWTDlz5nS2YZZyAADiB5++AAA8ZLy9vZ3gPXr0aF2/fl2jRo2Sy+XSa6+95gTv2JilHACA+EH3cgAAHlKxx2e3a9dOa9asUYsWLfTWW28pefLk8Vw7AAAgEboBAEiQbp/w7F4zjscu16hRI12/fl3z5s1jdnIAABIIQjcAAAlMdHS00x18y5YtKly4sJIlS3bP8rGDd8y23BYMAICEgQFeAAAkICtXrlTFihUlSV26dFGXLl107dq1v9zG29tbN27ckPR/Y7ejoqI8Wk8AAPDPMJEaAAAJRHR0tKKjo3Xq1CnlzJlTZ8+e1a5du9xuBXY3ZiYfHx9J0vz581W1atW7TqYGAADiHi3dAAAkEF5eXqpVq5ZKlCihI0eOKE+ePMqWLZsk6ebNm3fdJnY38qlTp6p+/frauXNnnNUZAAD8NUI3AADxLGZ6FTNTVFSUatWqpQ8//FDh4eGqUqWKJClRokS6fv2623ZRUVFO4J48ebK6deumzz//XM8++2zcPgEAAHBPTKQGAEA8ij1pWmRkpCTJ19dX0dHRWrFihbp27aqMGTNq3bp1zjbLly9XhQoVnNuCTZ48Wd27d9f06dNVt27duH8SAADgnmjpBgAgHnz99deS/m/is0GDBql27doqV66cFi1aJC8vL9WoUUOjRo3SyZMnVa5cOX3//feqWrWqxo0bp6RJk0qSxo4dq169ehG4AQBIoAjdAADEsdmzZ6tChQqaO3euJGn48OH68MMPVaRIEWXLlk2vvPKK3n//fblcLlWrVk3jx49XeHi4qlevritXrmjp0qXy8vLSkSNHNG7cOE2YMIHADQBAAsXs5QAAxLFGjRrp0KFDatasmRInTqzLly9r9uzZzvjtsmXLqn379oqOjlb37t1VuXJl7dy5U/v371eRIkXk5eWlqKgoZcqUSRs3blSGDBni+RkBAIB7IXQDABAPhgwZov/X3p1H13Tufxz/7JwgxJREmzThpjWFuDG3tHWJeWiVtoZqpIbEJQiHipBqiSEl1mpjVmkNl1JBbkoQ9NZwca/QKk1paVV6ETRRKUFIcn5/WDm/HLSlMkjyfq111nL2fvY+z84/9mc/z/PdWVlZeu211+Ts7KyWLVta940YMUKSNGrUKNnZ2WnkyJFydHRU8+bNJd0uoGYymWQymQjcAAA84gjdAAAUkrxF0yQpMjJSVatW1aRJk3T8+HF16dLFum/EiBGys7PTiBEj5OHhof79+1v3mUymQu03AAD48wjdAAAUktzA/cknn6hhw4by9vZWWFiYrly5otDQULm6uur111+3tg8KCpKrq6teeumlouoyAAB4SLwyDACAApZ3hPv8+fNyd3dX3759NWXKFHl5eUmSQkND9f7772v58uU2wTtXVlaW7O15Vg4AQHHD/94AABQgi8ViDdxvvfWWsrKyVLt2ba1fv15Xr17Ve++9pzp16lirlQcGBuratWsKDAy0OQ+BGwCA4omRbgAACsF7772nGTNmaNOmTXJwcFBqaqr69u2rZ599VlFRUapbt66k21PKjx07pt27dxdxjwEAQH4gdAMAkM+2bNmitm3bqnz58tZtfn5+qlChgqKjo63bkpKS1KpVK7Vr104RERGqV6+epLsLrgEAgOKL/9EBAMhH4eHhWrJkiRwcHKzbbt26pYsXL+rXX3+1bsvMzNRf//pXTZw4UXFxcZoyZYrOnz8vSTIMQzwTBwCgZCB0AwCQjyZPnqz169fLMAwdOXJEv/76q8qUKaPBgwcrPj5e69atkySVK1dOkuTi4iJ/f39t3bpVM2bMkHQ7dBuGUWTXAAAA8g+hGwCAfJKTkyPpdtGzuLg4derUSevWrVNGRoa6deumAQMGaMKECVqzZo0sFosuXbqkuLg4dezYUYsXL9aKFSv07bffFvFVAACA/EToBgAgn+Rdh92zZ0+1adNG77//vtavX6+KFSsqJCREPXr00BtvvKG6deuqadOmSk5OVr9+/VS1alW5urrKxcWlCK8AAADkNwqpAQDwkO4sfHbr1i2VKVNGkvT666/r0KFDCgsLk5+fn8qUKaMvvvhCBw8eVJUqVdS7d2/Z29vrzTffVGJiojZu3CgnJ6eiuhQAAJDPCN0AADyEvIE7OjpaBw4c0PXr19W8eXONGTNGkuTv76/ExERNnDhRr7zyiipXrmw9/uTJk4qKitLHH3+sPXv2qGHDhkVyHQAAoGAwvRwAgIeQG7hDQ0MVHh6uKlWqqGHDhnrzzTetoXvlypV65plnNHv2bP3jH//QjRs3JEnXr1/XgQMHlJaWRuAGAKCEYqQbAICHtHfvXg0YMEArVqxQq1attG3bNnXv3l2LFi1SQECAtV3Xrl3l5OSkjz/+2Fqd/MaNG8rKylLFihWLqvsAAKAA2Rd1BwAAKG4sFovNK73Onz8vd3d3tWrVSrGxsRowYIDmzZungIAApaen69ChQ2rfvr22bt2qnJwc63u4DcOweZ83AAAoeZheDgDAA8oN3Onp6ZKkatWqyTAMLVy4UAMHDtTs2bM1dOhQSdKBAwe0cOFCnTp1StLt6ei5wRsAAJR8hG4AAP6EtWvXavTo0UpPT5eHh4dycnI0duxYhYSEaNiwYZJuTx2fO3euHB0d9dRTT1mPzVvpHAAAlGxMLwcA4D7cOaX8p59+0hdffKEzZ86oQYMGGjJkiE6fPq1Tp05pzZo1Kl++vBYsWKALFy4oLi7OZko5AAAoPSikBgDAH8gbllNTU1WtWjVJUrt27ZSRkaEDBw5Ikj788ENt3rxZO3bsULNmzfT4449r9erVKlOmjLKzs2UymYrsGgAAQNEgdAMAcJ9mzJihzz77TEFBQerTp4+Sk5P10ksvqWfPngoPD5d0e0p5amqqnJycVKFCBRmGoaysLNnbM7kMAIDSiEVlAADcB4vFolOnTunf//63AgICNGrUKKWmpqpHjx46efKkDh8+LEkqW7asqlevLkdHR+uUcgI3AAClF3cBAADcB8MwNHjwYN26dUu+vr5at26dFi1apKtXr2rfvn1q1qyZmjRpcleRNNZwAwBQujHSDQDA73j//fc1efJk5eTk6Pnnn1flypWVkJCg+Ph4derUSdWqVdPZs2cVEhKigwcPFnV3AQDAI4aRbgAAfsP169dlZ2enyMhIHTlyRIMHD9b8+fPVunVrhYeHa+rUqerTp49cXFx06NAhNW3atKi7DAAAHjEUUgMA4A8kJydrwoQJOn36tGrUqKEePXron//8p8aNG6eWLVvatKVoGgAAyIvQDQDA78h91devv/6qvXv3KjIyUnv37lXFihU1bNgwzZw509qW93ADAIA7saYbAIDfYTKZZLFYVLlyZXXr1k27du3StGnTZGdnp/379yvvs2sCNwAAuBMj3QAA3KecnBxrdfKvvvpKDRs2lJ2dHSPcAADgNxG6AQDQ/U8Nzxu8pf+ffg4AAHAvTC8HAJRKOTk5Nt/vd6T6znYEbgAA8HsorwoAKHUsFot1tHrx4sU6evSovLy81KFDBzVo0OA3R73zbt+9e7datGghBweHQu07AAAoXhjpBgCUOrnBeerUqXr77bd16tQpffTRRxo6dKj27NkjwzB05+qrvIF78eLFatu2rY4dO1bofQcAAMULoRsAUGrcOaX83Llzio+PV0JCgubOnSt3d3cFBwdr9+7dNsE7b+D+4IMPFBYWpnXr1qlp06aFfg0AAKB4IXQDAEqFvAXQDh48qK+//lonT56Uo6OjJMnX11ejR4+Wl5eXRo8ebR3xzs7Otgnc48ePV3R0tF599dUiuxYAAFB8ELoBAKVCbuAeP368OnTooO7duysxMVFnzpyxtnn++edlNptVv3599e3bV1999ZW1UNqCBQsUFhampUuXErgBAMB9o5AaAKBEyzs1/KuvvlJcXJw2b96ss2fPKiYmRn379tWmTZvUunVrSdJzzz2nzMxM1alTRz4+PpKko0ePymw26+OPPyZwAwCAB8J7ugEApUJkZKTS09NlZ2enadOmSZK+++47RUREKD4+XrGxsWrTps1dx+W+h/v7779X7dq1C7vbAACgmGN6OQCgRMr7TDkzM1NJSUl699139e2331q3e3l5KSwsTN27d1fv3r21ffv2u86TO72cwA0AAP4MRroBACVaRkaGHB0dlZaWpoiICM2bN0+ffvqpunbtam1z4sQJjRs3TllZWdqyZUsR9hYAAJQ0hG4AQIkVFRWlDRs2aO3atXJ3d9fly5cVGhqq5cuXKz4+Xh07drS2/d///icPDw9rwTUAAID8wJ0FAKDEat++vZKSkhQUFKSUlBRVrVpVkZGRGjBggF566SV99tln1rY1atSQnZ3dXe/yBgAAeBiMdAMASoS87+HO+/348eNq3bq1WrRooejoaD3xxBNKT09XaGiolixZogMHDujpp58uwp4DAICSjNANAChRtm7dKl9fX5UvX976urBjx46pTZs2atmypRYvXiwPDw/98ssvio6O1tixY2Vvzxs0AQBAwSB0AwBKjB9//FG1atXS4MGDNW/ePJvgffDgQbVp00avvfaaJk+eLE9PT+txWVlZBG8AAFAgWNMNACi27nxu/NRTT2nz5s2KiYmR2WzW9evXZRiGdV/NmjW1fPlyzZ8/3+Y4AjcAACgo3GUAAIqlvGu4U1NT5eLiIsMw1LVrV61du1avvvqqpNsVzMuXL6/y5curY8eOWr16tRo0aFCUXQcAAKUI08sBAMXa1KlTtX37dmVlZclsNqt9+/Z67LHHtHXrVr3yyivy9fXVs88+q/379ys9PV379++XYRhMKQcAAIWC6eUAgGJr2bJlWrhwofz8/OTs7KwZM2YoKipKKSkp6tq1q/773//qypUr+vzzz1W2bFnt2bNHhmHIYrEQuAEAQKFgpBsAUGzc+VqwBQsWqGzZshoyZIgkacqUKdq4caM6d+6sESNGqHr16srIyJC9vb3Kli3LCDcAACh03HUAAIoFi8ViDdyffPKJUlNTlZiYqBdffNHaZsqUKZKkTZs2yc7OTsOGDVONGjVszkHgBgAAhYk7DwDAIy/vCHdISIiio6Pl5uamEydOKDk5Wc8//7w8PDwk3Q7eJpNJS5YsUY0aNTRs2DDreXIrmQMAABQW1nQDAB5peQP3yZMndeHCBX3++ec6cuSI5syZo5s3b2rSpEk6d+6c9Zi3335b4eHh1mnnAAAARYXQDQB4JG3ZskWSrIF7zZo1euGFF/TTTz+pVq1aKleunIKDg+Xn56eTJ08qLCxMKSkp1uMHDx4sk8mk7OzsIuk/AACAROgGADyCFi5cqOnTpysnJ8camm/cuKHHH39c33zzjU2QHjlypPr166cff/xRw4YNU1pams25TCZTofYdAAAgL6qXAwAeORcvXpSLi4tMJpOOHDmiRo0ayWKxKDY2VlOnTpWLi4tWr14tNzc36zGzZs3S6dOntWDBApsK5wAAAEWJ0A0AeGT961//UseOHbVkyRIFBgbKYrFo7dq1WrRokcqVK6eVK1fK1dXV2t5iscgwjLteLQYAAFBUuCMBADwy8j4HzsnJUYMGDTR27FiNHz9eS5culWEY6tu3r4KCgpSZmamBAwfarOM2DMPm1WIAAABFjbsSAMAjI/eVXu+9954SEhLk5uam0aNHa8iQITKbzTbBe/jw4UpOTlZkZOQ9zwEAAPAo4D3dAIBHzgcffKD+/furW7duqlGjhkaNGiVJMpvNkm5XJu/du7dcXFzUtm3bIuwpAADA7yN0AwCK1L3WX9evX1+pqanW7x4eHho1apQMw9Cbb76pjIwMBQcHq0OHDpKk7OxsqpQDAIBHEtPLAQBFKjdwHz58WGfPnpUk/e1vf9OxY8d08+ZNSbfXent4eCgoKEh9+vTRxo0bZbFYrGvACdwAAOBRRfVyAECRW7VqlXUE29vbW5cuXZIkzZ49W+7u7vL29lalSpUkSdeuXVP58uWtRdNYww0AAB5lhG4AQJHLzMzUzz//rKSkJF26dEkJCQlatWqV2rVrp3379ukvf/mLMjMzNX78eA0fPlySCNwAAKBYIHQDAArV/bxD+5dfftHTTz+tmTNnytvbWxcvXtR//vMfhYSEyN6eciQAAKD44M4FAFBo8gbuTz/9VN9++63c3NzUqFEjNW7cWJJ048YN2dnZqVy5cpIkb29veXt7y9fXVxJF0wAAQPFC6AYAFAqLxWIN3KGhoVq9erVq1aqlnJwcZWdna9KkSeratascHBzk4OCg+vXra//+/erVq5fNeQjcAACgOKF6OQCgUOSuv543b57Wrl2rmJgY7dq1Sy+//LIOHToks9ms2NhYa/tbt24pLS2tqLoLAACQL1jTDQAoNFeuXNHIkSP19NNPa+TIkdq0aZP8/f01fPhwffPNN0pKStLcuXP1wgsv6IcffpCnpydruAEAQLFG6AYAFJh7FU07efKkTCaTbty4oRdffFFms1mjRo3S8uXLNWTIEDk6OmrDhg1q3769JNZwAwCA4o3hAwBAgcgbuBMSEpSeni4fHx95e3tLkqKjo1W9enUFBARIkpycnNS9e3e1b9/eWjRNYg03AAAo3ljTDQAoELmBe+LEierVq5fefvttNWrUSPPnz9etW7dUpkwZff/99/ryyy918+ZNffTRR6pXr56GDx8uk8mk7OzsIr4CAACAh8dINwAgX1ksFhmGIYvFouTkZO3du1c7duyQl5eXli1bplGjRikjI0PPPPOMWrZsqZ49e8rZ2Vlly5ZVbGys9VhGuAEAQEnAmm4AQL7JO6X80qVLSktL09KlSzV9+nRriJ4zZ47Gjh2rqKgo+fj46PLlyzp//rwCAwNlb2/PGm4AAFCiELoBAPnurbfe0o4dO3TixAl5enoqJiZGXl5e1v1RUVEKDQ1VSEiIpk+fbt1O4AYAACUNa7oBAA8tJyfH+u9PPvlEy5Ytk7+/vwYNGqTvv/9eH374oZKTk61tzGaz3nnnHe3cuVN5n/0SuAEAQEnDSDcAIN/s3r1bMTExatGihd544w1J0sKFC/Xuu+/Kz89PQUFB8vT0tLbPu/7bMIyi6jYAAECBoZAaACBfnD9/XgEBAbpw4YLq1q1r3T58+HBZLBbNnDlTJpNJAQEBqlmzpiQRuAEAQInH9HIAQL5wc3NTbGys3N3dtXnzZn399dfWfSNGjFBYWJhmzZql7du32xxH4AYAACUZ08sBAPnqyJEjGjRokJo3b67Ro0erQYMG1n2xsbHq0aMHa7cBAECpQegGAOS7w4cPKzAwUM2aNZPZbJa3t7fNfqqUAwCA0oLQDQAoEIcPH9bQoUPl6empyMhIPfXUU0XdJQAAgELHmm4AQIFo0qSJ5s+fr0qVKtlULAcAAChNGOkGABSo3OrkOTk5srPjWS8AAChdCN0AgALHa8EAAEBpxZADAKDAEbgBAEBpRegGAAAAAKCAELoBAAAAACgghG4AAAAAAAoIoRsAAAAAgAJC6AYAAAAAoIAQugEAgCTJ19dXZrO5qLsBAECJQugGAKAYGThwoAzDuOvTpUuX+z7Hrl27ZBiGLl++bLM9NjZW06ZNs35/8sknFRUVlW99njlzps32uLg4XicHACjxCN0AABQzXbp0UUpKis1nzZo1D31eZ2dnVapUKR96eDcHBwfNmjVLv/zyS4GcHwCARxWhGwCAYqZcuXJyc3Oz+Tg5OVn3G4ahDz/8UC+//LIqVKigOnXqaOPGjZKk06dPq23btpIkJycnGYahgQMHSrKdXu7r66vk5GSNGTPGOpqekZGhypUra/369Tb9iYuLk6Ojo65cufKbfe7QoYPc3Nz07rvv/mabtLQ09evXTx4eHqpQoYJ8fHzuepjg6+ur4OBgmc1mOTk5ydXVVdHR0crIyNCgQYNUqVIl1a5dW1u3brU5LikpSV27dlXFihXl6uoqf39/paam/v4fGgCAfEDoBgCgBAoPD1efPn109OhRdevWTX5+frp06ZJq1KihDRs2SJK+++47paSkaM6cOXcdHxsbq+rVq2vq1KnW0XRHR0e99tprWrZsmU3bZcuWqVevXr87Sm4ymRQREaF58+bpzJkz92xz48YNNWvWTJs3b1ZSUpL+/ve/y9/fX4mJiTbtVqxYoWrVqikxMVHBwcEKCgpS79699dxzz+nLL79Up06d5O/vr2vXrkmSLl++rHbt2qlJkyY6dOiQEhISdOHCBfXp0+eB/qYAAPwZhG4AAIqZ+Ph4VaxY0eYTERFh02bgwIHq16+fateurYiICF29elWJiYkymUxydnaWJD3++ONyc3NTlSpV7voNZ2dnmUwmVapUyTqaLkmBgYHatm2bUlJSJEkXL17Uli1bNHjw4D/s98svv6zGjRtr8uTJ99zv4eGhcePGqXHjxqpZs6aCg4PVpUsXxcTE2LRr1KiRJk2apDp16mjixIlycHBQtWrVNGTIENWpU0fvvPOO0tLSdPToUUnS/Pnz1aRJE0VERKhevXpq0qSJli5dqp07d+rEiRN/2G8AAB6GfVF3AAAAPJi2bdtq0aJFNttyg3Suhg0bWv/t6OioypUr6+LFiw/9288884waNGigFStWaMKECVq1apU8PT3VunXr+zp+1qxZateuncaNG3fXvuzsbEVERCgmJkZnz57VzZs3lZmZqQoVKti0y3ttJpNJLi4u8vHxsW5zdXWVJOv1HjlyRDt37lTFihXv+s0ffvhBdevWva++AwDwZxC6AQAoZhwdHVW7du3fbVOmTBmb74ZhKCcnJ19+PzAwUAsWLNCECRO0bNkyDRo06L6rkLdu3VqdO3fWxIkTrWvJc82ePVtz5sxRVFSUfHx85OjoKLPZrJs3b9q0u9e15d2W25fc67169aq6d++uWbNm3dWfJ5544r76DQDAn0XoBgCglClbtqyk2yPLf9TuXm369++v8ePHa+7cuTp27JgGDBjwQL8/c+ZMNW7cWF5eXjbb9+3bpx49eqh///6SbofmEydOyNvb+4HOf6emTZtqw4YNevLJJ2Vvz60PAKBwsaYbAIBiJjMzU+fPn7f5PEglbk9PTxmGofj4eP3888+6evXqPds9+eST2rNnj86ePWtzficnJ73yyisKCQlRp06dVL169Qfqv4+Pj/z8/DR37lyb7XXq1NGOHTu0f/9+HT9+XEOHDtWFCxce6Nz3MmLECF26dEn9+vXTwYMH9cMPP2jbtm0aNGjQHz54AADgYRG6AQAoZhISEvTEE0/YfFq1anXfx3t4eCg8PFwTJkyQq6urRo4cec92U6dO1enTp1WrVi099thjNvsCAgJ08+bN+yqg9lvnvnO6+6RJk9S0aVN17txZvr6+cnNzU8+ePf/U+fNyd3fXvn37lJ2drU6dOsnHx0dms1lVq1aVnR23QgCAgmVYLBZLUXcCAAAULytXrtSYMWN07tw563R1AABwNxY2AQCA+3bt2jWlpKRo5syZGjp0KIEbAIA/wJwqAABw3yIjI1WvXj25ublp4sSJRd0dAAAeeUwvBwAAAACggDDSDQAAAABAASF0AwAAAABQQAjdAAAAAAAUEEI3AAAAAAAFhNANAAAAAEABIXQDAAAAAFBACN0AAAAAABQQQjcAAAAAAAWE0A0AAAAAQAH5P/VtmmShCpW1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to count the occurrences of entity names from CSV\n",
    "def count_entity_names(csv_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Assuming the entity names are in a column called 'entity_name'\n",
    "    entity_names = data['entity_name']\n",
    "    \n",
    "    # Count the occurrences of each entity_name\n",
    "    entity_counts = Counter(entity_names)\n",
    "    \n",
    "    return entity_counts\n",
    "\n",
    "# Function to plot the entity counts\n",
    "def plot_entity_counts(entity_counts):\n",
    "    # Extract keys and values from the dictionary\n",
    "    entity_names = list(entity_counts.keys())\n",
    "    counts = list(entity_counts.values())\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(entity_names, counts, color='lightcoral')\n",
    "\n",
    "    # Rotate x-axis labels to avoid overlap\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title('Entity Name Counts in Dataset')\n",
    "    plt.xlabel('Entity Name')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    # Adjust layout to prevent clipping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Display entity counts in tabular form without using external tools\n",
    "def display_entity_counts(entity_counts):\n",
    "    # Create a DataFrame for better display\n",
    "    df_counts = pd.DataFrame(list(entity_counts.items()), columns=['Entity Name', 'Count'])\n",
    "    return df_counts\n",
    "\n",
    "csv_path = 'dataset/train.csv'  # Path to your actual CSV file\n",
    "# Using the CSV to count entities and create a table\n",
    "entity_counts = count_entity_names(csv_path)\n",
    "entity_counts_table = display_entity_counts(entity_counts)\n",
    "print(entity_counts_table)\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Using the CSV to count entities and plot\n",
    "entity_counts = count_entity_names(csv_path)\n",
    "plot_entity_counts(entity_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e67f051-2136-4b84-adb8-0bb25deca557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Entity Name  Count\n",
      "0                         height  32282\n",
      "1                          width  26931\n",
      "2                          depth  28146\n",
      "3                    item_weight  22032\n",
      "4  maximum_weight_recommendation   7028\n",
      "5                        wattage   5447\n",
      "6                        voltage   5488\n",
      "7                    item_volume   3833\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = 'dataset/test.csv'  # Path to your actual CSV file\n",
    "\n",
    "entity_counts = count_entity_names(csv_path)\n",
    "entity_counts_table = display_entity_counts(entity_counts)\n",
    "print(entity_counts_table)\n",
    "\n",
    "# Using the CSV to count entities and plot\n",
    "entity_counts = count_entity_names(csv_path)\n",
    "plot_entity_counts(entity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78ab0a7-2be1-40fb-b650-d5ff77116f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 9996/9996 [00:00<00:00, 20684.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta file saved to /workspace/dataset/train_data_meta.json\n",
      "Dataset saved to /workspace/dataset/train_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_entity_value_to_float(text):\n",
    "    \"\"\"\n",
    "    Convert all numerical values in the text to floats.\n",
    "    \"\"\"\n",
    "    matches = re.findall(r'\\d+(?:\\.\\d+)?', text)\n",
    "    \n",
    "    if matches:\n",
    "        numbers = [float(match) for match in matches]\n",
    "        parts = re.split(r'(\\d+(?:\\.\\d+)?)', text)\n",
    "        result_parts = []\n",
    "        num_idx = 0\n",
    "        for part in parts:\n",
    "            if re.match(r'\\d+(?:\\.\\d+)?', part):\n",
    "                result_parts.append(str(numbers[num_idx]))\n",
    "                num_idx += 1\n",
    "            else:\n",
    "                result_parts.append(part)\n",
    "        return ''.join(result_parts).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def create_internvl_dataset_with_metadata(csv_file, image_dir, output_jsonl_file, entity_unit_map, test_csv=None, total=None):\n",
    "    \"\"\"\n",
    "    Function to create a dataset in JSONL format compatible with InternVL, \n",
    "    including metadata and using only the entity value in the assistant's response.\n",
    "    If test_csv is provided, samples are proportionally taken from the train set.\n",
    "    \"\"\"\n",
    "    # Load the train data\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # If test_csv is provided, load the test set and calculate proportions\n",
    "    if test_csv:\n",
    "        test_data = pd.read_csv(test_csv)\n",
    "        entity_proportions = test_data['entity_name'].value_counts(normalize=True)\n",
    "\n",
    "        # If total is specified, sample proportionally from the train data\n",
    "        if total:\n",
    "            sampled_data = pd.DataFrame()\n",
    "            for entity_name, proportion in entity_proportions.items():\n",
    "                num_samples = int(proportion * total)\n",
    "                entity_samples = data[data['entity_name'] == entity_name].sample(n=num_samples, replace=False, random_state=42)\n",
    "                sampled_data = pd.concat([sampled_data, entity_samples])\n",
    "        else:\n",
    "            sampled_data = data  # If no total, use full dataset\n",
    "    else:\n",
    "        sampled_data = data  # If no test_csv, use full dataset\n",
    "\n",
    "    # Shuffle the sampled data to randomize the order\n",
    "    sampled_data = sampled_data.sample(frac=1, random_state=42)\n",
    "\n",
    "    # Create the meta file structure\n",
    "    meta_info = {\n",
    "        \"amazon-product-dataset\": {\n",
    "            \"root\": image_dir,\n",
    "            \"annotation\": output_jsonl_file,\n",
    "            \"data_augment\": False,\n",
    "            \"repeat_time\": 1,\n",
    "            \"length\": len(sampled_data)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    jsonl_entries = []\n",
    "\n",
    "    # Iterate over each row in the sampled data with tqdm for progress bar\n",
    "    for idx, row in tqdm(sampled_data.iterrows(), total=len(sampled_data), desc=\"Processing data\"):\n",
    "        # Get the local image path\n",
    "        image_filename = os.path.basename(row[\"image_link\"])\n",
    "        local_image_path = os.path.join(image_dir, image_filename)\n",
    "        \n",
    "        # Convert entity_value to \"float number unit\"\n",
    "        entity_value_converted = convert_entity_value_to_float(str(row['entity_value']))\n",
    "\n",
    "        # Retrieve the available units for the current entity_name\n",
    "        entity_name = row['entity_name']\n",
    "        if entity_name in entity_unit_map:\n",
    "            units = ', '.join(sorted(entity_unit_map[entity_name]))\n",
    "            question = f'What is the {entity_name} of the item in one of the following units ({units})?'\n",
    "        else:\n",
    "            question = f'What is the {entity_name} of the item?'\n",
    "\n",
    "        entry = {\n",
    "            \"id\": idx,\n",
    "            \"image\": local_image_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": f\"{entity_value_converted}\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        jsonl_entries.append(entry)\n",
    "\n",
    "    # Define the path to save the meta file\n",
    "    meta_file = output_jsonl_file.replace(\".jsonl\", \"_meta.json\")\n",
    "\n",
    "    # Save the meta information\n",
    "    with open(meta_file, 'w') as meta_f:\n",
    "        json.dump(meta_info, meta_f, indent=4)\n",
    "    \n",
    "    print(f\"Meta file saved to {meta_file}\")\n",
    "\n",
    "    # Write the JSONL data to a file\n",
    "    with open(output_jsonl_file, 'w') as f:\n",
    "        for entry in jsonl_entries:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "    print(f\"Dataset saved to {output_jsonl_file}\")\n",
    "\n",
    "# Example usage:\n",
    "csv_file = '/workspace/dataset/train.csv'  # Path to your CSV file\n",
    "image_dir = '/workspace/dataset/train/'  # Directory where your images are stored\n",
    "output_jsonl_file = '/workspace/dataset/train_data.jsonl'  # Path to save the output JSONL file\n",
    "test_csv = '/workspace/dataset/test.csv'  # Optional: Path to your test CSV file, if needed\n",
    "\n",
    "# Define the entity-unit mapping\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Create the dataset with metadata, proportional sampling based on test set, and total = 50,000\n",
    "create_internvl_dataset_with_metadata(csv_file, image_dir, output_jsonl_file, entity_unit_map, test_csv=test_csv, total=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d7eba8-bb6b-4eb9-a16e-718e3ef9ac86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_internvl_dataset_with_metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/dataset/train/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m output_jsonl_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/dataset/test_data.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcreate_internvl_dataset_with_metadata\u001b[49m(csv_file, image_dir, output_jsonl_file, entity_unit_map)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_internvl_dataset_with_metadata' is not defined"
     ]
    }
   ],
   "source": [
    "csv_file = '/workspace/dataset/test.csv'  # Path to your CSV file\n",
    "image_dir = '/workspace/dataset/train/'\n",
    "output_jsonl_file = '/workspace/dataset/test_data.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54bca8d-9156-4dc7-9ee3-ae96fcf7a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     entity_name  expected_proportion  actual_proportion  \\\n",
      "0                         height             0.246076           0.246080   \n",
      "1                          depth             0.214549           0.214557   \n",
      "2                          width             0.205287           0.205296   \n",
      "3                    item_weight             0.167943           0.167953   \n",
      "4  maximum_weight_recommendation             0.053572           0.053564   \n",
      "5                        voltage             0.041833           0.041823   \n",
      "6                        wattage             0.041521           0.041523   \n",
      "7                    item_volume             0.029218           0.029202   \n",
      "\n",
      "   difference  \n",
      "0    0.000003  \n",
      "1    0.000008  \n",
      "2    0.000009  \n",
      "3    0.000010  \n",
      "4   -0.000008  \n",
      "5   -0.000010  \n",
      "6    0.000002  \n",
      "7   -0.000015  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def verify_distribution(jsonl_file, test_csv):\n",
    "    \"\"\"\n",
    "    Verifies the distribution of `entity_name` in the generated JSONL file against the \n",
    "    proportions in the test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - jsonl_file: Path to the generated JSONL file.\n",
    "    - test_csv: Path to the test set CSV file to compare against.\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame with the entity name, expected proportion, actual proportion, and the difference.\n",
    "    \"\"\"\n",
    "    # Load the test CSV to calculate expected proportions\n",
    "    test_data = pd.read_csv(test_csv)\n",
    "    test_entity_counts = test_data['entity_name'].value_counts(normalize=True)\n",
    "\n",
    "    # Read the JSONL file and count occurrences of each `entity_name`\n",
    "    entity_name_counts = Counter()\n",
    "    \n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            # Extract the entity name from the human question\n",
    "            question = entry['conversations'][0]['value']\n",
    "            # We assume the question is formatted as: \"What is the <entity_name> of the item\"\n",
    "            entity_name = question.split('What is the ')[1].split(' of')[0]\n",
    "            entity_name_counts[entity_name] += 1\n",
    "\n",
    "    # Convert the entity counts into proportions\n",
    "    total_count = sum(entity_name_counts.values())\n",
    "    actual_proportions = {entity: count / total_count for entity, count in entity_name_counts.items()}\n",
    "\n",
    "    # Create a DataFrame to compare expected and actual proportions\n",
    "    comparison_data = {\n",
    "        'entity_name': [],\n",
    "        'expected_proportion': [],\n",
    "        'actual_proportion': [],\n",
    "        'difference': []\n",
    "    }\n",
    "\n",
    "    for entity_name, expected_proportion in test_entity_counts.items():\n",
    "        actual_proportion = actual_proportions.get(entity_name, 0)\n",
    "        difference = actual_proportion - expected_proportion\n",
    "        \n",
    "        comparison_data['entity_name'].append(entity_name)\n",
    "        comparison_data['expected_proportion'].append(expected_proportion)\n",
    "        comparison_data['actual_proportion'].append(actual_proportion)\n",
    "        comparison_data['difference'].append(difference)\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    return comparison_df\n",
    "\n",
    "# Example usage:\n",
    "jsonl_file = 'dataset/train_data.jsonl'  # Path to the generated JSONL file\n",
    "test_csv = 'dataset/test.csv'  # Path to the test CSV file\n",
    "\n",
    "# Verify the distribution and display the result\n",
    "distribution_comparison_df = verify_distribution(jsonl_file, test_csv)\n",
    "print(distribution_comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d8766-9bd6-4769-b1e3-e951090232f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "def split_dataset(jsonl_file, train_output_file, val_output_file, train_meta_file, val_meta_file, split_ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Function to split a JSONL dataset and its meta information into training and validation sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - jsonl_file: Path to the input JSONL file containing the full dataset.\n",
    "    - train_output_file: Path to save the training split JSONL file.\n",
    "    - val_output_file: Path to save the validation split JSONL file.\n",
    "    - train_meta_file: Path to save the training meta JSON file.\n",
    "    - val_meta_file: Path to save the validation meta JSON file.\n",
    "    - split_ratio: Ratio of training data (default is 0.8 for an 80/20 split).\n",
    "    - seed: Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    # Set the random seed for reproducibility\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Read all the data from the JSONL file\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    # Shuffle the data to ensure randomness\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the number of training samples\n",
    "    train_size = int(len(data) * split_ratio)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    train_data = data[:train_size]\n",
    "    val_data = data[train_size:]\n",
    "\n",
    "    # Write the training data to the train_output_file with progress bar\n",
    "    with open(train_output_file, 'w') as f_train:\n",
    "        for entry in tqdm(train_data, desc=\"Writing training data\"):\n",
    "            json.dump(entry, f_train)\n",
    "            f_train.write('\\n')\n",
    "\n",
    "    # Write the validation data to the val_output_file with progress bar\n",
    "    with open(val_output_file, 'w') as f_val:\n",
    "        for entry in tqdm(val_data, desc=\"Writing validation data\"):\n",
    "            json.dump(entry, f_val)\n",
    "            f_val.write('\\n')\n",
    "\n",
    "    # Handle meta files for training and validation datasets\n",
    "    root_dir = os.path.dirname(jsonl_file)\n",
    "\n",
    "    # Create meta information for training dataset\n",
    "    train_meta = {\n",
    "        \"your-custom-dataset-train\": {\n",
    "            \"root\": root_dir,\n",
    "            \"annotation\": train_output_file,\n",
    "            \"data_augment\": False,\n",
    "            \"repeat_time\": 1,\n",
    "            \"length\": len(train_data)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create meta information for validation dataset\n",
    "    val_meta = {\n",
    "        \"your-custom-dataset-val\": {\n",
    "            \"root\": root_dir,\n",
    "            \"annotation\": val_output_file,\n",
    "            \"data_augment\": False,\n",
    "            \"repeat_time\": 1,\n",
    "            \"length\": len(val_data)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the training meta file\n",
    "    with open(train_meta_file, 'w') as f_train_meta:\n",
    "        json.dump(train_meta, f_train_meta, indent=4)\n",
    "\n",
    "    # Save the validation meta file\n",
    "    with open(val_meta_file, 'w') as f_val_meta:\n",
    "        json.dump(val_meta, f_val_meta, indent=4)\n",
    "\n",
    "    print(f\"Training dataset saved to {train_output_file}\")\n",
    "    print(f\"Validation dataset saved to {val_output_file}\")\n",
    "    print(f\"Training meta file saved to {train_meta_file}\")\n",
    "    print(f\"Validation meta file saved to {val_meta_file}\")\n",
    "    print(f\"Training samples: {len(train_data)}, Validation samples: {len(val_data)}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "jsonl_file = 'dataset/train_data.jsonl'  # Path to your full dataset JSONL file\n",
    "train_output_file = 'dataset/train_split.jsonl'  # Output path for training data\n",
    "val_output_file = 'dataset/val_split.jsonl'  # Output path for validation data\n",
    "train_meta_file = 'dataset/train_meta.json'  # Output path for training meta file\n",
    "val_meta_file = 'dataset/val_meta.json'  # Output path for validation meta file\n",
    "\n",
    "# Call the function to split the dataset (80/20 split by default)\n",
    "split_dataset(jsonl_file, train_output_file, val_output_file, train_meta_file, val_meta_file, split_ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c75122-6bc7-4079-885a-3d772426e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'InternVL'...\n",
      "remote: Enumerating objects: 2474, done.\u001b[K\n",
      "remote: Counting objects: 100% (932/932), done.\u001b[K\n",
      "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
      "remote: Total 2474 (delta 790), reused 784 (delta 753), pack-reused 1542 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2474/2474), 36.31 MiB | 53.66 MiB/s, done.\n",
      "Resolving deltas: 100% (1515/1515), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/OpenGVLab/InternVL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0225a336-eb50-4f6a-941c-2787a481ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/InternVL/internvl_chat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/InternVL/internvl_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b311f73-b99d-4a3e-8923-238c22cb308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///workspace/InternVL/internvl_chat\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from internvl_chat==2.0.0) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.15 in /usr/local/lib/python3.10/dist-packages (from internvl_chat==2.0.0) (0.16.0+cu118)\n",
      "Collecting transformers==4.37.2 (from internvl_chat==2.0.0)\n",
      "  Using cached transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "Collecting tokenizers==0.15.1 (from internvl_chat==2.0.0)\n",
      "  Using cached tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece==0.1.99 (from internvl_chat==2.0.0)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting shortuuid (from internvl_chat==2.0.0)\n",
      "  Using cached shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting accelerate (from internvl_chat==2.0.0)\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft>=0.4.0 (from internvl_chat==2.0.0)\n",
      "  Using cached peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes==0.41.0 (from internvl_chat==2.0.0)\n",
      "  Using cached bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pydantic (from internvl_chat==2.0.0)\n",
      "  Using cached pydantic-2.9.1-py3-none-any.whl.metadata (146 kB)\n",
      "Collecting markdown2[all] (from internvl_chat==2.0.0)\n",
      "  Using cached markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from internvl_chat==2.0.0) (1.24.1)\n",
      "Collecting scikit-learn>=1.2.2 (from internvl_chat==2.0.0)\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting gradio==3.35.2 (from internvl_chat==2.0.0)\n",
      "  Using cached gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting gradio-client==0.2.9 (from internvl_chat==2.0.0)\n",
      "  Using cached gradio_client-0.2.9-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from internvl_chat==2.0.0) (2.31.0)\n",
      "Collecting httpx==0.24.0 (from internvl_chat==2.0.0)\n",
      "  Using cached httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting uvicorn (from internvl_chat==2.0.0)\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastapi (from internvl_chat==2.0.0)\n",
      "  Using cached fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting deepspeed==0.13.5 (from internvl_chat==2.0.0)\n",
      "  Using cached deepspeed-0.13.5-py3-none-any.whl\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from internvl_chat==2.0.0) (0.8.0)\n",
      "Collecting einops-exts (from internvl_chat==2.0.0)\n",
      "  Using cached einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
      "Collecting timm==0.9.12 (from internvl_chat==2.0.0)\n",
      "  Using cached timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "Collecting hjson (from deepspeed==0.13.5->internvl_chat==2.0.0)\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ninja (from deepspeed==0.13.5->internvl_chat==2.0.0)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.5->internvl_chat==2.0.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.5->internvl_chat==2.0.0) (5.9.6)\n",
      "Collecting py-cpuinfo (from deepspeed==0.13.5->internvl_chat==2.0.0)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pynvml (from deepspeed==0.13.5->internvl_chat==2.0.0)\n",
      "  Using cached pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.5->internvl_chat==2.0.0) (4.66.5)\n",
      "Collecting aiofiles (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting altair>=4.2.0 (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting ffmpy (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (0.24.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (3.1.2)\n",
      "Collecting markdown-it-py>=2.0.0 (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (3.9.2)\n",
      "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting orjson (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (9.3.0)\n",
      "Collecting pydub (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (2.16.1)\n",
      "Collecting python-multipart (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->internvl_chat==2.0.0) (6.0.1)\n",
      "Collecting semantic-version (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting websockets>=10.0 (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9->internvl_chat==2.0.0) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9->internvl_chat==2.0.0) (4.4.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->internvl_chat==2.0.0) (2022.12.7)\n",
      "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->internvl_chat==2.0.0)\n",
      "  Using cached httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->internvl_chat==2.0.0) (3.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0->internvl_chat==2.0.0) (1.3.0)\n",
      "Collecting safetensors (from timm==0.9.12->internvl_chat==2.0.0)\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2->internvl_chat==2.0.0) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.37.2->internvl_chat==2.0.0)\n",
      "  Using cached regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=1.2.2->internvl_chat==2.0.0)\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.2.2->internvl_chat==2.0.0)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.2.2->internvl_chat==2.0.0)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->internvl_chat==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->internvl_chat==2.0.0) (3.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->internvl_chat==2.0.0) (2.1.0)\n",
      "Collecting click>=7.0 (from uvicorn->internvl_chat==2.0.0)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->internvl_chat==2.0.0)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->internvl_chat==2.0.0)\n",
      "  Using cached starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting typing-extensions (from gradio-client==0.2.9->internvl_chat==2.0.0)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->internvl_chat==2.0.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.3 (from pydantic->internvl_chat==2.0.0)\n",
      "  Using cached pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting wavedrom (from markdown2[all]->internvl_chat==2.0.0)\n",
      "  Using cached wavedrom-2.0.3.post3-py2.py3-none-any.whl\n",
      "Collecting latex2mathml (from markdown2[all]->internvl_chat==2.0.0)\n",
      "  Using cached latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->internvl_chat==2.0.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->internvl_chat==2.0.0) (1.26.13)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->internvl_chat==2.0.0) (4.19.2)\n",
      "Collecting narwhals>=1.5.2 (from altair>=4.2.0->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached narwhals-1.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->internvl_chat==2.0.0) (4.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2->internvl_chat==2.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2->internvl_chat==2.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2->internvl_chat==2.0.0) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->internvl_chat==2.0.0) (1.3.0)\n",
      "Collecting svgwrite (from wavedrom->markdown2[all]->internvl_chat==2.0.0)\n",
      "  Using cached svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from wavedrom->markdown2[all]->internvl_chat==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0->internvl_chat==2.0.0) (1.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->internvl_chat==2.0.0) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->internvl_chat==2.0.0) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->internvl_chat==2.0.0) (0.12.0)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->internvl_chat==2.0.0)\n",
      "  Using cached uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Using cached bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
      "Using cached gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
      "Using cached gradio_client-0.2.9-py3-none-any.whl (288 kB)\n",
      "Using cached httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "Using cached tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "Using cached peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "Using cached einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
      "Using cached fastapi-0.114.2-py3-none-any.whl (94 kB)\n",
      "Using cached pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Using cached altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Using cached mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "Using cached regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached starlette-0.38.5-py3-none-any.whl (71 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Using cached latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
      "Using cached markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n",
      "Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "Using cached orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached narwhals-1.8.1-py3-none-any.whl (166 kB)\n",
      "Using cached yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Using cached svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
      "Using cached uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Building wheels for collected packages: internvl_chat\n",
      "  Building editable for internvl_chat (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for internvl_chat: filename=internvl_chat-2.0.0-0.editable-py3-none-any.whl size=3969 sha256=0bce4b276338bfb1b74827517a23bf7adb491ebe547faa1d9b5f8b38e0f78d13\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c519ii5p/wheels/df/45/56/a726646ff4e7686ea50a233d7a324dd5f7a7118585443f7277\n",
      "Successfully built internvl_chat\n",
      "Installing collected packages: sentencepiece, pydub, py-cpuinfo, ninja, hjson, bitsandbytes, websockets, uc-micro-py, typing-extensions, threadpoolctl, svgwrite, shortuuid, semantic-version, scipy, safetensors, regex, python-multipart, pynvml, orjson, narwhals, mdurl, markdown2, latex2mathml, joblib, h11, frozenlist, ffmpy, einops-exts, click, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, wavedrom, uvicorn, starlette, scikit-learn, pydantic-core, multidict, markdown-it-py, linkify-it-py, httpcore, aiosignal, yarl, tokenizers, pydantic, mdit-py-plugins, httpx, accelerate, transformers, timm, gradio-client, fastapi, deepspeed, altair, aiohttp, peft, gradio, internvl_chat\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed accelerate-0.34.2 aiofiles-24.1.0 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 altair-5.4.1 annotated-types-0.7.0 async-timeout-4.0.3 bitsandbytes-0.41.0 click-8.1.7 deepspeed-0.13.5 einops-exts-0.0.4 fastapi-0.114.2 ffmpy-0.4.0 frozenlist-1.4.1 gradio-3.35.2 gradio-client-0.2.9 h11-0.14.0 hjson-3.1.0 httpcore-0.17.3 httpx-0.24.0 internvl_chat-2.0.0 joblib-1.4.2 latex2mathml-3.77.0 linkify-it-py-2.0.3 markdown-it-py-2.2.0 markdown2-2.5.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.1.0 narwhals-1.8.1 ninja-1.11.1.1 orjson-3.10.7 peft-0.12.0 py-cpuinfo-9.0.0 pydantic-2.9.1 pydantic-core-2.23.3 pydub-0.25.1 pynvml-11.5.3 python-multipart-0.0.9 regex-2024.9.11 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.13 starlette-0.38.5 svgwrite-1.4.3 threadpoolctl-3.5.0 timm-0.9.12 tokenizers-0.15.1 transformers-4.37.2 typing-extensions-4.12.2 uc-micro-py-1.0.3 uvicorn-0.30.6 wavedrom-2.0.3.post3 websockets-13.0.1 yarl-1.11.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %cd /workspace/InternVL\n",
    "# !pip install -r requirements.txt\n",
    "# %cd /workspace/InternVL/internvl_chat\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3edc2-1902-4f07-8d83-4e226bc16bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f84be8-f1e6-4596-93ef-cb02b74a1ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ GPUS=4\n",
      "+ BATCH_SIZE=64\n",
      "+ PER_DEVICE_BATCH_SIZE=8\n",
      "+ GRADIENT_ACC=2\n",
      "+ pwd\n",
      "+ export PYTHONPATH=:/workspace\n",
      "+ export MASTER_PORT=34229\n",
      "+ export TF_CPP_MIN_LOG_LEVEL=3\n",
      "+ export LAUNCHER=pytorch\n",
      "+ OUTPUT_DIR=work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora\n",
      "+ [ ! -d work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora ]\n",
      "+ + torchrun --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --nproc_per_node=4 --master_port=34229 /workspace/InternVL/internvl_chat/internvl/train/internvl_chat_finetune.py --model_name_or_path /workspace/pretrained/InternVL2-8B --conv_style internlm2-chat --output_dir work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora --meta_path /workspace/dataset/train_data_meta.json --overwrite_output_dir True --force_image_sizetee 448 -a --max_dynamic_patch work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/training_log.txt 6\n",
      " --down_sample_ratio 0.5 --drop_path_rate 0.0 --freeze_llm True --freeze_mlp True --freeze_backbone True --use_llm_lora 16 --vision_select_layer -1 --dataloader_num_workers 4 --bf16 True --num_train_epochs 3 --per_device_train_batch_size 8 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 200 --save_total_limit 1 --learning_rate 4e-5 --weight_decay 0.01 --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --max_seq_length 4096 --do_train True --grad_checkpoint True --group_by_length True --dynamic_image_size True --use_thumbnail True --ps_version v2 --deepspeed /workspace/InternVL/internvl_chat/zero_stage1_config.json --report_to tensorboard\n",
      "[2024-09-15 15:34:46,456] torch.distributed.run: [WARNING] \n",
      "[2024-09-15 15:34:46,456] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-09-15 15:34:46,456] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-09-15 15:34:46,456] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-09-15 15:34:48,796] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:34:48,855] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:34:48,856] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:34:48,857] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "[2024-09-15 15:34:50,926] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-15 15:34:50,947] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-15 15:34:50,947] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-09-15 15:34:51,008] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-09-15 15:34:51,010] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "09/15/2024 15:34:51 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "09/15/2024 15:34:51 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "09/15/2024 15:34:51 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=/workspace/InternVL/internvl_chat/zero_stage1_config.json,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=True,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=4e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/runs/Sep15_15-34-50_1fe2e16e3880,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=cosine,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n",
      "09/15/2024 15:34:51 - INFO - __main__ - Loading Tokenizer: /workspace/pretrained/InternVL2-8B\n",
      "[INFO|tokenization_utils_base.py:2025] 2024-09-15 15:34:51,047 >> loading file ./tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2025] 2024-09-15 15:34:51,047 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2025] 2024-09-15 15:34:51,047 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2025] 2024-09-15 15:34:51,047 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2025] 2024-09-15 15:34:51,047 >> loading file tokenizer.json\n",
      "09/15/2024 15:34:51 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "09/15/2024 15:34:51 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "[WARNING|logging.py:314] 2024-09-15 15:34:51,204 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[WARNING|logging.py:314] 2024-09-15 15:34:51,236 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[WARNING|logging.py:314] 2024-09-15 15:34:51,253 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[WARNING|logging.py:314] 2024-09-15 15:34:51,255 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "09/15/2024 15:34:51 - INFO - __main__ - Loading InternVLChatModel...\n",
      "[INFO|configuration_utils.py:727] 2024-09-15 15:34:51,387 >> loading configuration file /workspace/pretrained/InternVL2-8B/config.json\n",
      "[INFO|configuration_utils.py:792] 2024-09-15 15:34:51,389 >> Model config InternVLChatConfig {\n",
      "  \"_commit_hash\": null,\n",
      "  \"architectures\": [\n",
      "    \"InternVLChatModel\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_internvl_chat.InternVLChatConfig\",\n",
      "    \"AutoModel\": \"modeling_internvl_chat.InternVLChatModel\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_internvl_chat.InternVLChatModel\"\n",
      "  },\n",
      "  \"downsample_ratio\": 0.5,\n",
      "  \"dynamic_image_size\": true,\n",
      "  \"force_image_size\": 448,\n",
      "  \"llm_config\": {\n",
      "    \"_name_or_path\": \"internlm/internlm2_5-7b-chat\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"InternLM2ForCausalLM\"\n",
      "    ],\n",
      "    \"attn_implementation\": \"flash_attention_2\",\n",
      "    \"auto_map\": {\n",
      "      \"AutoConfig\": \"configuration_internlm2.InternLM2Config\",\n",
      "      \"AutoModel\": \"modeling_internlm2.InternLM2ForCausalLM\",\n",
      "      \"AutoModelForCausalLM\": \"modeling_internlm2.InternLM2ForCausalLM\"\n",
      "    },\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bias\": false,\n",
      "    \"bos_token_id\": 1,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 4096,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 14336,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 32768,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"internlm2\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 32,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 32,\n",
      "    \"num_key_value_heads\": 8,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 2,\n",
      "    \"prefix\": null,\n",
      "    \"pretraining_tp\": 1,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"rms_norm_eps\": 1e-05,\n",
      "    \"rope_scaling\": {\n",
      "      \"factor\": 2.0,\n",
      "      \"type\": \"dynamic\"\n",
      "    },\n",
      "    \"rope_theta\": 1000000,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": false,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"bfloat16\",\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.37.2\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": true,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 92553\n",
      "  },\n",
      "  \"max_dynamic_patch\": 12,\n",
      "  \"min_dynamic_patch\": 1,\n",
      "  \"model_type\": \"internvl_chat\",\n",
      "  \"pad2square\": false,\n",
      "  \"ps_version\": \"v2\",\n",
      "  \"select_layer\": -1,\n",
      "  \"template\": \"internlm2-chat\",\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": null,\n",
      "  \"use_backbone_lora\": 0,\n",
      "  \"use_llm_lora\": 0,\n",
      "  \"use_thumbnail\": true,\n",
      "  \"vision_config\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"InternVisionModel\"\n",
      "    ],\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"drop_path_rate\": 0.0,\n",
      "    \"dropout\": 0.0,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_size\": 1024,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"image_size\": 448,\n",
      "    \"initializer_factor\": 1.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 4096,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-06,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"intern_vit_6b\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"norm_type\": \"layer_norm\",\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 24,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"patch_size\": 14,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"qk_normalization\": false,\n",
      "    \"qkv_bias\": true,\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"bfloat16\",\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.37.2\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": true,\n",
      "    \"use_flash_attn\": true\n",
      "  }\n",
      "}\n",
      "\n",
      "09/15/2024 15:34:51 - INFO - __main__ - Using flash_attention_2 for InternLM\n",
      "[INFO|modeling_utils.py:3473] 2024-09-15 15:34:51,390 >> loading weights file /workspace/pretrained/InternVL2-8B/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1426] 2024-09-15 15:34:51,391 >> Instantiating InternVLChatModel model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:826] 2024-09-15 15:34:51,392 >> Generate config GenerationConfig {}\n",
      "\n",
      "[INFO|configuration_utils.py:826] 2024-09-15 15:34:51,429 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 2\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.17s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.17s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.94s/it]trainable params: 37,748,736 || all params: 7,775,531,008 || trainable%: 0.4855\n",
      "trainable params: 37,748,736 || all params: 7,775,531,008 || trainable%: 0.4855\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.38s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.45s/it]\n",
      "[INFO|modeling_utils.py:4350] 2024-09-15 15:35:02,655 >> All model checkpoint weights were used when initializing InternVLChatModel.\n",
      "\n",
      "[INFO|modeling_utils.py:4358] 2024-09-15 15:35:02,656 >> All the weights of InternVLChatModel were initialized from the model checkpoint at /workspace/pretrained/InternVL2-8B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use InternVLChatModel for predictions without further training.\n",
      "[INFO|configuration_utils.py:779] 2024-09-15 15:35:02,661 >> loading configuration file /workspace/pretrained/InternVL2-8B/generation_config.json\n",
      "[INFO|configuration_utils.py:826] 2024-09-15 15:35:02,661 >> Generate config GenerationConfig {\n",
      "  \"eos_token_id\": [\n",
      "    92542,\n",
      "    92543\n",
      "  ]\n",
      "}\n",
      "\n",
      "09/15/2024 15:35:02 - INFO - __main__ - Finished\n",
      "09/15/2024 15:35:02 - INFO - __main__ - model.config.force_image_size: 448\n",
      "09/15/2024 15:35:02 - INFO - __main__ - data_args.force_image_size: 448\n",
      "09/15/2024 15:35:02 - INFO - __main__ - model.config.vision_config.image_size: 448\n",
      "09/15/2024 15:35:02 - INFO - __main__ - [Dataset] num_image_token: 256\n",
      "09/15/2024 15:35:02 - INFO - __main__ - [Dataset] dynamic_image_size: True\n",
      "09/15/2024 15:35:02 - INFO - __main__ - [Dataset] use_thumbnail: True\n",
      "09/15/2024 15:35:02 - INFO - __main__ - [Dataset] min_dynamic_patch: 1, max_dynamic_patch: 6\n",
      "09/15/2024 15:35:02 - INFO - __main__ - Formatting inputs...Skip in lazy mode\n",
      "09/15/2024 15:35:03 - INFO - __main__ - Add dataset: amazon-product-dataset with length: 9996\n",
      "trainable params: 37,748,736 || all params: 7,775,531,008 || trainable%: 0.4855\n",
      "trainable params: 37,748,736 || all params: 7,775,531,008 || trainable%: 0.4855\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.0.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.1.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.2.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.3.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.4.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.5.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.6.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.7.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.8.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.9.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.10.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.11.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.12.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.13.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.14.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.15.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.16.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.17.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.18.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.19.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.20.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.21.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.22.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.23.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.24.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.25.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.26.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.27.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.28.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.29.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.30.feed_forward.w2.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.attention.wqkv.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.attention.wqkv.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.attention.wo.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.attention.wo.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w1.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w1.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w3.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w3.lora_B.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w2.lora_A.default.weight\n",
      "09/15/2024 15:35:03 - INFO - __main__ - language_model.base_model.model.model.layers.31.feed_forward.w2.lora_B.default.weight\n",
      "[INFO|trainer.py:571] 2024-09-15 15:35:03,664 >> Using auto half precision backend\n",
      "[2024-09-15 15:35:03,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.13.5, git-hash=unknown, git-branch=unknown\n",
      "[2024-09-15 15:35:07,120] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06660223007202148 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10187005996704102 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10172486305236816 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10187482833862305 seconds\n",
      "[2024-09-15 15:35:07,875] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2024-09-15 15:35:07,875] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-09-15 15:35:07,915] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2024-09-15 15:35:07,915] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2024-09-15 15:35:07,915] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 1 optimizer\n",
      "[2024-09-15 15:35:07,915] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 1000000000\n",
      "[2024-09-15 15:35:07,915] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 1000000000\n",
      "[2024-09-15 15:35:07,915] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-09-15 15:35:07,915] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-09-15 15:35:08,212] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-09-15 15:35:08,213] [INFO] [utils.py:801:see_memory_usage] MA 15.65 GB         Max_MA 15.67 GB         CA 15.85 GB         Max_CA 16 GB \n",
      "[2024-09-15 15:35:08,213] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 83.43 GB, percent = 8.8%\n",
      "[2024-09-15 15:35:08,404] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-09-15 15:35:08,405] [INFO] [utils.py:801:see_memory_usage] MA 15.65 GB         Max_MA 15.68 GB         CA 15.89 GB         Max_CA 16 GB \n",
      "[2024-09-15 15:35:08,406] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 83.54 GB, percent = 8.8%\n",
      "[2024-09-15 15:35:08,406] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-09-15 15:35:08,586] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-09-15 15:35:08,587] [INFO] [utils.py:801:see_memory_usage] MA 15.65 GB         Max_MA 15.65 GB         CA 15.89 GB         Max_CA 16 GB \n",
      "[2024-09-15 15:35:08,587] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 83.57 GB, percent = 8.8%\n",
      "[2024-09-15 15:35:08,589] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2024-09-15 15:35:08,590] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client callable to create LR scheduler\n",
      "[2024-09-15 15:35:08,590] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f124e5eb550>\n",
      "[2024-09-15 15:35:08,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.999]]\n",
      "[2024-09-15 15:35:08,594] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f124e5eaad0>\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-09-15 15:35:08,595] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 2\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   optimizer_name ............... adamw\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   optimizer_params ............. {'lr': 4e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.01}\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   train_batch_size ............. 64\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  8\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... True\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-09-15 15:35:08,596] [INFO] [config.py:1000:print]   world_size ................... 4\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:1000:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1000000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=1000000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 1\n",
      "[2024-09-15 15:35:08,597] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 1.000000e+09, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 1.000000e+09, \n",
      "        \"contiguous_gradients\": true\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"auto_cast\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"initial_scale_power\": 32, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 4e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.01\n",
      "        }\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"train_batch_size\": 64, \n",
      "    \"train_micro_batch_size_per_gpu\": 8, \n",
      "    \"wall_clock_breakdown\": true\n",
      "}\n",
      "[INFO|trainer.py:1721] 2024-09-15 15:35:08,597 >> ***** Running training *****\n",
      "[INFO|trainer.py:1722] 2024-09-15 15:35:08,597 >>   Num examples = 9,996\n",
      "[INFO|trainer.py:1723] 2024-09-15 15:35:08,597 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1724] 2024-09-15 15:35:08,597 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1727] 2024-09-15 15:35:08,597 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1728] 2024-09-15 15:35:08,597 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1729] 2024-09-15 15:35:08,597 >>   Total optimization steps = 468\n",
      "[INFO|trainer.py:1730] 2024-09-15 15:35:08,602 >>   Number of trainable parameters = 37,748,736\n",
      "  0%|          | 0/468 [00:00<?, ?it/s][2024-09-15 15:35:11,456] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:11,521] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:11,535] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:11,538] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:15,183] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:15,311] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:15,340] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:15,363] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:18,943] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:19,141] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:19,167] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:19,199] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:22,642] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:22,828] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:22,985] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 15:35:23,010] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:35:33,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 2692.38 | bwd_microstep: 5120.97 | bwd_inner_microstep: 5120.91 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:35:41,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.32 | optimizer_gradients: 3.19 | optimizer_step: 1.10\n",
      "[2024-09-15 15:35:41,096] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1428.64 | bwd_microstep: 6570.22 | bwd_inner_microstep: 2592.98 | bwd_allreduce_microstep: 3977.18 | step_microstep: 20.40\n",
      "[2024-09-15 15:35:41,096] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 4120.99 | bwd: 11691.19 | bwd_inner: 7713.88 | bwd_allreduce: 3977.21 | step: 20.47\n",
      "{'loss': 3.7352, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.01}\n",
      "  0%|          | 1/468 [00:32<4:12:57, 32.50s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1900\n",
      "[2024-09-15 15:35:46,587] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 2114.63 | bwd_microstep: 3346.61 | bwd_inner_microstep: 3346.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1368\n",
      "[2024-09-15 15:35:51,828] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.45 | optimizer_step: 0.40\n",
      "[2024-09-15 15:35:51,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1431.24 | bwd_microstep: 3775.07 | bwd_inner_microstep: 2525.83 | bwd_allreduce_microstep: 1249.18 | step_microstep: 7.44\n",
      "[2024-09-15 15:35:51,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3545.84 | bwd: 7121.73 | bwd_inner: 5872.40 | bwd_allreduce: 1249.21 | step: 7.55\n",
      "{'loss': 3.7667, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.01}\n",
      "  0%|          | 2/468 [00:43<2:32:58, 19.70s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 15:35:57,158] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.06 | bwd_microstep: 3397.31 | bwd_inner_microstep: 3397.28 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:36:02,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.43 | optimizer_step: 0.38\n",
      "[2024-09-15 15:36:02,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1449.11 | bwd_microstep: 3756.23 | bwd_inner_microstep: 2554.96 | bwd_allreduce_microstep: 1201.22 | step_microstep: 7.18\n",
      "[2024-09-15 15:36:02,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3351.14 | bwd: 7153.56 | bwd_inner: 5952.24 | bwd_allreduce: 1201.25 | step: 7.23\n",
      "{'loss': 3.7797, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}\n",
      "  1%|          | 3/468 [00:53<2:00:19, 15.53s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1900\n",
      "[2024-09-15 15:36:07,753] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1908.96 | bwd_microstep: 3419.12 | bwd_inner_microstep: 3419.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 15:36:11,827] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.42 | optimizer_step: 0.39\n",
      "[2024-09-15 15:36:11,827] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1456.12 | bwd_microstep: 2581.32 | bwd_inner_microstep: 2568.45 | bwd_allreduce_microstep: 12.82 | step_microstep: 7.76\n",
      "[2024-09-15 15:36:11,827] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3365.04 | bwd: 6000.45 | bwd_inner: 5987.55 | bwd_allreduce: 12.84 | step: 7.99\n",
      "{'loss': 3.6592, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.03}\n",
      "  1%|          | 4/468 [01:03<1:41:28, 13.12s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 15:36:17,164] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.27 | bwd_microstep: 3402.54 | bwd_inner_microstep: 3402.51 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:36:22,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.45 | optimizer_step: 0.40\n",
      "[2024-09-15 15:36:22,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.39 | bwd_microstep: 3838.39 | bwd_inner_microstep: 2570.19 | bwd_allreduce_microstep: 1268.14 | step_microstep: 7.96\n",
      "[2024-09-15 15:36:22,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3362.63 | bwd: 7240.95 | bwd_inner: 5972.70 | bwd_allreduce: 1268.17 | step: 8.02\n",
      "{'loss': 3.6968, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}\n",
      "  1%|          | 5/468 [01:13<1:34:25, 12.24s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:36:27,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.86 | bwd_microstep: 3409.65 | bwd_inner_microstep: 3409.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1880\n",
      "[2024-09-15 15:36:33,560] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.44 | optimizer_step: 0.38\n",
      "[2024-09-15 15:36:33,560] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1892.98 | bwd_microstep: 3795.64 | bwd_inner_microstep: 3401.18 | bwd_allreduce_microstep: 394.40 | step_microstep: 7.40\n",
      "[2024-09-15 15:36:33,561] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3795.81 | bwd: 7205.34 | bwd_inner: 6810.79 | bwd_allreduce: 394.43 | step: 7.66\n",
      "{'loss': 3.7754, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}\n",
      "  1%|▏         | 6/468 [01:24<1:31:09, 11.84s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:36:38,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.01 | bwd_microstep: 3407.13 | bwd_inner_microstep: 3407.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:36:44,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.46 | optimizer_step: 0.40\n",
      "[2024-09-15 15:36:44,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1485.18 | bwd_microstep: 3853.58 | bwd_inner_microstep: 2612.02 | bwd_allreduce_microstep: 1241.49 | step_microstep: 8.50\n",
      "[2024-09-15 15:36:44,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3385.16 | bwd: 7260.72 | bwd_inner: 6019.13 | bwd_allreduce: 1241.52 | step: 8.74\n",
      "{'loss': 3.4281, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.04}\n",
      "  1%|▏         | 7/468 [01:35<1:28:07, 11.47s/it]dynamic ViT batch size: 32, images per sample: 4.0, dynamic token length: 1388\n",
      "[2024-09-15 15:36:48,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1422.53 | bwd_microstep: 2543.25 | bwd_inner_microstep: 2543.08 | bwd_allreduce_microstep: 0.10 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:36:54,934] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.46 | optimizer_step: 0.41\n",
      "[2024-09-15 15:36:54,934] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.08 | bwd_microstep: 5172.00 | bwd_inner_microstep: 2576.72 | bwd_allreduce_microstep: 2595.21 | step_microstep: 7.57\n",
      "[2024-09-15 15:36:54,935] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2883.58 | bwd: 7715.28 | bwd_inner: 5119.80 | bwd_allreduce: 2595.36 | step: 7.78\n",
      "{'loss': 3.6136, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.05}\n",
      "  2%|▏         | 8/468 [01:46<1:25:57, 11.21s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1905\n",
      "[2024-09-15 15:37:00,312] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1908.26 | bwd_microstep: 3438.19 | bwd_inner_microstep: 3438.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:37:05,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 15:37:05,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.78 | bwd_microstep: 3438.20 | bwd_inner_microstep: 3425.71 | bwd_allreduce_microstep: 12.44 | step_microstep: 8.47\n",
      "[2024-09-15 15:37:05,690] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3816.01 | bwd: 6876.40 | bwd_inner: 6863.88 | bwd_allreduce: 12.46 | step: 8.53\n",
      "{'loss': 3.0098, 'learning_rate': 2.4e-05, 'epoch': 0.06}\n",
      "  2%|▏         | 9/468 [01:57<1:24:40, 11.07s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:37:11,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.10 | bwd_microstep: 3422.41 | bwd_inner_microstep: 3422.39 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1879\n",
      "[2024-09-15 15:37:16,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.29 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 15:37:16,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.58 | bwd_microstep: 3439.21 | bwd_inner_microstep: 3425.38 | bwd_allreduce_microstep: 13.78 | step_microstep: 7.83\n",
      "[2024-09-15 15:37:16,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3820.66 | bwd: 6861.63 | bwd_inner: 6847.77 | bwd_allreduce: 13.80 | step: 7.88\n",
      "{'loss': 2.7693, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.06}\n",
      "  2%|▏         | 10/468 [02:07<1:23:43, 10.97s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:37:21,779] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1906.43 | bwd_microstep: 3408.52 | bwd_inner_microstep: 3408.28 | bwd_allreduce_microstep: 0.11 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 34, images per sample: 4.25, dynamic token length: 1367\n",
      "[2024-09-15 15:37:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.45 | optimizer_step: 0.39\n",
      "[2024-09-15 15:37:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1421.51 | bwd_microstep: 2649.81 | bwd_inner_microstep: 2533.64 | bwd_allreduce_microstep: 116.10 | step_microstep: 7.46\n",
      "[2024-09-15 15:37:25,886] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3327.92 | bwd: 6058.35 | bwd_inner: 5941.97 | bwd_allreduce: 116.23 | step: 7.66\n",
      "{'loss': 2.2559, 'learning_rate': 2.9333333333333333e-05, 'epoch': 0.07}\n",
      "  2%|▏         | 11/468 [02:17<1:20:00, 10.50s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:37:30,028] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.54 | bwd_microstep: 2624.72 | bwd_inner_microstep: 2624.69 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:37:35,415] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 15:37:35,416] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.24 | bwd_microstep: 3448.17 | bwd_inner_microstep: 3434.46 | bwd_allreduce_microstep: 13.66 | step_microstep: 7.79\n",
      "[2024-09-15 15:37:35,416] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3395.75 | bwd: 6072.90 | bwd_inner: 6059.16 | bwd_allreduce: 13.68 | step: 7.87\n",
      "{'loss': 2.1567, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.08}\n",
      "  3%|▎         | 12/468 [02:26<1:17:34, 10.21s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 15:37:40,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1898.25 | bwd_microstep: 3421.09 | bwd_inner_microstep: 3421.03 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:37:46,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.29 | optimizer_gradients: 0.43 | optimizer_step: 0.39\n",
      "[2024-09-15 15:37:46,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.83 | bwd_microstep: 3840.85 | bwd_inner_microstep: 2590.34 | bwd_allreduce_microstep: 1250.46 | step_microstep: 7.49\n",
      "[2024-09-15 15:37:46,109] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3366.05 | bwd: 7261.98 | bwd_inner: 6011.37 | bwd_allreduce: 1250.49 | step: 7.75\n",
      "{'loss': 1.7343, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.08}\n",
      "  3%|▎         | 13/468 [02:37<1:18:31, 10.36s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 15:37:51,449] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.95 | bwd_microstep: 3413.05 | bwd_inner_microstep: 3413.02 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1370\n",
      "[2024-09-15 15:37:56,835] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.45 | optimizer_step: 0.40\n",
      "[2024-09-15 15:37:56,835] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.56 | bwd_microstep: 3880.59 | bwd_inner_microstep: 2589.86 | bwd_allreduce_microstep: 1290.66 | step_microstep: 7.43\n",
      "[2024-09-15 15:37:56,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3364.48 | bwd: 7293.65 | bwd_inner: 6002.89 | bwd_allreduce: 1290.69 | step: 7.50\n",
      "{'loss': 1.677, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.09}\n",
      "  3%|▎         | 14/468 [02:48<1:19:12, 10.47s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1387\n",
      "[2024-09-15 15:38:00,979] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.70 | bwd_microstep: 2623.23 | bwd_inner_microstep: 2623.20 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1366\n",
      "[2024-09-15 15:38:08,325] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.44 | optimizer_step: 0.39\n",
      "[2024-09-15 15:38:08,326] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1458.45 | bwd_microstep: 5855.29 | bwd_inner_microstep: 2576.15 | bwd_allreduce_microstep: 3279.08 | step_microstep: 7.63\n",
      "[2024-09-15 15:38:08,326] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2947.08 | bwd: 8478.53 | bwd_inner: 5199.36 | bwd_allreduce: 3279.11 | step: 7.83\n",
      "{'loss': 1.2854, 'learning_rate': 4e-05, 'epoch': 0.1}\n",
      "  3%|▎         | 15/468 [02:59<1:21:21, 10.78s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:38:12,467] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1487.74 | bwd_microstep: 2620.17 | bwd_inner_microstep: 2620.14 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:38:19,043] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.10 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 15:38:19,044] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.94 | bwd_microstep: 5082.62 | bwd_inner_microstep: 2585.74 | bwd_allreduce_microstep: 2496.82 | step_microstep: 8.35\n",
      "[2024-09-15 15:38:19,044] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2949.65 | bwd: 7702.82 | bwd_inner: 5205.89 | bwd_allreduce: 2496.85 | step: 8.41\n",
      "{'loss': 1.1381, 'learning_rate': 3.999951904814875e-05, 'epoch': 0.1}\n",
      "  3%|▎         | 16/468 [03:10<1:21:02, 10.76s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 15:38:23,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.34 | bwd_microstep: 2583.00 | bwd_inner_microstep: 2582.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:38:29,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.54 | optimizer_step: 0.40\n",
      "[2024-09-15 15:38:29,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.07 | bwd_microstep: 4612.74 | bwd_inner_microstep: 3426.25 | bwd_allreduce_microstep: 1186.37 | step_microstep: 8.59\n",
      "[2024-09-15 15:38:29,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3369.38 | bwd: 7195.77 | bwd_inner: 6009.22 | bwd_allreduce: 1186.44 | step: 8.63\n",
      "{'loss': 0.7843, 'learning_rate': 3.999807621572648e-05, 'epoch': 0.11}\n",
      "  4%|▎         | 17/468 [03:21<1:20:36, 10.72s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:38:35,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.25 | bwd_microstep: 3427.56 | bwd_inner_microstep: 3427.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:38:40,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.40 | optimizer_step: 0.37\n",
      "[2024-09-15 15:38:40,445] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.72 | bwd_microstep: 3449.69 | bwd_inner_microstep: 3436.10 | bwd_allreduce_microstep: 13.53 | step_microstep: 8.29\n",
      "[2024-09-15 15:38:40,445] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3818.95 | bwd: 6877.25 | bwd_inner: 6863.63 | bwd_allreduce: 13.55 | step: 8.35\n",
      "{'loss': 0.7415, 'learning_rate': 3.999567157212646e-05, 'epoch': 0.12}\n",
      "  4%|▍         | 18/468 [03:31<1:20:30, 10.73s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:38:44,590] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.53 | bwd_microstep: 2619.43 | bwd_inner_microstep: 2619.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:38:51,133] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.21 | optimizer_gradients: 0.46 | optimizer_step: 0.38\n",
      "[2024-09-15 15:38:51,133] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.86 | bwd_microstep: 4596.09 | bwd_inner_microstep: 3431.55 | bwd_allreduce_microstep: 1164.47 | step_microstep: 10.73\n",
      "[2024-09-15 15:38:51,134] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3403.36 | bwd: 7215.53 | bwd_inner: 6050.96 | bwd_allreduce: 1164.50 | step: 10.78\n",
      "{'loss': 0.6684, 'learning_rate': 3.999230523300049e-05, 'epoch': 0.12}\n",
      "  4%|▍         | 19/468 [03:42<1:20:13, 10.72s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:38:55,211] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.89 | bwd_microstep: 2582.58 | bwd_inner_microstep: 2582.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:39:00,601] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.20 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 15:39:00,602] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.68 | bwd_microstep: 3443.24 | bwd_inner_microstep: 3429.54 | bwd_allreduce_microstep: 13.63 | step_microstep: 7.59\n",
      "[2024-09-15 15:39:00,602] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.55 | bwd: 6025.84 | bwd_inner: 6012.09 | bwd_allreduce: 13.67 | step: 7.82\n",
      "{'loss': 0.4267, 'learning_rate': 3.998797736025326e-05, 'epoch': 0.13}\n",
      "  4%|▍         | 20/468 [03:52<1:17:14, 10.34s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:39:04,749] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.26 | bwd_microstep: 2625.82 | bwd_inner_microstep: 2625.79 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:39:10,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.37 | optimizer_step: 0.37\n",
      "[2024-09-15 15:39:10,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1944.82 | bwd_microstep: 3493.35 | bwd_inner_microstep: 3481.05 | bwd_allreduce_microstep: 12.26 | step_microstep: 8.54\n",
      "[2024-09-15 15:39:10,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3435.04 | bwd: 6119.18 | bwd_inner: 6106.84 | bwd_allreduce: 12.28 | step: 8.77\n",
      "{'loss': 0.5993, 'learning_rate': 3.9982688162034624e-05, 'epoch': 0.13}\n",
      "  4%|▍         | 21/468 [04:01<1:15:27, 10.13s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1367\n",
      "[2024-09-15 15:39:14,290] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1454.96 | bwd_microstep: 2574.76 | bwd_inner_microstep: 2574.73 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 15:39:20,905] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.44 | optimizer_step: 0.40\n",
      "[2024-09-15 15:39:20,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.46 | bwd_microstep: 4646.49 | bwd_inner_microstep: 3463.18 | bwd_allreduce_microstep: 1183.25 | step_microstep: 9.22\n",
      "[2024-09-15 15:39:20,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.40 | bwd: 7221.26 | bwd_inner: 6037.91 | bwd_allreduce: 1183.28 | step: 9.27\n",
      "{'loss': 0.555, 'learning_rate': 3.997643789272954e-05, 'epoch': 0.14}\n",
      "  5%|▍         | 22/468 [04:12<1:16:30, 10.29s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 15:39:25,062] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.09 | bwd_microstep: 2629.22 | bwd_inner_microstep: 2629.19 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:39:31,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.43 | optimizer_step: 0.39\n",
      "[2024-09-15 15:39:31,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.54 | bwd_microstep: 4625.08 | bwd_inner_microstep: 3440.71 | bwd_allreduce_microstep: 1184.31 | step_microstep: 7.65\n",
      "[2024-09-15 15:39:31,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3408.61 | bwd: 7254.31 | bwd_inner: 6069.90 | bwd_allreduce: 1184.35 | step: 7.71\n",
      "{'loss': 0.5142, 'learning_rate': 3.996922685294587e-05, 'epoch': 0.15}\n",
      "  5%|▍         | 23/468 [04:23<1:17:18, 10.42s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:39:37,015] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.79 | bwd_microstep: 3431.91 | bwd_inner_microstep: 3431.88 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 15:39:42,376] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.51 | optimizer_step: 0.69\n",
      "[2024-09-15 15:39:42,377] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1898.70 | bwd_microstep: 3429.28 | bwd_inner_microstep: 3416.03 | bwd_allreduce_microstep: 13.19 | step_microstep: 10.30\n",
      "[2024-09-15 15:39:42,377] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3814.47 | bwd: 6861.21 | bwd_inner: 6847.92 | bwd_allreduce: 13.22 | step: 10.35\n",
      "{'loss': 0.3841, 'learning_rate': 3.9961055389499904e-05, 'epoch': 0.15}\n",
      "  5%|▌         | 24/468 [04:33<1:17:50, 10.52s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:39:47,764] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.61 | bwd_microstep: 3437.97 | bwd_inner_microstep: 3437.94 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:39:53,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.41 | optimizer_step: 0.42\n",
      "[2024-09-15 15:39:53,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.21 | bwd_microstep: 3451.29 | bwd_inner_microstep: 3439.09 | bwd_allreduce_microstep: 12.15 | step_microstep: 8.03\n",
      "[2024-09-15 15:39:53,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3836.79 | bwd: 6889.27 | bwd_inner: 6877.03 | bwd_allreduce: 12.18 | step: 8.10\n",
      "{'loss': 0.3057, 'learning_rate': 3.9951923895399696e-05, 'epoch': 0.16}\n",
      "  5%|▌         | 25/468 [04:44<1:18:15, 10.60s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 15:39:58,555] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.89 | bwd_microstep: 3442.11 | bwd_inner_microstep: 3442.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:40:03,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:40:03,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.84 | bwd_microstep: 3452.66 | bwd_inner_microstep: 3440.01 | bwd_allreduce_microstep: 12.61 | step_microstep: 8.13\n",
      "[2024-09-15 15:40:03,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3837.69 | bwd: 6894.79 | bwd_inner: 6882.10 | bwd_allreduce: 12.63 | step: 8.36\n",
      "{'loss': 0.4327, 'learning_rate': 3.9941832809826136e-05, 'epoch': 0.17}\n",
      "  6%|▌         | 26/468 [04:55<1:18:31, 10.66s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 15:40:09,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1887.69 | bwd_microstep: 3404.81 | bwd_inner_microstep: 3404.78 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:40:14,731] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 15:40:14,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1933.66 | bwd_microstep: 3474.72 | bwd_inner_microstep: 3462.07 | bwd_allreduce_microstep: 12.60 | step_microstep: 8.20\n",
      "[2024-09-15 15:40:14,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3821.33 | bwd: 6879.54 | bwd_inner: 6866.85 | bwd_allreduce: 12.63 | step: 8.41\n",
      "{'loss': 0.3207, 'learning_rate': 3.993078261811186e-05, 'epoch': 0.17}\n",
      "  6%|▌         | 27/468 [05:06<1:18:35, 10.69s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:40:20,160] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.74 | bwd_microstep: 3462.58 | bwd_inner_microstep: 3462.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 15:40:24,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.77 | optimizer_gradients: 0.38 | optimizer_step: 0.37\n",
      "[2024-09-15 15:40:24,234] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1457.10 | bwd_microstep: 2584.90 | bwd_inner_microstep: 2572.07 | bwd_allreduce_microstep: 12.78 | step_microstep: 8.05\n",
      "[2024-09-15 15:40:24,234] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.81 | bwd: 6047.49 | bwd_inner: 6034.62 | bwd_allreduce: 12.80 | step: 8.10\n",
      "{'loss': 0.454, 'learning_rate': 3.991877385171789e-05, 'epoch': 0.18}\n",
      "  6%|▌         | 28/468 [05:15<1:15:47, 10.34s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:40:29,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.59 | bwd_microstep: 3442.66 | bwd_inner_microstep: 3442.63 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1880\n",
      "[2024-09-15 15:40:35,037] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 15:40:35,037] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.55 | bwd_microstep: 3459.17 | bwd_inner_microstep: 3446.78 | bwd_allreduce_microstep: 12.34 | step_microstep: 8.38\n",
      "[2024-09-15 15:40:35,037] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3839.12 | bwd: 6901.84 | bwd_inner: 6889.41 | bwd_allreduce: 12.36 | step: 8.44\n",
      "{'loss': 0.2997, 'learning_rate': 3.990580708820805e-05, 'epoch': 0.19}\n",
      "  6%|▌         | 29/468 [05:26<1:16:38, 10.48s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 15:40:40,471] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.84 | bwd_microstep: 3467.60 | bwd_inner_microstep: 3467.37 | bwd_allreduce_microstep: 0.09 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:40:45,830] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.33 | optimizer_step: 0.37\n",
      "[2024-09-15 15:40:45,830] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.06 | bwd_microstep: 3425.70 | bwd_inner_microstep: 3412.00 | bwd_allreduce_microstep: 13.64 | step_microstep: 7.65\n",
      "[2024-09-15 15:40:45,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3834.88 | bwd: 6893.33 | bwd_inner: 6879.41 | bwd_allreduce: 13.76 | step: 7.82\n",
      "{'loss': 0.3583, 'learning_rate': 3.9891882951221246e-05, 'epoch': 0.19}\n",
      "  6%|▋         | 30/468 [05:37<1:17:10, 10.57s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:40:49,989] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.05 | bwd_microstep: 2635.61 | bwd_inner_microstep: 2635.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:40:55,398] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 15:40:55,399] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.52 | bwd_microstep: 3457.26 | bwd_inner_microstep: 3444.62 | bwd_allreduce_microstep: 12.59 | step_microstep: 8.38\n",
      "[2024-09-15 15:40:55,399] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3413.55 | bwd: 6092.89 | bwd_inner: 6080.21 | bwd_allreduce: 12.61 | step: 8.44\n",
      "{'loss': 0.2823, 'learning_rate': 3.9877002110441424e-05, 'epoch': 0.2}\n",
      "  7%|▋         | 31/468 [05:46<1:14:48, 10.27s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 15:41:00,814] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1928.82 | bwd_microstep: 3453.57 | bwd_inner_microstep: 3453.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:41:06,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:41:06,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.19 | bwd_microstep: 3463.36 | bwd_inner_microstep: 3450.16 | bwd_allreduce_microstep: 13.11 | step_microstep: 8.27\n",
      "[2024-09-15 15:41:06,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3845.98 | bwd: 6916.94 | bwd_inner: 6903.74 | bwd_allreduce: 13.12 | step: 8.43\n",
      "{'loss': 0.2659, 'learning_rate': 3.986116528156537e-05, 'epoch': 0.2}\n",
      "  7%|▋         | 32/468 [05:57<1:15:51, 10.44s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:41:11,631] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1922.75 | bwd_microstep: 3443.03 | bwd_inner_microstep: 3443.00 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:41:17,056] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.49 | optimizer_step: 0.44\n",
      "[2024-09-15 15:41:17,057] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1927.59 | bwd_microstep: 3463.47 | bwd_inner_microstep: 3450.13 | bwd_allreduce_microstep: 13.28 | step_microstep: 10.30\n",
      "[2024-09-15 15:41:17,057] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3850.31 | bwd: 6906.51 | bwd_inner: 6893.13 | bwd_allreduce: 13.31 | step: 10.36\n",
      "{'loss': 0.3158, 'learning_rate': 3.9844373226268305e-05, 'epoch': 0.21}\n",
      "  7%|▋         | 33/468 [06:08<1:16:32, 10.56s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 15:41:22,496] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.51 | bwd_microstep: 3467.38 | bwd_inner_microstep: 3467.35 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:41:27,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 15:41:27,958] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1940.57 | bwd_microstep: 3488.35 | bwd_inner_microstep: 3475.80 | bwd_allreduce_microstep: 12.50 | step_microstep: 8.49\n",
      "[2024-09-15 15:41:27,958] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3876.06 | bwd: 6955.74 | bwd_inner: 6943.15 | bwd_allreduce: 12.52 | step: 8.55\n",
      "{'loss': 0.2704, 'learning_rate': 3.982662675216723e-05, 'epoch': 0.22}\n",
      "  7%|▋         | 34/468 [06:19<1:17:05, 10.66s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1900\n",
      "[2024-09-15 15:41:33,484] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1974.08 | bwd_microstep: 3520.76 | bwd_inner_microstep: 3520.74 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 15:41:38,880] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.37 | optimizer_gradients: 0.42 | optimizer_step: 0.42\n",
      "[2024-09-15 15:41:38,881] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.27 | bwd_microstep: 3451.28 | bwd_inner_microstep: 3438.16 | bwd_allreduce_microstep: 13.06 | step_microstep: 12.32\n",
      "[2024-09-15 15:41:38,881] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3883.31 | bwd: 6972.06 | bwd_inner: 6958.90 | bwd_allreduce: 13.08 | step: 12.39\n",
      "{'loss': 0.3642, 'learning_rate': 3.9807926712782115e-05, 'epoch': 0.22}\n",
      "  7%|▋         | 35/468 [06:30<1:17:29, 10.74s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 15:41:44,332] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.51 | bwd_microstep: 3475.27 | bwd_inner_microstep: 3475.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:41:49,703] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.40 | optimizer_step: 0.42\n",
      "[2024-09-15 15:41:49,703] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.07 | bwd_microstep: 3434.24 | bwd_inner_microstep: 3421.17 | bwd_allreduce_microstep: 13.02 | step_microstep: 8.88\n",
      "[2024-09-15 15:41:49,704] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3843.55 | bwd: 6909.53 | bwd_inner: 6896.42 | bwd_allreduce: 13.04 | step: 8.94\n",
      "{'loss': 0.3058, 'learning_rate': 3.978827400749481e-05, 'epoch': 0.23}\n",
      "  8%|▊         | 36/468 [06:41<1:17:29, 10.76s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:41:53,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1497.85 | bwd_microstep: 2632.68 | bwd_inner_microstep: 2632.65 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1876\n",
      "[2024-09-15 15:41:59,237] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.66 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 15:41:59,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.02 | bwd_microstep: 3435.61 | bwd_inner_microstep: 3422.66 | bwd_allreduce_microstep: 12.90 | step_microstep: 8.58\n",
      "[2024-09-15 15:41:59,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.84 | bwd: 6068.30 | bwd_inner: 6055.31 | bwd_allreduce: 12.92 | step: 8.80\n",
      "{'loss': 0.3343, 'learning_rate': 3.976766958150581e-05, 'epoch': 0.24}\n",
      "  8%|▊         | 37/468 [06:50<1:14:40, 10.40s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:42:04,596] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.65 | bwd_microstep: 3416.69 | bwd_inner_microstep: 3416.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:42:10,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 15:42:10,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1923.57 | bwd_microstep: 3457.34 | bwd_inner_microstep: 3445.02 | bwd_allreduce_microstep: 12.26 | step_microstep: 8.17\n",
      "[2024-09-15 15:42:10,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3826.19 | bwd: 6874.04 | bwd_inner: 6861.69 | bwd_allreduce: 12.28 | step: 8.22\n",
      "{'loss': 0.2987, 'learning_rate': 3.97461144257888e-05, 'epoch': 0.24}\n",
      "  8%|▊         | 38/468 [07:01<1:15:18, 10.51s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 15:42:14,138] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1481.44 | bwd_microstep: 2615.04 | bwd_inner_microstep: 2615.02 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:42:19,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.20 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:42:19,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1477.48 | bwd_microstep: 3830.75 | bwd_inner_microstep: 2604.62 | bwd_allreduce_microstep: 1226.07 | step_microstep: 7.99\n",
      "[2024-09-15 15:42:19,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.88 | bwd: 6445.81 | bwd_inner: 5219.64 | bwd_allreduce: 1226.10 | step: 8.15\n",
      "{'loss': 0.2469, 'learning_rate': 3.972360957704298e-05, 'epoch': 0.25}\n",
      "  8%|▊         | 39/468 [07:10<1:12:54, 10.20s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:42:23,643] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.27 | bwd_microstep: 2634.91 | bwd_inner_microstep: 2634.88 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 15:42:30,221] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.68 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 15:42:30,222] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1945.76 | bwd_microstep: 4598.78 | bwd_inner_microstep: 3473.61 | bwd_allreduce_microstep: 1125.11 | step_microstep: 7.98\n",
      "[2024-09-15 15:42:30,222] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3441.00 | bwd: 7233.70 | bwd_inner: 6108.49 | bwd_allreduce: 1125.14 | step: 8.04\n",
      "{'loss': 0.359, 'learning_rate': 3.970015611764323e-05, 'epoch': 0.26}\n",
      "  9%|▊         | 40/468 [07:21<1:13:53, 10.36s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:42:34,386] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.48 | bwd_microstep: 2638.47 | bwd_inner_microstep: 2638.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:42:39,809] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.41 | optimizer_step: 0.42\n",
      "[2024-09-15 15:42:39,810] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.29 | bwd_microstep: 3464.03 | bwd_inner_microstep: 3450.83 | bwd_allreduce_microstep: 13.15 | step_microstep: 9.16\n",
      "[2024-09-15 15:42:39,810] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3415.74 | bwd: 6102.51 | bwd_inner: 6089.27 | bwd_allreduce: 13.17 | step: 9.40\n",
      "{'loss': 0.2903, 'learning_rate': 3.9675755175588006e-05, 'epoch': 0.26}\n",
      "  9%|▉         | 41/468 [07:31<1:12:04, 10.13s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:42:45,207] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.00 | bwd_microstep: 3444.36 | bwd_inner_microstep: 3444.33 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:42:50,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.19 | optimizer_gradients: 0.53 | optimizer_step: 0.43\n",
      "[2024-09-15 15:42:50,496] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.76 | bwd_microstep: 3779.40 | bwd_inner_microstep: 2600.54 | bwd_allreduce_microstep: 1178.80 | step_microstep: 8.47\n",
      "[2024-09-15 15:42:50,496] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3395.73 | bwd: 7223.77 | bwd_inner: 6044.87 | bwd_allreduce: 1178.83 | step: 8.54\n",
      "{'loss': 0.3881, 'learning_rate': 3.9650407924445147e-05, 'epoch': 0.27}\n",
      "  9%|▉         | 42/468 [07:41<1:13:06, 10.30s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1888\n",
      "[2024-09-15 15:42:55,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.81 | bwd_microstep: 3439.16 | bwd_inner_microstep: 3439.00 | bwd_allreduce_microstep: 0.07 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:42:59,988] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:42:59,989] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.70 | bwd_microstep: 2609.69 | bwd_inner_microstep: 2595.45 | bwd_allreduce_microstep: 14.19 | step_microstep: 7.36\n",
      "[2024-09-15 15:42:59,989] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3377.48 | bwd: 6048.88 | bwd_inner: 6034.48 | bwd_allreduce: 14.28 | step: 7.51\n",
      "{'loss': 0.2877, 'learning_rate': 3.9624115583295375e-05, 'epoch': 0.27}\n",
      "  9%|▉         | 43/468 [07:51<1:11:13, 10.05s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 15:43:05,406] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1931.44 | bwd_microstep: 3456.55 | bwd_inner_microstep: 3456.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:43:10,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.74 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 15:43:10,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1475.42 | bwd_microstep: 3885.86 | bwd_inner_microstep: 2603.08 | bwd_allreduce_microstep: 1282.72 | step_microstep: 8.80\n",
      "[2024-09-15 15:43:10,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3406.83 | bwd: 7342.43 | bwd_inner: 6059.61 | bwd_allreduce: 1282.75 | step: 8.85\n",
      "{'loss': 0.2628, 'learning_rate': 3.959687941667372e-05, 'epoch': 0.28}\n",
      "  9%|▉         | 44/468 [08:02<1:12:39, 10.28s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:43:14,969] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.83 | bwd_microstep: 2636.84 | bwd_inner_microstep: 2636.50 | bwd_allreduce_microstep: 0.14 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:43:21,610] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 15:43:21,610] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1498.41 | bwd_microstep: 5109.16 | bwd_inner_microstep: 2639.43 | bwd_allreduce_microstep: 2469.67 | step_microstep: 7.46\n",
      "[2024-09-15 15:43:21,611] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2993.21 | bwd: 7746.05 | bwd_inner: 5276.01 | bwd_allreduce: 2469.83 | step: 7.71\n",
      "{'loss': 0.2789, 'learning_rate': 3.9568700734508645e-05, 'epoch': 0.29}\n",
      " 10%|▉         | 45/468 [08:13<1:13:36, 10.44s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:43:26,984] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.87 | bwd_microstep: 3430.56 | bwd_inner_microstep: 3430.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:43:32,401] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:43:32,401] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.24 | bwd_microstep: 3463.16 | bwd_inner_microstep: 3448.21 | bwd_allreduce_microstep: 14.90 | step_microstep: 8.19\n",
      "[2024-09-15 15:43:32,401] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3830.08 | bwd: 6893.73 | bwd_inner: 6878.74 | bwd_allreduce: 14.92 | step: 8.35\n",
      "{'loss': 0.2164, 'learning_rate': 3.9539580892059086e-05, 'epoch': 0.29}\n",
      " 10%|▉         | 46/468 [08:23<1:14:10, 10.55s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:43:37,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.59 | bwd_microstep: 3464.59 | bwd_inner_microstep: 3464.56 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:43:41,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.77 | optimizer_gradients: 0.34 | optimizer_step: 0.40\n",
      "[2024-09-15 15:43:41,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.57 | bwd_microstep: 2611.60 | bwd_inner_microstep: 2596.16 | bwd_allreduce_microstep: 15.39 | step_microstep: 7.95\n",
      "[2024-09-15 15:43:41,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.14 | bwd: 6076.20 | bwd_inner: 6060.72 | bwd_allreduce: 15.41 | step: 8.19\n",
      "{'loss': 0.217, 'learning_rate': 3.950952128984927e-05, 'epoch': 0.3}\n",
      " 10%|█         | 47/468 [08:33<1:11:53, 10.25s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 15:43:47,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1940.27 | bwd_microstep: 3473.30 | bwd_inner_microstep: 3473.27 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1881\n",
      "[2024-09-15 15:43:52,888] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.41 | optimizer_step: 0.39\n",
      "[2024-09-15 15:43:52,888] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1952.80 | bwd_microstep: 3506.00 | bwd_inner_microstep: 3493.42 | bwd_allreduce_microstep: 12.52 | step_microstep: 8.34\n",
      "[2024-09-15 15:43:52,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3893.05 | bwd: 6979.31 | bwd_inner: 6966.70 | bwd_allreduce: 12.55 | step: 8.48\n",
      "{'loss': 0.2196, 'learning_rate': 3.9478523373601325e-05, 'epoch': 0.31}\n",
      " 10%|█         | 48/468 [08:44<1:13:11, 10.46s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:43:58,292] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.28 | bwd_microstep: 3447.97 | bwd_inner_microstep: 3447.94 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:44:03,694] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:44:03,695] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.98 | bwd_microstep: 3452.10 | bwd_inner_microstep: 3437.07 | bwd_allreduce_microstep: 14.98 | step_microstep: 8.28\n",
      "[2024-09-15 15:44:03,695] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3834.24 | bwd: 6900.08 | bwd_inner: 6885.02 | bwd_allreduce: 15.00 | step: 8.45\n",
      "{'loss': 0.3036, 'learning_rate': 3.944658863416575e-05, 'epoch': 0.31}\n",
      " 10%|█         | 49/468 [08:55<1:13:44, 10.56s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 15:44:07,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.83 | bwd_microstep: 2576.27 | bwd_inner_microstep: 2576.24 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:44:13,217] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 15:44:13,218] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.71 | bwd_microstep: 3492.87 | bwd_inner_microstep: 3446.64 | bwd_allreduce_microstep: 46.19 | step_microstep: 7.58\n",
      "[2024-09-15 15:44:13,218] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3381.49 | bwd: 6069.17 | bwd_inner: 6022.88 | bwd_allreduce: 46.21 | step: 7.81\n",
      "{'loss': 0.2398, 'learning_rate': 3.941371860744978e-05, 'epoch': 0.32}\n",
      " 11%|█         | 50/468 [09:04<1:11:23, 10.25s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1390\n",
      "[2024-09-15 15:44:17,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1481.09 | bwd_microstep: 2615.18 | bwd_inner_microstep: 2615.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:44:23,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.37 | optimizer_step: 0.39\n",
      "[2024-09-15 15:44:23,930] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.91 | bwd_microstep: 4631.83 | bwd_inner_microstep: 3442.15 | bwd_allreduce_microstep: 1189.61 | step_microstep: 7.20\n",
      "[2024-09-15 15:44:23,930] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3397.96 | bwd: 7247.05 | bwd_inner: 6057.26 | bwd_allreduce: 1189.66 | step: 7.47\n",
      "{'loss': 0.2441, 'learning_rate': 3.937991487434342e-05, 'epoch': 0.33}\n",
      " 11%|█         | 51/468 [09:15<1:12:11, 10.39s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 15:44:29,258] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1888.85 | bwd_microstep: 3408.90 | bwd_inner_microstep: 3408.87 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:44:33,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.46 | optimizer_step: 0.39\n",
      "[2024-09-15 15:44:33,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.59 | bwd_microstep: 2615.89 | bwd_inner_microstep: 2598.01 | bwd_allreduce_microstep: 17.81 | step_microstep: 9.42\n",
      "[2024-09-15 15:44:33,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3358.41 | bwd: 6024.80 | bwd_inner: 6006.89 | bwd_allreduce: 17.84 | step: 9.64\n",
      "{'loss': 0.2922, 'learning_rate': 3.934517906064348e-05, 'epoch': 0.33}\n",
      " 11%|█         | 52/468 [09:24<1:10:05, 10.11s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 15:44:38,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1939.30 | bwd_microstep: 3476.40 | bwd_inner_microstep: 3476.37 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:44:44,294] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 15:44:44,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.04 | bwd_microstep: 3486.14 | bwd_inner_microstep: 3471.12 | bwd_allreduce_microstep: 14.97 | step_microstep: 7.56\n",
      "[2024-09-15 15:44:44,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3875.31 | bwd: 6962.55 | bwd_inner: 6947.49 | bwd_allreduce: 14.99 | step: 7.80\n",
      "{'loss': 0.3127, 'learning_rate': 3.930951283697534e-05, 'epoch': 0.34}\n",
      " 11%|█▏        | 53/468 [09:35<1:11:34, 10.35s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:44:48,397] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.80 | bwd_microstep: 2598.11 | bwd_inner_microstep: 2598.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 15:44:54,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 15:44:54,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1441.77 | bwd_microstep: 5034.22 | bwd_inner_microstep: 2565.14 | bwd_allreduce_microstep: 2469.02 | step_microstep: 7.15\n",
      "[2024-09-15 15:44:54,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2914.55 | bwd: 7632.37 | bwd_inner: 5163.22 | bwd_allreduce: 2469.05 | step: 7.37\n",
      "{'loss': 0.2994, 'learning_rate': 3.927291791871264e-05, 'epoch': 0.35}\n",
      " 12%|█▏        | 54/468 [09:46<1:11:56, 10.43s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 15:44:59,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1477.08 | bwd_microstep: 2612.19 | bwd_inner_microstep: 2612.17 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 15:45:04,396] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 15:45:04,397] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.88 | bwd_microstep: 3436.57 | bwd_inner_microstep: 3421.77 | bwd_allreduce_microstep: 14.76 | step_microstep: 7.69\n",
      "[2024-09-15 15:45:04,397] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3376.94 | bwd: 6048.78 | bwd_inner: 6033.93 | bwd_allreduce: 14.78 | step: 7.91\n",
      "{'loss': 0.2534, 'learning_rate': 3.923539606589473e-05, 'epoch': 0.35}\n",
      " 12%|█▏        | 55/468 [09:55<1:09:50, 10.15s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1396\n",
      "[2024-09-15 15:45:08,601] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1507.66 | bwd_microstep: 2666.51 | bwd_inner_microstep: 2666.48 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 15:45:15,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.05 | optimizer_gradients: 0.40 | optimizer_step: 0.38\n",
      "[2024-09-15 15:45:15,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.14 | bwd_microstep: 4980.32 | bwd_inner_microstep: 2561.03 | bwd_allreduce_microstep: 2419.23 | step_microstep: 10.49\n",
      "[2024-09-15 15:45:15,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2947.77 | bwd: 7646.84 | bwd_inner: 5227.51 | bwd_allreduce: 2419.26 | step: 10.71\n",
      "{'loss': 0.2855, 'learning_rate': 3.919694908314209e-05, 'epoch': 0.36}\n",
      " 12%|█▏        | 56/468 [10:06<1:10:44, 10.30s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:45:20,441] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.64 | bwd_microstep: 3435.70 | bwd_inner_microstep: 3435.68 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:45:25,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.33 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 15:45:25,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.62 | bwd_microstep: 3444.66 | bwd_inner_microstep: 3429.91 | bwd_allreduce_microstep: 14.70 | step_microstep: 8.00\n",
      "[2024-09-15 15:45:25,832] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3825.23 | bwd: 6880.38 | bwd_inner: 6865.59 | bwd_allreduce: 14.72 | step: 8.13\n",
      "{'loss': 0.2889, 'learning_rate': 3.9157578819569455e-05, 'epoch': 0.36}\n",
      " 12%|█▏        | 57/468 [10:17<1:11:31, 10.44s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:45:31,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.92 | bwd_microstep: 3428.03 | bwd_inner_microstep: 3428.00 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1372\n",
      "[2024-09-15 15:45:36,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:45:36,594] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1442.50 | bwd_microstep: 3909.83 | bwd_inner_microstep: 2561.29 | bwd_allreduce_microstep: 1348.48 | step_microstep: 7.56\n",
      "[2024-09-15 15:45:36,594] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3357.40 | bwd: 7337.87 | bwd_inner: 5989.29 | bwd_allreduce: 1348.51 | step: 7.73\n",
      "{'loss': 0.3228, 'learning_rate': 3.9117287168696956e-05, 'epoch': 0.37}\n",
      " 12%|█▏        | 58/468 [10:27<1:12:00, 10.54s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:45:40,741] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.36 | bwd_microstep: 2628.89 | bwd_inner_microstep: 2628.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:45:45,973] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.37 | optimizer_step: 0.37\n",
      "[2024-09-15 15:45:45,974] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.78 | bwd_microstep: 3728.93 | bwd_inner_microstep: 2595.93 | bwd_allreduce_microstep: 1132.95 | step_microstep: 7.17\n",
      "[2024-09-15 15:45:45,974] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.11 | bwd: 6357.83 | bwd_inner: 5224.79 | bwd_allreduce: 1132.98 | step: 7.39\n",
      "{'loss': 0.2197, 'learning_rate': 3.907607606835899e-05, 'epoch': 0.38}\n",
      " 13%|█▎        | 59/468 [10:37<1:09:28, 10.19s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:45:51,343] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.47 | bwd_microstep: 3426.91 | bwd_inner_microstep: 3426.88 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.12\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1368\n",
      "[2024-09-15 15:45:56,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 15:45:56,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.67 | bwd_microstep: 3851.68 | bwd_inner_microstep: 2584.06 | bwd_allreduce_microstep: 1267.56 | step_microstep: 7.51\n",
      "[2024-09-15 15:45:56,690] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3371.11 | bwd: 7278.60 | bwd_inner: 6010.95 | bwd_allreduce: 1267.59 | step: 7.66\n",
      "{'loss': 0.3422, 'learning_rate': 3.903394750061106e-05, 'epoch': 0.38}\n",
      " 13%|█▎        | 60/468 [10:48<1:10:22, 10.35s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:46:00,838] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.11 | bwd_microstep: 2629.30 | bwd_inner_microstep: 2629.28 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:46:07,370] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.04 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 15:46:07,370] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.80 | bwd_microstep: 4578.62 | bwd_inner_microstep: 3440.25 | bwd_allreduce_microstep: 1138.30 | step_microstep: 10.30\n",
      "[2024-09-15 15:46:07,371] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3403.88 | bwd: 7207.93 | bwd_inner: 6069.53 | bwd_allreduce: 1138.33 | step: 10.37\n",
      "{'loss': 0.2788, 'learning_rate': 3.899090349163444e-05, 'epoch': 0.39}\n",
      " 13%|█▎        | 61/468 [10:58<1:10:52, 10.45s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:46:11,519] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.72 | bwd_microstep: 2628.60 | bwd_inner_microstep: 2628.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:46:18,062] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.37 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:46:18,063] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.83 | bwd_microstep: 4565.39 | bwd_inner_microstep: 3488.63 | bwd_allreduce_microstep: 1076.70 | step_microstep: 7.78\n",
      "[2024-09-15 15:46:18,063] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3430.53 | bwd: 7194.00 | bwd_inner: 6117.20 | bwd_allreduce: 1076.73 | step: 8.04\n",
      "{'loss': 0.3245, 'learning_rate': 3.8946946111638696e-05, 'epoch': 0.4}\n",
      " 13%|█▎        | 62/468 [11:09<1:11:11, 10.52s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 15:46:23,409] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.16 | bwd_microstep: 3416.19 | bwd_inner_microstep: 3416.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:46:28,821] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 15:46:28,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.00 | bwd_microstep: 3912.84 | bwd_inner_microstep: 2589.69 | bwd_allreduce_microstep: 1323.09 | step_microstep: 7.55\n",
      "[2024-09-15 15:46:28,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3364.13 | bwd: 7329.07 | bwd_inner: 6005.86 | bwd_allreduce: 1323.12 | step: 7.79\n",
      "{'loss': 0.336, 'learning_rate': 3.8902077474762155e-05, 'epoch': 0.4}\n",
      " 13%|█▎        | 63/468 [11:20<1:11:30, 10.59s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:46:32,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.43 | bwd_microstep: 2588.53 | bwd_inner_microstep: 2588.50 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 15:46:39,470] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.35 | optimizer_step: 0.36\n",
      "[2024-09-15 15:46:39,471] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1437.67 | bwd_microstep: 5091.91 | bwd_inner_microstep: 2554.08 | bwd_allreduce_microstep: 2537.78 | step_microstep: 7.00\n",
      "[2024-09-15 15:46:39,471] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2903.07 | bwd: 7680.46 | bwd_inner: 5142.58 | bwd_allreduce: 2537.80 | step: 7.22\n",
      "{'loss': 0.2951, 'learning_rate': 3.8856299738970225e-05, 'epoch': 0.41}\n",
      " 14%|█▎        | 64/468 [11:30<1:11:26, 10.61s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:46:44,881] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1924.79 | bwd_microstep: 3455.20 | bwd_inner_microstep: 3455.17 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:46:48,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 15:46:48,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.29 | bwd_microstep: 2605.53 | bwd_inner_microstep: 2590.26 | bwd_allreduce_microstep: 15.23 | step_microstep: 7.76\n",
      "[2024-09-15 15:46:48,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.05 | bwd: 6060.74 | bwd_inner: 6045.43 | bwd_allreduce: 15.25 | step: 7.87\n",
      "{'loss': 0.3156, 'learning_rate': 3.880961510595158e-05, 'epoch': 0.42}\n",
      " 14%|█▍        | 65/468 [11:40<1:09:03, 10.28s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:46:53,132] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.12 | bwd_microstep: 2627.10 | bwd_inner_microstep: 2627.01 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:46:58,535] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 15:46:58,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.95 | bwd_microstep: 3454.12 | bwd_inner_microstep: 3439.14 | bwd_allreduce_microstep: 14.93 | step_microstep: 7.70\n",
      "[2024-09-15 15:46:58,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3402.04 | bwd: 6081.26 | bwd_inner: 6066.15 | bwd_allreduce: 14.98 | step: 7.93\n",
      "{'loss': 0.2534, 'learning_rate': 3.876202582101229e-05, 'epoch': 0.42}\n",
      " 14%|█▍        | 66/468 [11:49<1:07:24, 10.06s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1876\n",
      "[2024-09-15 15:47:03,853] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1884.09 | bwd_microstep: 3402.12 | bwd_inner_microstep: 3402.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:47:09,283] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 15:47:09,284] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.45 | bwd_microstep: 3926.39 | bwd_inner_microstep: 2596.01 | bwd_allreduce_microstep: 1330.31 | step_microstep: 7.20\n",
      "[2024-09-15 15:47:09,284] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3354.51 | bwd: 7328.55 | bwd_inner: 5998.10 | bwd_allreduce: 1330.35 | step: 7.43\n",
      "{'loss': 0.2775, 'learning_rate': 3.8713534172967815e-05, 'epoch': 0.43}\n",
      " 14%|█▍        | 67/468 [12:00<1:08:37, 10.27s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1908\n",
      "[2024-09-15 15:47:15,446] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 2375.78 | bwd_microstep: 3755.55 | bwd_inner_microstep: 3755.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:47:20,854] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 15:47:20,854] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.31 | bwd_microstep: 3455.26 | bwd_inner_microstep: 3440.27 | bwd_allreduce_microstep: 14.93 | step_microstep: 7.99\n",
      "[2024-09-15 15:47:20,854] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 4292.06 | bwd: 7210.82 | bwd_inner: 7195.80 | bwd_allreduce: 14.96 | step: 8.22\n",
      "{'loss': 0.3381, 'learning_rate': 3.866414249403295e-05, 'epoch': 0.43}\n",
      " 15%|█▍        | 68/468 [12:12<1:11:03, 10.66s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:47:25,005] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.26 | bwd_microstep: 2628.94 | bwd_inner_microstep: 2628.80 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 15:47:31,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 15:47:31,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.07 | bwd_microstep: 4691.59 | bwd_inner_microstep: 3425.35 | bwd_allreduce_microstep: 1266.19 | step_microstep: 7.19\n",
      "[2024-09-15 15:47:31,635] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3395.31 | bwd: 7320.57 | bwd_inner: 6054.14 | bwd_allreduce: 1266.30 | step: 7.44\n",
      "{'loss': 0.2593, 'learning_rate': 3.861385315970964e-05, 'epoch': 0.44}\n",
      " 15%|█▍        | 69/468 [12:23<1:11:07, 10.70s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:47:37,016] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.02 | bwd_microstep: 3438.89 | bwd_inner_microstep: 3438.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.09\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 15:47:42,361] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:47:42,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1886.56 | bwd_microstep: 3424.47 | bwd_inner_microstep: 3409.39 | bwd_allreduce_microstep: 15.04 | step_microstep: 7.84\n",
      "[2024-09-15 15:47:42,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3798.55 | bwd: 6863.37 | bwd_inner: 6848.25 | bwd_allreduce: 15.06 | step: 7.96\n",
      "{'loss': 0.166, 'learning_rate': 3.856266858867273e-05, 'epoch': 0.45}\n",
      " 15%|█▍        | 70/468 [12:33<1:11:00, 10.70s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:47:46,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.47 | bwd_microstep: 2632.70 | bwd_inner_microstep: 2632.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:47:51,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:47:51,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.14 | bwd_microstep: 3806.80 | bwd_inner_microstep: 2595.76 | bwd_allreduce_microstep: 1210.98 | step_microstep: 7.19\n",
      "[2024-09-15 15:47:51,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2961.59 | bwd: 6439.51 | bwd_inner: 5228.43 | bwd_allreduce: 1211.01 | step: 7.41\n",
      "{'loss': 0.3453, 'learning_rate': 3.851059124265363e-05, 'epoch': 0.45}\n",
      " 15%|█▌        | 71/468 [12:43<1:08:22, 10.33s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:47:57,216] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.84 | bwd_microstep: 3442.15 | bwd_inner_microstep: 3442.12 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:48:02,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 15:48:02,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.79 | bwd_microstep: 3481.43 | bwd_inner_microstep: 3466.64 | bwd_allreduce_microstep: 14.74 | step_microstep: 8.04\n",
      "[2024-09-15 15:48:02,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3848.61 | bwd: 6923.59 | bwd_inner: 6908.76 | bwd_allreduce: 14.76 | step: 8.30\n",
      "{'loss': 0.2238, 'learning_rate': 3.8457623626321944e-05, 'epoch': 0.46}\n",
      " 15%|█▌        | 72/468 [12:54<1:09:12, 10.49s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:48:06,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.16 | bwd_microstep: 2594.36 | bwd_inner_microstep: 2594.33 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:48:13,384] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:48:13,385] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.99 | bwd_microstep: 5120.81 | bwd_inner_microstep: 2596.79 | bwd_allreduce_microstep: 2523.96 | step_microstep: 7.50\n",
      "[2024-09-15 15:48:13,385] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2937.12 | bwd: 7715.18 | bwd_inner: 5191.12 | bwd_allreduce: 2524.00 | step: 7.73\n",
      "{'loss': 0.2773, 'learning_rate': 3.840376828716499e-05, 'epoch': 0.47}\n",
      " 16%|█▌        | 73/468 [13:04<1:09:29, 10.55s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 15:48:17,468] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.37 | bwd_microstep: 2591.75 | bwd_inner_microstep: 2591.72 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:48:24,044] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.36 | optimizer_step: 0.37\n",
      "[2024-09-15 15:48:24,045] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.39 | bwd_microstep: 4622.85 | bwd_inner_microstep: 3443.40 | bwd_allreduce_microstep: 1179.40 | step_microstep: 7.01\n",
      "[2024-09-15 15:48:24,045] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.73 | bwd: 7214.61 | bwd_inner: 6035.12 | bwd_allreduce: 1179.42 | step: 7.24\n",
      "{'loss': 0.2777, 'learning_rate': 3.834902781536527e-05, 'epoch': 0.47}\n",
      " 16%|█▌        | 74/468 [13:15<1:09:31, 10.59s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:48:29,424] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.39 | bwd_microstep: 3436.48 | bwd_inner_microstep: 3436.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1880\n",
      "[2024-09-15 15:48:34,910] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 15:48:34,910] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1947.33 | bwd_microstep: 3503.51 | bwd_inner_microstep: 3488.52 | bwd_allreduce_microstep: 14.95 | step_microstep: 7.94\n",
      "[2024-09-15 15:48:34,910] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3858.70 | bwd: 6940.00 | bwd_inner: 6924.97 | bwd_allreduce: 14.97 | step: 8.08\n",
      "{'loss': 0.3032, 'learning_rate': 3.8293404843675904e-05, 'epoch': 0.48}\n",
      " 16%|█▌        | 75/468 [13:26<1:09:53, 10.67s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 15:48:40,269] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.98 | bwd_microstep: 3425.59 | bwd_inner_microstep: 3425.56 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:48:44,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.19 | optimizer_gradients: 0.50 | optimizer_step: 0.43\n",
      "[2024-09-15 15:48:44,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.14 | bwd_microstep: 2628.08 | bwd_inner_microstep: 2593.95 | bwd_allreduce_microstep: 34.07 | step_microstep: 9.59\n",
      "[2024-09-15 15:48:44,404] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3371.09 | bwd: 6053.70 | bwd_inner: 6019.52 | bwd_allreduce: 34.10 | step: 9.83\n",
      "{'loss': 0.2138, 'learning_rate': 3.8236902047294015e-05, 'epoch': 0.49}\n",
      " 16%|█▌        | 76/468 [13:35<1:07:24, 10.32s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1876\n",
      "[2024-09-15 15:48:49,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1884.69 | bwd_microstep: 3407.66 | bwd_inner_microstep: 3407.64 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 15:48:53,864] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.39 | optimizer_step: 0.37\n",
      "[2024-09-15 15:48:53,865] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1437.89 | bwd_microstep: 2660.77 | bwd_inner_microstep: 2558.05 | bwd_allreduce_microstep: 102.66 | step_microstep: 7.25\n",
      "[2024-09-15 15:48:53,865] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3322.55 | bwd: 6068.46 | bwd_inner: 5965.69 | bwd_allreduce: 102.69 | step: 7.47\n",
      "{'loss': 0.2605, 'learning_rate': 3.817952214373206e-05, 'epoch': 0.49}\n",
      " 16%|█▋        | 77/468 [13:45<1:05:33, 10.06s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1900\n",
      "[2024-09-15 15:48:59,385] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1970.16 | bwd_microstep: 3518.65 | bwd_inner_microstep: 3518.62 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:49:04,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.32 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:49:04,797] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.66 | bwd_microstep: 3457.78 | bwd_inner_microstep: 3443.09 | bwd_allreduce_microstep: 14.63 | step_microstep: 7.93\n",
      "[2024-09-15 15:49:04,797] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3889.80 | bwd: 6976.43 | bwd_inner: 6961.71 | bwd_allreduce: 14.66 | step: 8.04\n",
      "{'loss': 0.3205, 'learning_rate': 3.812126789268712e-05, 'epoch': 0.5}\n",
      " 17%|█▋        | 78/468 [13:56<1:07:05, 10.32s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:49:08,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.76 | bwd_microstep: 2636.31 | bwd_inner_microstep: 2636.28 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:49:14,375] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 15:49:14,376] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.73 | bwd_microstep: 3912.74 | bwd_inner_microstep: 2598.56 | bwd_allreduce_microstep: 1314.12 | step_microstep: 7.26\n",
      "[2024-09-15 15:49:14,376] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2962.47 | bwd: 6549.06 | bwd_inner: 5234.84 | bwd_allreduce: 1314.15 | step: 7.48\n",
      "{'loss': 0.27, 'learning_rate': 3.806214209590819e-05, 'epoch': 0.5}\n",
      " 17%|█▋        | 79/468 [14:05<1:05:28, 10.10s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 15:49:18,461] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.01 | bwd_microstep: 2595.41 | bwd_inner_microstep: 2595.27 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:49:23,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.35 | optimizer_step: 0.39\n",
      "[2024-09-15 15:49:23,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1949.34 | bwd_microstep: 3503.56 | bwd_inner_microstep: 3488.68 | bwd_allreduce_microstep: 14.84 | step_microstep: 7.73\n",
      "[2024-09-15 15:49:23,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3409.32 | bwd: 6099.00 | bwd_inner: 6083.95 | bwd_allreduce: 14.93 | step: 7.96\n",
      "{'loss': 0.2882, 'learning_rate': 3.80021475970614e-05, 'epoch': 0.51}\n",
      " 17%|█▋        | 80/468 [14:15<1:04:17,  9.94s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 15:49:28,107] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.10 | bwd_microstep: 2634.97 | bwd_inner_microstep: 2634.94 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:49:33,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.35 | optimizer_step: 0.38\n",
      "[2024-09-15 15:49:33,519] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.62 | bwd_microstep: 3459.52 | bwd_inner_microstep: 3444.59 | bwd_allreduce_microstep: 14.88 | step_microstep: 7.56\n",
      "[2024-09-15 15:49:33,519] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3408.70 | bwd: 6094.52 | bwd_inner: 6079.53 | bwd_allreduce: 14.90 | step: 7.79\n",
      "{'loss': 0.3081, 'learning_rate': 3.7941287281593284e-05, 'epoch': 0.52}\n",
      " 17%|█▋        | 81/468 [14:24<1:03:24,  9.83s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:49:38,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.22 | bwd_microstep: 3446.49 | bwd_inner_microstep: 3446.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 15:49:44,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:49:44,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1889.51 | bwd_microstep: 3432.12 | bwd_inner_microstep: 3410.97 | bwd_allreduce_microstep: 21.10 | step_microstep: 8.47\n",
      "[2024-09-15 15:49:44,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3809.71 | bwd: 6878.64 | bwd_inner: 6857.43 | bwd_allreduce: 21.13 | step: 8.69\n",
      "{'loss': 0.3268, 'learning_rate': 3.787956407659198e-05, 'epoch': 0.52}\n",
      " 18%|█▊        | 82/468 [14:35<1:05:01, 10.11s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:49:48,438] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.26 | bwd_microstep: 2630.69 | bwd_inner_microstep: 2630.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:49:53,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:49:53,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.03 | bwd_microstep: 3782.71 | bwd_inner_microstep: 2596.64 | bwd_allreduce_microstep: 1186.01 | step_microstep: 7.45\n",
      "[2024-09-15 15:49:53,726] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2963.26 | bwd: 6413.44 | bwd_inner: 5227.31 | bwd_allreduce: 1186.04 | step: 7.68\n",
      "{'loss': 0.2018, 'learning_rate': 3.781698095064647e-05, 'epoch': 0.53}\n",
      " 18%|█▊        | 83/468 [14:45<1:03:35,  9.91s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 15:49:59,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.31 | bwd_microstep: 3423.54 | bwd_inner_microstep: 3423.52 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:50:04,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.34 | optimizer_step: 0.41\n",
      "[2024-09-15 15:50:04,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.03 | bwd_microstep: 3486.75 | bwd_inner_microstep: 3471.72 | bwd_allreduce_microstep: 14.98 | step_microstep: 7.93\n",
      "[2024-09-15 15:50:04,536] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3833.31 | bwd: 6910.30 | bwd_inner: 6895.24 | bwd_allreduce: 15.00 | step: 8.16\n",
      "{'loss': 0.2624, 'learning_rate': 3.775354091370376e-05, 'epoch': 0.54}\n",
      " 18%|█▊        | 84/468 [14:55<1:05:09, 10.18s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:50:08,693] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.63 | bwd_microstep: 2632.69 | bwd_inner_microstep: 2632.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:50:14,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:50:14,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.49 | bwd_microstep: 3485.89 | bwd_inner_microstep: 3470.55 | bwd_allreduce_microstep: 15.30 | step_microstep: 7.68\n",
      "[2024-09-15 15:50:14,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3432.09 | bwd: 6118.59 | bwd_inner: 6103.21 | bwd_allreduce: 15.32 | step: 7.76\n",
      "{'loss': 0.2042, 'learning_rate': 3.7689247016924186e-05, 'epoch': 0.54}\n",
      " 18%|█▊        | 85/468 [15:05<1:03:54, 10.01s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 15:50:19,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.19 | bwd_microstep: 3466.48 | bwd_inner_microstep: 3466.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1884\n",
      "[2024-09-15 15:50:25,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.35 | optimizer_step: 0.38\n",
      "[2024-09-15 15:50:25,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.88 | bwd_microstep: 3464.91 | bwd_inner_microstep: 3449.81 | bwd_allreduce_microstep: 15.06 | step_microstep: 7.85\n",
      "[2024-09-15 15:50:25,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3856.04 | bwd: 6931.40 | bwd_inner: 6916.26 | bwd_allreduce: 15.08 | step: 8.03\n",
      "{'loss': 0.3193, 'learning_rate': 3.7624102352534615e-05, 'epoch': 0.55}\n",
      " 18%|█▊        | 86/468 [15:16<1:05:20, 10.26s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 15:50:30,439] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.66 | bwd_microstep: 3467.30 | bwd_inner_microstep: 3467.27 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:50:35,857] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 15:50:35,858] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.76 | bwd_microstep: 3461.96 | bwd_inner_microstep: 3447.02 | bwd_allreduce_microstep: 14.88 | step_microstep: 7.85\n",
      "[2024-09-15 15:50:35,858] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3853.39 | bwd: 6929.28 | bwd_inner: 6914.29 | bwd_allreduce: 14.91 | step: 7.98\n",
      "{'loss': 0.2487, 'learning_rate': 3.755811005367974e-05, 'epoch': 0.56}\n",
      " 19%|█▊        | 87/468 [15:27<1:06:17, 10.44s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1901\n",
      "[2024-09-15 15:50:41,342] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1957.00 | bwd_microstep: 3496.40 | bwd_inner_microstep: 3496.37 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 15:50:46,639] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.38 | optimizer_step: 0.40\n",
      "[2024-09-15 15:50:46,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1457.52 | bwd_microstep: 3804.60 | bwd_inner_microstep: 2579.78 | bwd_allreduce_microstep: 1224.77 | step_microstep: 7.48\n",
      "[2024-09-15 15:50:46,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3414.49 | bwd: 7301.01 | bwd_inner: 6076.15 | bwd_allreduce: 1224.80 | step: 7.62\n",
      "{'loss': 0.1408, 'learning_rate': 3.7491273294271386e-05, 'epoch': 0.56}\n",
      " 19%|█▉        | 88/468 [15:38<1:06:46, 10.54s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 15:50:52,001] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.79 | bwd_microstep: 3430.95 | bwd_inner_microstep: 3430.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:50:57,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 15:50:57,496] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1950.46 | bwd_microstep: 3508.02 | bwd_inner_microstep: 3493.36 | bwd_allreduce_microstep: 14.61 | step_microstep: 8.53\n",
      "[2024-09-15 15:50:57,496] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3850.23 | bwd: 6938.98 | bwd_inner: 6924.29 | bwd_allreduce: 14.64 | step: 8.75\n",
      "{'loss': 0.276, 'learning_rate': 3.742359528883588e-05, 'epoch': 0.57}\n",
      " 19%|█▉        | 89/468 [15:48<1:07:11, 10.64s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 15:51:02,819] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1886.38 | bwd_microstep: 3406.33 | bwd_inner_microstep: 3406.30 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1877\n",
      "[2024-09-15 15:51:08,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 15:51:08,236] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.67 | bwd_microstep: 3485.36 | bwd_inner_microstep: 3410.95 | bwd_allreduce_microstep: 74.36 | step_microstep: 7.35\n",
      "[2024-09-15 15:51:08,236] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3783.02 | bwd: 6891.70 | bwd_inner: 6817.25 | bwd_allreduce: 74.39 | step: 7.57\n",
      "{'loss': 0.2293, 'learning_rate': 3.735507929235941e-05, 'epoch': 0.58}\n",
      " 19%|█▉        | 90/468 [15:59<1:07:12, 10.67s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:51:13,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.06 | bwd_microstep: 3432.18 | bwd_inner_microstep: 3432.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:51:19,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 15:51:19,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.61 | bwd_microstep: 3461.74 | bwd_inner_microstep: 3446.60 | bwd_allreduce_microstep: 15.09 | step_microstep: 8.38\n",
      "[2024-09-15 15:51:19,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3830.64 | bwd: 6893.92 | bwd_inner: 6878.75 | bwd_allreduce: 15.11 | step: 8.64\n",
      "{'loss': 0.2223, 'learning_rate': 3.7285728600131535e-05, 'epoch': 0.58}\n",
      " 19%|█▉        | 91/468 [16:10<1:07:15, 10.70s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:51:23,189] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1496.79 | bwd_microstep: 2634.88 | bwd_inner_microstep: 2634.85 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:51:29,860] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:51:29,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.43 | bwd_microstep: 5141.10 | bwd_inner_microstep: 2638.01 | bwd_allreduce_microstep: 2503.02 | step_microstep: 7.53\n",
      "[2024-09-15 15:51:29,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2991.19 | bwd: 7775.99 | bwd_inner: 5272.87 | bwd_allreduce: 2503.06 | step: 7.71\n",
      "{'loss': 0.3011, 'learning_rate': 3.7215546547586596e-05, 'epoch': 0.59}\n",
      " 20%|█▉        | 92/468 [16:21<1:07:19, 10.74s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:51:35,244] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.34 | bwd_microstep: 3438.62 | bwd_inner_microstep: 3438.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:51:40,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:51:40,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.29 | bwd_microstep: 3483.80 | bwd_inner_microstep: 3468.69 | bwd_allreduce_microstep: 15.06 | step_microstep: 7.79\n",
      "[2024-09-15 15:51:40,698] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3847.61 | bwd: 6922.44 | bwd_inner: 6907.29 | bwd_allreduce: 15.08 | step: 8.03\n",
      "{'loss': 0.2439, 'learning_rate': 3.7144536510143436e-05, 'epoch': 0.59}\n",
      " 20%|█▉        | 93/468 [16:32<1:07:19, 10.77s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:51:46,083] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.97 | bwd_microstep: 3438.48 | bwd_inner_microstep: 3438.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:51:50,199] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 15:51:50,199] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.44 | bwd_microstep: 2613.09 | bwd_inner_microstep: 2597.88 | bwd_allreduce_microstep: 15.17 | step_microstep: 8.30\n",
      "[2024-09-15 15:51:50,199] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3383.38 | bwd: 6051.58 | bwd_inner: 6036.33 | bwd_allreduce: 15.19 | step: 8.52\n",
      "{'loss': 0.2061, 'learning_rate': 3.707270190304294e-05, 'epoch': 0.6}\n",
      " 20%|██        | 94/468 [16:41<1:04:46, 10.39s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:51:55,570] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.17 | bwd_microstep: 3426.07 | bwd_inner_microstep: 3426.04 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1880\n",
      "[2024-09-15 15:52:00,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:52:00,987] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.95 | bwd_microstep: 3460.83 | bwd_inner_microstep: 3445.74 | bwd_allreduce_microstep: 15.04 | step_microstep: 7.77\n",
      "[2024-09-15 15:52:00,987] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3834.10 | bwd: 6886.91 | bwd_inner: 6871.79 | bwd_allreduce: 15.06 | step: 7.99\n",
      "{'loss': 0.1888, 'learning_rate': 3.7000046181183834e-05, 'epoch': 0.61}\n",
      " 20%|██        | 95/468 [16:52<1:05:20, 10.51s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1877\n",
      "[2024-09-15 15:52:06,353] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.87 | bwd_microstep: 3423.95 | bwd_inner_microstep: 3423.93 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:52:11,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 15:52:11,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.36 | bwd_microstep: 3459.84 | bwd_inner_microstep: 3445.12 | bwd_allreduce_microstep: 14.66 | step_microstep: 7.97\n",
      "[2024-09-15 15:52:11,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3830.20 | bwd: 6883.80 | bwd_inner: 6869.05 | bwd_allreduce: 14.68 | step: 8.22\n",
      "{'loss': 0.2698, 'learning_rate': 3.692657283895651e-05, 'epoch': 0.61}\n",
      " 21%|██        | 96/468 [17:03<1:05:39, 10.59s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:52:17,161] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.46 | bwd_microstep: 3443.50 | bwd_inner_microstep: 3443.47 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 15:52:22,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:52:22,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1903.83 | bwd_microstep: 3441.69 | bwd_inner_microstep: 3426.70 | bwd_allreduce_microstep: 14.94 | step_microstep: 8.22\n",
      "[2024-09-15 15:52:22,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3823.27 | bwd: 6885.20 | bwd_inner: 6870.18 | bwd_allreduce: 14.96 | step: 8.46\n",
      "{'loss': 0.1813, 'learning_rate': 3.6852285410074974e-05, 'epoch': 0.62}\n",
      " 21%|██        | 97/468 [17:13<1:05:49, 10.65s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:52:27,936] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.09 | bwd_microstep: 3444.38 | bwd_inner_microstep: 3444.36 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.29\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:52:33,187] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:52:33,187] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.51 | bwd_microstep: 3745.76 | bwd_inner_microstep: 2598.35 | bwd_allreduce_microstep: 1147.36 | step_microstep: 7.88\n",
      "[2024-09-15 15:52:33,187] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3387.57 | bwd: 7190.16 | bwd_inner: 6042.70 | bwd_allreduce: 1147.39 | step: 8.17\n",
      "{'loss': 0.3824, 'learning_rate': 3.6777187467406857e-05, 'epoch': 0.63}\n",
      " 21%|██        | 98/468 [17:24<1:05:38, 10.65s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:52:38,564] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.24 | bwd_microstep: 3433.24 | bwd_inner_microstep: 3433.22 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.29\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:52:43,979] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 15:52:43,979] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.22 | bwd_microstep: 3462.08 | bwd_inner_microstep: 3446.91 | bwd_allreduce_microstep: 15.13 | step_microstep: 8.11\n",
      "[2024-09-15 15:52:43,979] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3829.43 | bwd: 6895.34 | bwd_inner: 6880.13 | bwd_allreduce: 15.15 | step: 8.34\n",
      "{'loss': 0.2891, 'learning_rate': 3.6701282622801626e-05, 'epoch': 0.63}\n",
      " 21%|██        | 99/468 [17:35<1:05:44, 10.69s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:52:49,371] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.55 | bwd_microstep: 3440.86 | bwd_inner_microstep: 3440.83 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:52:54,787] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 15:52:54,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.47 | bwd_microstep: 3461.07 | bwd_inner_microstep: 3445.71 | bwd_allreduce_microstep: 15.32 | step_microstep: 8.14\n",
      "[2024-09-15 15:52:54,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3838.99 | bwd: 6901.94 | bwd_inner: 6886.54 | bwd_allreduce: 15.34 | step: 8.37\n",
      "{'loss': 0.1906, 'learning_rate': 3.662457452691682e-05, 'epoch': 0.64}\n",
      " 21%|██▏       | 100/468 [17:46<1:05:46, 10.73s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:52:58,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.22 | bwd_microstep: 2638.29 | bwd_inner_microstep: 2638.26 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 15:53:04,411] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.34 | optimizer_step: 0.40\n",
      "[2024-09-15 15:53:04,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1940.54 | bwd_microstep: 3484.33 | bwd_inner_microstep: 3469.01 | bwd_allreduce_microstep: 15.27 | step_microstep: 7.90\n",
      "[2024-09-15 15:53:04,412] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3433.74 | bwd: 6122.65 | bwd_inner: 6107.27 | bwd_allreduce: 15.29 | step: 8.12\n",
      "{'loss': 0.2127, 'learning_rate': 3.6547066869042524e-05, 'epoch': 0.65}\n",
      " 22%|██▏       | 101/468 [17:55<1:03:34, 10.39s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:53:09,752] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.51 | bwd_microstep: 3411.10 | bwd_inner_microstep: 3411.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 15:53:15,078] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:53:15,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1457.84 | bwd_microstep: 3834.01 | bwd_inner_microstep: 2577.16 | bwd_allreduce_microstep: 1256.79 | step_microstep: 7.58\n",
      "[2024-09-15 15:53:15,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3357.32 | bwd: 7245.12 | bwd_inner: 5988.23 | bwd_allreduce: 1256.82 | step: 7.79\n",
      "{'loss': 0.3177, 'learning_rate': 3.6468763376923886e-05, 'epoch': 0.65}\n",
      " 22%|██▏       | 102/468 [18:06<1:03:54, 10.48s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:53:20,420] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1895.29 | bwd_microstep: 3415.27 | bwd_inner_microstep: 3415.24 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 15:53:25,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 15:53:25,718] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.84 | bwd_microstep: 3807.82 | bwd_inner_microstep: 2578.60 | bwd_allreduce_microstep: 1229.16 | step_microstep: 7.43\n",
      "[2024-09-15 15:53:25,718] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3351.10 | bwd: 7223.10 | bwd_inner: 5993.85 | bwd_allreduce: 1229.19 | step: 7.67\n",
      "{'loss': 0.1738, 'learning_rate': 3.638966781658187e-05, 'epoch': 0.66}\n",
      " 22%|██▏       | 103/468 [18:17<1:04:01, 10.53s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 15:53:31,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.72 | bwd_microstep: 3455.70 | bwd_inner_microstep: 3455.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:53:35,244] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.39 | optimizer_step: 0.42\n",
      "[2024-09-15 15:53:35,245] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.45 | bwd_microstep: 2613.28 | bwd_inner_microstep: 2599.95 | bwd_allreduce_microstep: 13.28 | step_microstep: 8.06\n",
      "[2024-09-15 15:53:35,245] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.15 | bwd: 6068.99 | bwd_inner: 6055.62 | bwd_allreduce: 13.30 | step: 8.25\n",
      "{'loss': 0.1801, 'learning_rate': 3.630978399213206e-05, 'epoch': 0.66}\n",
      " 22%|██▏       | 104/468 [18:26<1:02:02, 10.23s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:53:39,406] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.56 | bwd_microstep: 2636.48 | bwd_inner_microstep: 2636.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:53:44,720] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.44 | optimizer_step: 0.40\n",
      "[2024-09-15 15:53:44,721] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.09 | bwd_microstep: 3811.89 | bwd_inner_microstep: 2595.82 | bwd_allreduce_microstep: 1216.01 | step_microstep: 8.29\n",
      "[2024-09-15 15:53:44,721] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2960.62 | bwd: 6448.39 | bwd_inner: 5232.27 | bwd_allreduce: 1216.05 | step: 8.35\n",
      "{'loss': 0.2335, 'learning_rate': 3.622911574560181e-05, 'epoch': 0.67}\n",
      " 22%|██▏       | 105/468 [18:36<1:00:30, 10.00s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 15:53:50,071] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1898.15 | bwd_microstep: 3417.01 | bwd_inner_microstep: 3416.56 | bwd_allreduce_microstep: 0.09 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 15:53:55,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:53:55,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.22 | bwd_microstep: 3931.00 | bwd_inner_microstep: 2571.10 | bwd_allreduce_microstep: 1359.84 | step_microstep: 7.53\n",
      "[2024-09-15 15:53:55,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3353.34 | bwd: 7348.03 | bwd_inner: 5987.69 | bwd_allreduce: 1360.20 | step: 7.80\n",
      "{'loss': 0.2521, 'learning_rate': 3.6147666956745364e-05, 'epoch': 0.68}\n",
      " 23%|██▎       | 106/468 [18:46<1:01:46, 10.24s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:54:00,975] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1945.92 | bwd_microstep: 3484.29 | bwd_inner_microstep: 3484.26 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:54:06,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:54:06,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.80 | bwd_microstep: 3459.70 | bwd_inner_microstep: 3444.23 | bwd_allreduce_microstep: 15.42 | step_microstep: 8.11\n",
      "[2024-09-15 15:54:06,389] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3863.70 | bwd: 6944.00 | bwd_inner: 6928.49 | bwd_allreduce: 15.44 | step: 8.30\n",
      "{'loss': 0.204, 'learning_rate': 3.60654415428573e-05, 'epoch': 0.68}\n",
      " 23%|██▎       | 107/468 [18:57<1:02:44, 10.43s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 15:54:11,713] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1890.93 | bwd_microstep: 3403.51 | bwd_inner_microstep: 3403.37 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:54:17,031] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.29 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 15:54:17,032] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.25 | bwd_microstep: 3809.97 | bwd_inner_microstep: 2598.69 | bwd_allreduce_microstep: 1211.22 | step_microstep: 8.18\n",
      "[2024-09-15 15:54:17,032] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3362.16 | bwd: 7213.53 | bwd_inner: 6002.07 | bwd_allreduce: 1211.33 | step: 8.44\n",
      "{'loss': 0.2199, 'learning_rate': 3.598244345858412e-05, 'epoch': 0.69}\n",
      " 23%|██▎       | 108/468 [19:08<1:02:57, 10.49s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:54:21,186] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.01 | bwd_microstep: 2631.32 | bwd_inner_microstep: 2631.20 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:54:27,750] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:54:27,750] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.55 | bwd_microstep: 4608.48 | bwd_inner_microstep: 3443.91 | bwd_allreduce_microstep: 1164.50 | step_microstep: 7.47\n",
      "[2024-09-15 15:54:27,751] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3411.54 | bwd: 7239.84 | bwd_inner: 6075.11 | bwd_allreduce: 1164.59 | step: 7.73\n",
      "{'loss': 0.322, 'learning_rate': 3.589867669573404e-05, 'epoch': 0.7}\n",
      " 23%|██▎       | 109/468 [19:19<1:03:11, 10.56s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:54:33,137] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.41 | bwd_microstep: 3438.26 | bwd_inner_microstep: 3438.23 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:54:38,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.35 | optimizer_step: 0.39\n",
      "[2024-09-15 15:54:38,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.03 | bwd_microstep: 3462.43 | bwd_inner_microstep: 3446.78 | bwd_allreduce_microstep: 15.61 | step_microstep: 7.85\n",
      "[2024-09-15 15:54:38,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3837.41 | bwd: 6900.70 | bwd_inner: 6885.01 | bwd_allreduce: 15.63 | step: 8.03\n",
      "{'loss': 0.2733, 'learning_rate': 3.5814145283085055e-05, 'epoch': 0.7}\n",
      " 24%|██▎       | 110/468 [19:29<1:03:27, 10.63s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:54:43,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.50 | bwd_microstep: 3432.95 | bwd_inner_microstep: 3432.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:54:49,376] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:54:49,376] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.49 | bwd_microstep: 3935.98 | bwd_inner_microstep: 2595.38 | bwd_allreduce_microstep: 1340.54 | step_microstep: 7.90\n",
      "[2024-09-15 15:54:49,377] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3383.97 | bwd: 7368.94 | bwd_inner: 6028.30 | bwd_allreduce: 1340.57 | step: 8.16\n",
      "{'loss': 0.3102, 'learning_rate': 3.5728853286191075e-05, 'epoch': 0.71}\n",
      " 24%|██▎       | 111/468 [19:40<1:03:36, 10.69s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1366\n",
      "[2024-09-15 15:54:53,446] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.72 | bwd_microstep: 2579.38 | bwd_inner_microstep: 2579.25 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:54:58,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.29 | optimizer_gradients: 0.39 | optimizer_step: 0.41\n",
      "[2024-09-15 15:54:58,800] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.62 | bwd_microstep: 3849.14 | bwd_inner_microstep: 2595.38 | bwd_allreduce_microstep: 1253.69 | step_microstep: 7.57\n",
      "[2024-09-15 15:54:58,801] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2928.32 | bwd: 6428.55 | bwd_inner: 5174.64 | bwd_allreduce: 1253.78 | step: 7.83\n",
      "{'loss': 0.2365, 'learning_rate': 3.56428048071865e-05, 'epoch': 0.72}\n",
      " 24%|██▍       | 112/468 [19:50<1:01:10, 10.31s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1878\n",
      "[2024-09-15 15:55:04,135] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1892.89 | bwd_microstep: 3410.73 | bwd_inner_microstep: 3410.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1878\n",
      "[2024-09-15 15:55:09,465] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 15:55:09,466] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1884.25 | bwd_microstep: 3411.06 | bwd_inner_microstep: 3398.52 | bwd_allreduce_microstep: 12.49 | step_microstep: 8.13\n",
      "[2024-09-15 15:55:09,466] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3777.11 | bwd: 6821.83 | bwd_inner: 6809.18 | bwd_allreduce: 12.52 | step: 8.38\n",
      "{'loss': 0.1718, 'learning_rate': 3.555600398458885e-05, 'epoch': 0.72}\n",
      " 24%|██▍       | 113/468 [20:00<1:01:37, 10.42s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 15:55:14,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.06 | bwd_microstep: 3432.56 | bwd_inner_microstep: 3432.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:55:20,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 15:55:20,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.77 | bwd_microstep: 3481.07 | bwd_inner_microstep: 3468.56 | bwd_allreduce_microstep: 12.47 | step_microstep: 8.68\n",
      "[2024-09-15 15:55:20,298] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3852.80 | bwd: 6913.64 | bwd_inner: 6901.09 | bwd_allreduce: 12.49 | step: 8.87\n",
      "{'loss': 0.198, 'learning_rate': 3.546845499309976e-05, 'epoch': 0.73}\n",
      " 24%|██▍       | 114/468 [20:11<1:02:11, 10.54s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 15:55:24,424] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1481.81 | bwd_microstep: 2613.20 | bwd_inner_microstep: 2613.17 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:55:30,913] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 15:55:30,914] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.56 | bwd_microstep: 4987.68 | bwd_inner_microstep: 2597.68 | bwd_allreduce_microstep: 2389.93 | step_microstep: 7.52\n",
      "[2024-09-15 15:55:30,914] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2952.33 | bwd: 7600.89 | bwd_inner: 5210.86 | bwd_allreduce: 2389.96 | step: 7.57\n",
      "{'loss': 0.2557, 'learning_rate': 3.538016204340418e-05, 'epoch': 0.73}\n",
      " 25%|██▍       | 115/468 [20:22<1:02:08, 10.56s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:55:35,059] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.28 | bwd_microstep: 2624.60 | bwd_inner_microstep: 2624.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:55:40,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 15:55:40,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.46 | bwd_microstep: 3775.45 | bwd_inner_microstep: 2596.63 | bwd_allreduce_microstep: 1178.76 | step_microstep: 7.53\n",
      "[2024-09-15 15:55:40,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2962.71 | bwd: 6400.06 | bwd_inner: 5221.20 | bwd_allreduce: 1178.79 | step: 7.60\n",
      "{'loss': 0.1825, 'learning_rate': 3.529112938196787e-05, 'epoch': 0.74}\n",
      " 25%|██▍       | 116/468 [20:31<59:58, 10.22s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 15:55:45,782] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1943.36 | bwd_microstep: 3467.14 | bwd_inner_microstep: 3467.11 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 15:55:49,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.34 | optimizer_step: 0.42\n",
      "[2024-09-15 15:55:49,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.35 | bwd_microstep: 2588.29 | bwd_inner_microstep: 2573.26 | bwd_allreduce_microstep: 14.98 | step_microstep: 7.70\n",
      "[2024-09-15 15:55:49,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.69 | bwd: 6055.44 | bwd_inner: 6040.38 | bwd_allreduce: 15.00 | step: 7.75\n",
      "{'loss': 0.3099, 'learning_rate': 3.5201361290833165e-05, 'epoch': 0.75}\n",
      " 25%|██▌       | 117/468 [20:41<58:33, 10.01s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:55:54,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.40 | bwd_microstep: 2631.79 | bwd_inner_microstep: 2631.76 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 15:56:00,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.39 | optimizer_step: 0.42\n",
      "[2024-09-15 15:56:00,669] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.33 | bwd_microstep: 5158.54 | bwd_inner_microstep: 2597.42 | bwd_allreduce_microstep: 2561.06 | step_microstep: 7.93\n",
      "[2024-09-15 15:56:00,669] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2959.71 | bwd: 7790.35 | bwd_inner: 5229.18 | bwd_allreduce: 2561.10 | step: 8.16\n",
      "{'loss': 0.3273, 'learning_rate': 3.511086208741303e-05, 'epoch': 0.75}\n",
      " 25%|██▌       | 118/468 [20:52<59:47, 10.25s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 15:56:06,129] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1944.58 | bwd_microstep: 3483.23 | bwd_inner_microstep: 3483.21 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 15:56:11,493] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.35 | optimizer_step: 0.37\n",
      "[2024-09-15 15:56:11,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.71 | bwd_microstep: 3432.62 | bwd_inner_microstep: 3417.52 | bwd_allreduce_microstep: 15.06 | step_microstep: 8.30\n",
      "[2024-09-15 15:56:11,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3845.27 | bwd: 6915.87 | bwd_inner: 6900.73 | bwd_allreduce: 15.08 | step: 8.35\n",
      "{'loss': 0.4337, 'learning_rate': 3.501963612428341e-05, 'epoch': 0.76}\n",
      " 25%|██▌       | 119/468 [21:02<1:00:37, 10.42s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:56:16,877] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.03 | bwd_microstep: 3435.90 | bwd_inner_microstep: 3435.87 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:56:22,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.63 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 15:56:22,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.89 | bwd_microstep: 3841.45 | bwd_inner_microstep: 2594.16 | bwd_allreduce_microstep: 1247.23 | step_microstep: 8.01\n",
      "[2024-09-15 15:56:22,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3388.88 | bwd: 7277.37 | bwd_inner: 6030.04 | bwd_allreduce: 1247.26 | step: 8.11\n",
      "{'loss': 0.2754, 'learning_rate': 3.492768778897388e-05, 'epoch': 0.77}\n",
      " 26%|██▌       | 120/468 [21:13<1:00:59, 10.52s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:56:27,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1931.46 | bwd_microstep: 3459.48 | bwd_inner_microstep: 3459.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:56:32,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 15:56:32,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.35 | bwd_microstep: 3844.17 | bwd_inner_microstep: 2590.15 | bwd_allreduce_microstep: 1253.96 | step_microstep: 8.30\n",
      "[2024-09-15 15:56:32,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3401.78 | bwd: 7303.67 | bwd_inner: 6049.61 | bwd_allreduce: 1253.99 | step: 8.55\n",
      "{'loss': 0.2226, 'learning_rate': 3.483502150375665e-05, 'epoch': 0.77}\n",
      " 26%|██▌       | 121/468 [21:24<1:01:15, 10.59s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 15:56:37,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1436.71 | bwd_microstep: 2550.04 | bwd_inner_microstep: 2550.01 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:56:43,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:56:43,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.11 | bwd_microstep: 4614.35 | bwd_inner_microstep: 3440.54 | bwd_allreduce_microstep: 1173.74 | step_microstep: 7.64\n",
      "[2024-09-15 15:56:43,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3353.79 | bwd: 7164.40 | bwd_inner: 5990.56 | bwd_allreduce: 1173.77 | step: 7.80\n",
      "{'loss': 0.2698, 'learning_rate': 3.474164172543386e-05, 'epoch': 0.78}\n",
      " 26%|██▌       | 122/468 [21:34<1:01:04, 10.59s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 15:56:49,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1933.55 | bwd_microstep: 3465.18 | bwd_inner_microstep: 3465.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:56:54,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:56:54,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.81 | bwd_microstep: 3455.80 | bwd_inner_microstep: 3440.81 | bwd_allreduce_microstep: 14.93 | step_microstep: 8.04\n",
      "[2024-09-15 15:56:54,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3851.32 | bwd: 6920.99 | bwd_inner: 6905.96 | bwd_allreduce: 14.97 | step: 8.11\n",
      "{'loss': 0.2, 'learning_rate': 3.464755294512325e-05, 'epoch': 0.79}\n",
      " 26%|██▋       | 123/468 [21:45<1:01:19, 10.67s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 15:56:58,516] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.12 | bwd_microstep: 2591.67 | bwd_inner_microstep: 2591.49 | bwd_allreduce_microstep: 0.09 | step_microstep: 0.29\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:57:05,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.68 | optimizer_step: 0.46\n",
      "[2024-09-15 15:57:05,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.32 | bwd_microstep: 5178.84 | bwd_inner_microstep: 2592.53 | bwd_allreduce_microstep: 2586.19 | step_microstep: 10.44\n",
      "[2024-09-15 15:57:05,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2942.41 | bwd: 7770.60 | bwd_inner: 5184.02 | bwd_allreduce: 2586.37 | step: 10.72\n",
      "{'loss': 0.1865, 'learning_rate': 3.455275968804212e-05, 'epoch': 0.79}\n",
      " 26%|██▋       | 124/468 [21:56<1:01:20, 10.70s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1900\n",
      "[2024-09-15 15:57:10,571] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1906.96 | bwd_microstep: 3428.61 | bwd_inner_microstep: 3428.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:57:15,895] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 15:57:15,896] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.46 | bwd_microstep: 3823.76 | bwd_inner_microstep: 2589.61 | bwd_allreduce_microstep: 1234.09 | step_microstep: 7.50\n",
      "[2024-09-15 15:57:15,896] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3374.39 | bwd: 7252.38 | bwd_inner: 6018.20 | bwd_allreduce: 1234.12 | step: 7.63\n",
      "{'loss': 0.2586, 'learning_rate': 3.445726651328971e-05, 'epoch': 0.8}\n",
      " 27%|██▋       | 125/468 [22:07<1:01:09, 10.70s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:57:21,316] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1931.69 | bwd_microstep: 3457.20 | bwd_inner_microstep: 3457.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:57:26,555] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.42\n",
      "[2024-09-15 15:57:26,555] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.78 | bwd_microstep: 3736.06 | bwd_inner_microstep: 2589.73 | bwd_allreduce_microstep: 1146.26 | step_microstep: 7.47\n",
      "[2024-09-15 15:57:26,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3400.44 | bwd: 7193.28 | bwd_inner: 6046.91 | bwd_allreduce: 1146.30 | step: 7.75\n",
      "{'loss': 0.3064, 'learning_rate': 3.4361078013627945e-05, 'epoch': 0.81}\n",
      " 27%|██▋       | 126/468 [22:17<1:00:54, 10.69s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 15:57:31,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1898.61 | bwd_microstep: 3413.99 | bwd_inner_microstep: 3413.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 15:57:37,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 15:57:37,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.74 | bwd_microstep: 3964.98 | bwd_inner_microstep: 2591.20 | bwd_allreduce_microstep: 1373.72 | step_microstep: 7.56\n",
      "[2024-09-15 15:57:37,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3367.32 | bwd: 7378.98 | bwd_inner: 6005.16 | bwd_allreduce: 1373.75 | step: 7.62\n",
      "{'loss': 0.21, 'learning_rate': 3.426419881526052e-05, 'epoch': 0.81}\n",
      " 27%|██▋       | 127/468 [22:28<1:00:56, 10.72s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 15:57:42,793] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.47 | bwd_microstep: 3461.73 | bwd_inner_microstep: 3461.71 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1878\n",
      "[2024-09-15 15:57:48,218] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.37 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 15:57:48,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1875.41 | bwd_microstep: 3515.56 | bwd_inner_microstep: 3398.02 | bwd_allreduce_microstep: 117.48 | step_microstep: 7.94\n",
      "[2024-09-15 15:57:48,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3812.85 | bwd: 6977.33 | bwd_inner: 6859.73 | bwd_allreduce: 117.51 | step: 8.18\n",
      "{'loss': 0.1701, 'learning_rate': 3.4166633577610425e-05, 'epoch': 0.82}\n",
      " 27%|██▋       | 128/468 [22:39<1:00:59, 10.76s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:57:53,603] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.76 | bwd_microstep: 3435.00 | bwd_inner_microstep: 3434.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:57:59,007] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 15:57:59,007] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.12 | bwd_microstep: 3451.75 | bwd_inner_microstep: 3436.86 | bwd_allreduce_microstep: 14.84 | step_microstep: 8.29\n",
      "[2024-09-15 15:57:59,007] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3835.86 | bwd: 6886.76 | bwd_inner: 6871.83 | bwd_allreduce: 14.86 | step: 8.51\n",
      "{'loss': 0.2909, 'learning_rate': 3.4068386993095806e-05, 'epoch': 0.82}\n",
      " 28%|██▊       | 129/468 [22:50<1:00:51, 10.77s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 15:58:04,402] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.22 | bwd_microstep: 3436.31 | bwd_inner_microstep: 3436.29 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1880\n",
      "[2024-09-15 15:58:09,815] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 15:58:09,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.55 | bwd_microstep: 3455.83 | bwd_inner_microstep: 3440.61 | bwd_allreduce_microstep: 15.17 | step_microstep: 8.35\n",
      "[2024-09-15 15:58:09,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3840.74 | bwd: 6892.15 | bwd_inner: 6876.90 | bwd_allreduce: 15.19 | step: 8.59\n",
      "{'loss': 0.2558, 'learning_rate': 3.396946378690435e-05, 'epoch': 0.83}\n",
      " 28%|██▊       | 130/468 [23:01<1:00:44, 10.78s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:58:13,968] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.04 | bwd_microstep: 2629.58 | bwd_inner_microstep: 2629.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:58:19,422] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:58:19,422] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.65 | bwd_microstep: 3482.48 | bwd_inner_microstep: 3467.26 | bwd_allreduce_microstep: 15.17 | step_microstep: 7.66\n",
      "[2024-09-15 15:58:19,422] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3430.67 | bwd: 6112.07 | bwd_inner: 6096.81 | bwd_allreduce: 15.20 | step: 7.82\n",
      "{'loss': 0.1833, 'learning_rate': 3.386986871676597e-05, 'epoch': 0.84}\n",
      " 28%|██▊       | 131/468 [23:10<58:34, 10.43s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:58:24,812] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.04 | bwd_microstep: 3439.25 | bwd_inner_microstep: 3439.22 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:58:28,924] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.84 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 15:58:28,925] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.48 | bwd_microstep: 2606.88 | bwd_inner_microstep: 2593.61 | bwd_allreduce_microstep: 13.22 | step_microstep: 9.11\n",
      "[2024-09-15 15:58:28,925] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3389.49 | bwd: 6046.14 | bwd_inner: 6032.83 | bwd_allreduce: 13.24 | step: 9.34\n",
      "{'loss': 0.184, 'learning_rate': 3.3769606572724e-05, 'epoch': 0.84}\n",
      " 28%|██▊       | 132/468 [23:20<56:51, 10.15s/it]dynamic ViT batch size: 32, images per sample: 4.0, dynamic token length: 1878\n",
      "[2024-09-15 15:58:34,164] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1842.72 | bwd_microstep: 3361.09 | bwd_inner_microstep: 3361.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1879\n",
      "[2024-09-15 15:58:39,623] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.35 | optimizer_step: 0.42\n",
      "[2024-09-15 15:58:39,624] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.97 | bwd_microstep: 3486.50 | bwd_inner_microstep: 3471.45 | bwd_allreduce_microstep: 15.01 | step_microstep: 7.97\n",
      "[2024-09-15 15:58:39,624] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3784.67 | bwd: 6847.61 | bwd_inner: 6832.51 | bwd_allreduce: 15.03 | step: 8.12\n",
      "{'loss': 0.2481, 'learning_rate': 3.366868217690482e-05, 'epoch': 0.85}\n",
      " 28%|██▊       | 133/468 [23:31<57:35, 10.32s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:58:45,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1922.33 | bwd_microstep: 3444.45 | bwd_inner_microstep: 3444.42 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 15:58:50,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.39 | optimizer_step: 0.41\n",
      "[2024-09-15 15:58:50,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.87 | bwd_microstep: 3760.89 | bwd_inner_microstep: 2596.74 | bwd_allreduce_microstep: 1164.09 | step_microstep: 7.53\n",
      "[2024-09-15 15:58:50,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3393.17 | bwd: 7205.39 | bwd_inner: 6041.17 | bwd_allreduce: 1164.12 | step: 7.79\n",
      "{'loss': 0.1628, 'learning_rate': 3.3567100383285925e-05, 'epoch': 0.86}\n",
      " 29%|██▊       | 134/468 [23:41<58:00, 10.42s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1901\n",
      "[2024-09-15 15:58:55,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1959.94 | bwd_microstep: 3489.39 | bwd_inner_microstep: 3489.36 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:59:01,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.34 | optimizer_step: 0.40\n",
      "[2024-09-15 15:59:01,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1939.42 | bwd_microstep: 3484.50 | bwd_inner_microstep: 3469.10 | bwd_allreduce_microstep: 15.35 | step_microstep: 8.13\n",
      "[2024-09-15 15:59:01,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3899.33 | bwd: 6973.90 | bwd_inner: 6958.46 | bwd_allreduce: 15.38 | step: 8.33\n",
      "{'loss': 0.1711, 'learning_rate': 3.346486607746249e-05, 'epoch': 0.86}\n",
      " 29%|██▉       | 135/468 [23:52<58:42, 10.58s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 15:59:06,594] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1903.69 | bwd_microstep: 3422.48 | bwd_inner_microstep: 3422.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 15:59:12,050] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:59:12,050] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.70 | bwd_microstep: 3485.98 | bwd_inner_microstep: 3473.29 | bwd_allreduce_microstep: 12.64 | step_microstep: 8.18\n",
      "[2024-09-15 15:59:12,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3842.37 | bwd: 6908.47 | bwd_inner: 6895.75 | bwd_allreduce: 12.66 | step: 8.24\n",
      "{'loss': 0.2293, 'learning_rate': 3.336198417641238e-05, 'epoch': 0.87}\n",
      " 29%|██▉       | 136/468 [24:03<58:55, 10.65s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 15:59:16,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.41 | bwd_microstep: 2598.14 | bwd_inner_microstep: 2598.11 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 15:59:22,810] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.41\n",
      "[2024-09-15 15:59:22,811] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.50 | bwd_microstep: 4716.45 | bwd_inner_microstep: 3448.47 | bwd_allreduce_microstep: 1267.93 | step_microstep: 7.47\n",
      "[2024-09-15 15:59:22,811] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3384.88 | bwd: 7314.61 | bwd_inner: 6046.58 | bwd_allreduce: 1267.96 | step: 7.53\n",
      "{'loss': 0.2515, 'learning_rate': 3.325845962825966e-05, 'epoch': 0.88}\n",
      " 29%|██▉       | 137/468 [24:14<58:56, 10.68s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1902\n",
      "[2024-09-15 15:59:28,253] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1939.54 | bwd_microstep: 3472.22 | bwd_inner_microstep: 3472.19 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 15:59:33,488] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 15:59:33,488] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.33 | bwd_microstep: 3728.91 | bwd_inner_microstep: 2596.10 | bwd_allreduce_microstep: 1132.75 | step_microstep: 7.64\n",
      "[2024-09-15 15:59:33,489] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3409.84 | bwd: 7201.14 | bwd_inner: 6068.30 | bwd_allreduce: 1132.78 | step: 7.73\n",
      "{'loss': 0.1741, 'learning_rate': 3.315429741203666e-05, 'epoch': 0.88}\n",
      " 29%|██▉       | 138/468 [24:24<58:44, 10.68s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 15:59:37,646] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.03 | bwd_microstep: 2633.45 | bwd_inner_microstep: 2633.42 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 15:59:43,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:59:43,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.40 | bwd_microstep: 3459.69 | bwd_inner_microstep: 3446.17 | bwd_allreduce_microstep: 13.48 | step_microstep: 7.56\n",
      "[2024-09-15 15:59:43,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3413.40 | bwd: 6093.15 | bwd_inner: 6079.59 | bwd_allreduce: 13.50 | step: 7.69\n",
      "{'loss': 0.1595, 'learning_rate': 3.304950253744443e-05, 'epoch': 0.89}\n",
      " 30%|██▉       | 139/468 [24:34<56:44, 10.35s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1876\n",
      "[2024-09-15 15:59:48,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1889.90 | bwd_microstep: 3400.22 | bwd_inner_microstep: 3400.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1877\n",
      "[2024-09-15 15:59:53,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 15:59:53,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1953.56 | bwd_microstep: 3505.64 | bwd_inner_microstep: 3490.51 | bwd_allreduce_microstep: 15.08 | step_microstep: 7.83\n",
      "[2024-09-15 15:59:53,876] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3843.43 | bwd: 6905.89 | bwd_inner: 6890.65 | bwd_allreduce: 15.12 | step: 8.07\n",
      "{'loss': 0.1889, 'learning_rate': 3.294408004461188e-05, 'epoch': 0.89}\n",
      " 30%|██▉       | 140/468 [24:45<57:20, 10.49s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 15:59:58,034] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.48 | bwd_microstep: 2633.58 | bwd_inner_microstep: 2633.49 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:00:04,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:00:04,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1939.83 | bwd_microstep: 4602.09 | bwd_inner_microstep: 3466.51 | bwd_allreduce_microstep: 1135.52 | step_microstep: 7.48\n",
      "[2024-09-15 16:00:04,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3434.29 | bwd: 7235.71 | bwd_inner: 6100.01 | bwd_allreduce: 1135.58 | step: 7.73\n",
      "{'loss': 0.2864, 'learning_rate': 3.283803500385332e-05, 'epoch': 0.9}\n",
      " 30%|███       | 141/468 [24:56<57:34, 10.56s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:00:08,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.52 | bwd_microstep: 2628.72 | bwd_inner_microstep: 2628.69 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:00:14,181] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 16:00:14,182] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.68 | bwd_microstep: 3459.19 | bwd_inner_microstep: 3443.88 | bwd_allreduce_microstep: 15.27 | step_microstep: 7.49\n",
      "[2024-09-15 16:00:14,182] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3414.17 | bwd: 6087.94 | bwd_inner: 6072.57 | bwd_allreduce: 15.29 | step: 7.73\n",
      "{'loss': 0.1941, 'learning_rate': 3.27313725154246e-05, 'epoch': 0.91}\n",
      " 30%|███       | 142/468 [25:05<55:46, 10.27s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:00:19,574] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.49 | bwd_microstep: 3440.51 | bwd_inner_microstep: 3440.44 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:00:24,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.36 | optimizer_step: 0.42\n",
      "[2024-09-15 16:00:24,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.58 | bwd_microstep: 3459.79 | bwd_inner_microstep: 3444.81 | bwd_allreduce_microstep: 14.93 | step_microstep: 8.54\n",
      "[2024-09-15 16:00:24,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3842.05 | bwd: 6900.33 | bwd_inner: 6885.26 | bwd_allreduce: 14.95 | step: 8.79\n",
      "{'loss': 0.2526, 'learning_rate': 3.2624097709277855e-05, 'epoch': 0.91}\n",
      " 31%|███       | 143/468 [25:16<56:29, 10.43s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 16:00:29,153] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1497.55 | bwd_microstep: 2634.02 | bwd_inner_microstep: 2633.98 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:00:35,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.39 | optimizer_step: 0.41\n",
      "[2024-09-15 16:00:35,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.33 | bwd_microstep: 4996.13 | bwd_inner_microstep: 2597.04 | bwd_allreduce_microstep: 2399.04 | step_microstep: 7.57\n",
      "[2024-09-15 16:00:35,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2968.86 | bwd: 7630.19 | bwd_inner: 5231.02 | bwd_allreduce: 2399.07 | step: 7.80\n",
      "{'loss': 0.1784, 'learning_rate': 3.251621574481475e-05, 'epoch': 0.92}\n",
      " 31%|███       | 144/468 [25:27<56:41, 10.50s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:00:41,046] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.76 | bwd_microstep: 3440.40 | bwd_inner_microstep: 3440.37 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:00:46,497] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:00:46,497] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.85 | bwd_microstep: 3479.54 | bwd_inner_microstep: 3465.31 | bwd_allreduce_microstep: 14.18 | step_microstep: 8.37\n",
      "[2024-09-15 16:00:46,498] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3852.59 | bwd: 6919.95 | bwd_inner: 6905.69 | bwd_allreduce: 14.20 | step: 8.61\n",
      "{'loss': 0.3217, 'learning_rate': 3.240773181063834e-05, 'epoch': 0.93}\n",
      " 31%|███       | 145/468 [25:37<57:04, 10.60s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 16:00:51,819] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1890.27 | bwd_microstep: 3400.48 | bwd_inner_microstep: 3400.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:00:57,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:00:57,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1923.36 | bwd_microstep: 3459.27 | bwd_inner_microstep: 3444.02 | bwd_allreduce_microstep: 15.21 | step_microstep: 8.49\n",
      "[2024-09-15 16:00:57,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3813.61 | bwd: 6859.78 | bwd_inner: 6844.47 | bwd_allreduce: 15.23 | step: 8.73\n",
      "{'loss': 0.2438, 'learning_rate': 3.229865112430352e-05, 'epoch': 0.93}\n",
      " 31%|███       | 146/468 [25:48<57:07, 10.64s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:01:02,676] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.26 | bwd_microstep: 3461.13 | bwd_inner_microstep: 3461.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1881\n",
      "[2024-09-15 16:01:08,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:01:08,026] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1893.79 | bwd_microstep: 3421.50 | bwd_inner_microstep: 3406.21 | bwd_allreduce_microstep: 15.24 | step_microstep: 7.87\n",
      "[2024-09-15 16:01:08,026] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3832.03 | bwd: 6882.64 | bwd_inner: 6867.31 | bwd_allreduce: 15.26 | step: 8.03\n",
      "{'loss': 0.2797, 'learning_rate': 3.218897893206608e-05, 'epoch': 0.94}\n",
      " 31%|███▏      | 147/468 [25:59<57:10, 10.69s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:01:12,128] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1473.11 | bwd_microstep: 2598.20 | bwd_inner_microstep: 2598.17 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:01:18,772] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:01:18,772] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.27 | bwd_microstep: 5137.56 | bwd_inner_microstep: 2594.08 | bwd_allreduce_microstep: 2543.42 | step_microstep: 7.44\n",
      "[2024-09-15 16:01:18,773] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2945.36 | bwd: 7735.79 | bwd_inner: 5192.26 | bwd_allreduce: 2543.45 | step: 7.69\n",
      "{'loss': 0.2358, 'learning_rate': 3.2078720508630427e-05, 'epoch': 0.95}\n",
      " 32%|███▏      | 148/468 [26:10<57:05, 10.70s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:01:24,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1933.64 | bwd_microstep: 3461.00 | bwd_inner_microstep: 3460.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:01:29,608] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.37 | optimizer_step: 0.40\n",
      "[2024-09-15 16:01:29,608] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.13 | bwd_microstep: 3454.23 | bwd_inner_microstep: 3439.14 | bwd_allreduce_microstep: 15.05 | step_microstep: 8.07\n",
      "[2024-09-15 16:01:29,608] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3852.74 | bwd: 6915.24 | bwd_inner: 6900.11 | bwd_allreduce: 15.07 | step: 8.31\n",
      "{'loss': 0.2403, 'learning_rate': 3.196788115689584e-05, 'epoch': 0.95}\n",
      " 32%|███▏      | 149/468 [26:21<57:07, 10.74s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:01:34,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.77 | bwd_microstep: 3438.64 | bwd_inner_microstep: 3438.62 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:01:40,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 16:01:40,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.93 | bwd_microstep: 3767.86 | bwd_inner_microstep: 2592.34 | bwd_allreduce_microstep: 1175.46 | step_microstep: 7.65\n",
      "[2024-09-15 16:01:40,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3389.67 | bwd: 7206.52 | bwd_inner: 6030.96 | bwd_allreduce: 1175.49 | step: 7.90\n",
      "{'loss': 0.2295, 'learning_rate': 3.185646620770146e-05, 'epoch': 0.96}\n",
      " 32%|███▏      | 150/468 [26:31<56:49, 10.72s/it]dynamic ViT batch size: 45, images per sample: 5.625, dynamic token length: 1878\n",
      "[2024-09-15 16:01:45,720] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1939.84 | bwd_microstep: 3474.34 | bwd_inner_microstep: 3474.31 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.28\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 16:01:50,855] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:01:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.08 | bwd_microstep: 3661.92 | bwd_inner_microstep: 2554.65 | bwd_allreduce_microstep: 1107.22 | step_microstep: 7.64\n",
      "[2024-09-15 16:01:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.89 | bwd: 7136.27 | bwd_inner: 6028.96 | bwd_allreduce: 1107.23 | step: 7.94\n",
      "{'loss': 0.2063, 'learning_rate': 3.1744481019569885e-05, 'epoch': 0.96}\n",
      " 32%|███▏      | 151/468 [26:42<56:25, 10.68s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:01:56,317] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1946.85 | bwd_microstep: 3482.23 | bwd_inner_microstep: 3482.19 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1880\n",
      "[2024-09-15 16:02:01,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:02:01,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.67 | bwd_microstep: 3480.12 | bwd_inner_microstep: 3465.22 | bwd_allreduce_microstep: 14.85 | step_microstep: 8.21\n",
      "[2024-09-15 16:02:01,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3881.50 | bwd: 6962.39 | bwd_inner: 6947.42 | bwd_allreduce: 14.87 | step: 8.47\n",
      "{'loss': 0.2654, 'learning_rate': 3.163193097844949e-05, 'epoch': 0.97}\n",
      " 32%|███▏      | 152/468 [26:53<56:36, 10.75s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:02:07,151] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.88 | bwd_microstep: 3435.25 | bwd_inner_microstep: 3435.23 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.12\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:02:12,563] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 16:02:12,564] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.40 | bwd_microstep: 3456.84 | bwd_inner_microstep: 3443.19 | bwd_allreduce_microstep: 13.60 | step_microstep: 8.11\n",
      "[2024-09-15 16:02:12,564] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3838.25 | bwd: 6892.10 | bwd_inner: 6878.41 | bwd_allreduce: 13.62 | step: 8.26\n",
      "{'loss': 0.2071, 'learning_rate': 3.1518821497455326e-05, 'epoch': 0.98}\n",
      " 33%|███▎      | 153/468 [27:03<56:30, 10.76s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 16:02:17,954] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1922.68 | bwd_microstep: 3437.62 | bwd_inner_microstep: 3437.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1880\n",
      "[2024-09-15 16:02:23,378] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.34 | optimizer_step: 0.40\n",
      "[2024-09-15 16:02:23,379] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1923.92 | bwd_microstep: 3464.17 | bwd_inner_microstep: 3449.08 | bwd_allreduce_microstep: 15.05 | step_microstep: 8.13\n",
      "[2024-09-15 16:02:23,379] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3846.58 | bwd: 6901.80 | bwd_inner: 6886.67 | bwd_allreduce: 15.07 | step: 8.25\n",
      "{'loss': 0.2035, 'learning_rate': 3.1405158016608806e-05, 'epoch': 0.98}\n",
      " 33%|███▎      | 154/468 [27:14<56:24, 10.78s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1394\n",
      "[2024-09-15 16:02:27,580] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1507.36 | bwd_microstep: 2663.19 | bwd_inner_microstep: 2663.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 16:02:34,045] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:02:34,045] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1458.72 | bwd_microstep: 4972.41 | bwd_inner_microstep: 2575.10 | bwd_allreduce_microstep: 2397.24 | step_microstep: 7.49\n",
      "[2024-09-15 16:02:34,046] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2966.06 | bwd: 7635.61 | bwd_inner: 5238.27 | bwd_allreduce: 2397.28 | step: 7.76\n",
      "{'loss': 0.2398, 'learning_rate': 3.129094600257611e-05, 'epoch': 0.99}\n",
      " 33%|███▎      | 155/468 [27:25<56:03, 10.75s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 16:02:39,430] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.18 | bwd_microstep: 3439.16 | bwd_inner_microstep: 3439.13 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 16:02:44,810] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 16:02:44,811] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.78 | bwd_microstep: 3907.01 | bwd_inner_microstep: 2552.79 | bwd_allreduce_microstep: 1354.12 | step_microstep: 7.57\n",
      "[2024-09-15 16:02:44,811] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3353.93 | bwd: 7346.20 | bwd_inner: 5991.93 | bwd_allreduce: 1354.12 | step: 7.81\n",
      "{'loss': 0.1623, 'learning_rate': 3.1176190948405194e-05, 'epoch': 1.0}\n",
      " 33%|███▎      | 156/468 [27:36<55:54, 10.75s/it]petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1878\n",
      "[2024-09-15 16:02:51,276] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1906.34 | bwd_microstep: 3418.42 | bwd_inner_microstep: 3418.39 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "[2024-09-15 16:02:53,613] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:53,631] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:53,661] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:53,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:57,384] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:57,441] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:57,530] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:02:57,531] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:01,109] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:01,156] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:01,280] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:01,311] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:04,874] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:04,891] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:05,004] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:03:05,026] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:03:12,877] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 16:03:12,877] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.40 | bwd_microstep: 3420.65 | bwd_inner_microstep: 3405.84 | bwd_allreduce_microstep: 14.77 | step_microstep: 7.88\n",
      "[2024-09-15 16:03:12,877] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3806.71 | bwd: 6839.12 | bwd_inner: 6824.22 | bwd_allreduce: 14.79 | step: 8.13\n",
      "{'loss': 0.2313, 'learning_rate': 3.106089837326161e-05, 'epoch': 1.0}\n",
      " 34%|███▎      | 157/468 [28:04<1:22:39, 15.95s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:03:18,209] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1894.64 | bwd_microstep: 3406.46 | bwd_inner_microstep: 3406.43 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1902\n",
      "[2024-09-15 16:03:23,605] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:03:23,605] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.36 | bwd_microstep: 3447.44 | bwd_inner_microstep: 3432.88 | bwd_allreduce_microstep: 14.52 | step_microstep: 8.27\n",
      "[2024-09-15 16:03:23,605] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3811.98 | bwd: 6853.91 | bwd_inner: 6839.31 | bwd_allreduce: 14.53 | step: 8.32\n",
      "{'loss': 0.2687, 'learning_rate': 3.094507382216312e-05, 'epoch': 1.01}\n",
      " 34%|███▍      | 158/468 [28:15<1:14:17, 14.38s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:03:27,673] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.55 | bwd_microstep: 2577.07 | bwd_inner_microstep: 2577.04 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:03:33,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:03:33,089] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.29 | bwd_microstep: 3918.14 | bwd_inner_microstep: 2578.81 | bwd_allreduce_microstep: 1339.27 | step_microstep: 7.46\n",
      "[2024-09-15 16:03:33,089] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2921.81 | bwd: 6495.22 | bwd_inner: 5155.85 | bwd_allreduce: 1339.30 | step: 7.57\n",
      "{'loss': 0.246, 'learning_rate': 3.082872286571295e-05, 'epoch': 1.02}\n",
      " 34%|███▍      | 159/468 [28:24<1:06:29, 12.91s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:03:37,157] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.00 | bwd_microstep: 2577.85 | bwd_inner_microstep: 2577.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:03:42,565] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:03:42,565] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1486.74 | bwd_microstep: 3886.88 | bwd_inner_microstep: 2620.29 | bwd_allreduce_microstep: 1266.53 | step_microstep: 7.57\n",
      "[2024-09-15 16:03:42,565] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2946.71 | bwd: 6464.77 | bwd_inner: 5198.10 | bwd_allreduce: 1266.56 | step: 7.80\n",
      "{'loss': 0.191, 'learning_rate': 3.0711851099831885e-05, 'epoch': 1.02}\n",
      " 34%|███▍      | 160/468 [28:33<1:00:59, 11.88s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:03:46,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.82 | bwd_microstep: 2578.18 | bwd_inner_microstep: 2578.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:03:51,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:03:51,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1486.73 | bwd_microstep: 3808.83 | bwd_inner_microstep: 2620.55 | bwd_allreduce_microstep: 1188.22 | step_microstep: 7.26\n",
      "[2024-09-15 16:03:51,966] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2946.52 | bwd: 6387.02 | bwd_inner: 5198.71 | bwd_allreduce: 1188.25 | step: 7.49\n",
      "{'loss': 0.1543, 'learning_rate': 3.059446414548915e-05, 'epoch': 1.03}\n",
      " 34%|███▍      | 161/468 [28:43<56:58, 11.14s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:03:56,035] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.03 | bwd_microstep: 2578.69 | bwd_inner_microstep: 2578.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:04:02,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:04:02,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.78 | bwd_microstep: 4687.16 | bwd_inner_microstep: 3433.56 | bwd_allreduce_microstep: 1253.54 | step_microstep: 7.18\n",
      "[2024-09-15 16:04:02,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3369.79 | bwd: 7265.88 | bwd_inner: 6012.22 | bwd_allreduce: 1253.57 | step: 7.42\n",
      "{'loss': 0.1978, 'learning_rate': 3.047656764843203e-05, 'epoch': 1.04}\n",
      " 35%|███▍      | 162/468 [28:54<56:07, 11.01s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:04:06,742] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.64 | bwd_microstep: 2582.79 | bwd_inner_microstep: 2582.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:04:13,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:04:13,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.70 | bwd_microstep: 4611.47 | bwd_inner_microstep: 3411.83 | bwd_allreduce_microstep: 1199.58 | step_microstep: 7.58\n",
      "[2024-09-15 16:04:13,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3358.32 | bwd: 7194.28 | bwd_inner: 5994.60 | bwd_allreduce: 1199.61 | step: 7.63\n",
      "{'loss': 0.2698, 'learning_rate': 3.0358167278914387e-05, 'epoch': 1.04}\n",
      " 35%|███▍      | 163/468 [29:04<55:21, 10.89s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:04:17,356] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.19 | bwd_microstep: 2583.97 | bwd_inner_microstep: 2583.90 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:04:24,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.39 | optimizer_step: 0.39\n",
      "[2024-09-15 16:04:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.77 | bwd_microstep: 5170.78 | bwd_inner_microstep: 2586.94 | bwd_allreduce_microstep: 2583.78 | step_microstep: 7.52\n",
      "[2024-09-15 16:04:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2926.94 | bwd: 7754.79 | bwd_inner: 5170.84 | bwd_allreduce: 2583.82 | step: 7.75\n",
      "{'loss': 0.2351, 'learning_rate': 3.023926873142391e-05, 'epoch': 1.05}\n",
      " 35%|███▌      | 164/468 [29:15<54:57, 10.85s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:04:28,102] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.72 | bwd_microstep: 2582.52 | bwd_inner_microstep: 2582.49 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:04:34,686] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.37 | optimizer_step: 0.37\n",
      "[2024-09-15 16:04:34,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.35 | bwd_microstep: 4637.38 | bwd_inner_microstep: 3433.83 | bwd_allreduce_microstep: 1203.49 | step_microstep: 7.54\n",
      "[2024-09-15 16:04:34,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3372.05 | bwd: 7219.91 | bwd_inner: 6016.32 | bwd_allreduce: 1203.52 | step: 7.76\n",
      "{'loss': 0.1925, 'learning_rate': 3.011987772440825e-05, 'epoch': 1.05}\n",
      " 35%|███▌      | 165/468 [29:26<54:29, 10.79s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:04:40,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1908.70 | bwd_microstep: 3425.95 | bwd_inner_microstep: 3425.93 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:04:44,211] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:04:44,211] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1487.93 | bwd_microstep: 2636.76 | bwd_inner_microstep: 2621.82 | bwd_allreduce_microstep: 14.90 | step_microstep: 7.56\n",
      "[2024-09-15 16:04:44,212] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3396.61 | bwd: 6062.73 | bwd_inner: 6047.75 | bwd_allreduce: 14.92 | step: 7.65\n",
      "{'loss': 0.2246, 'learning_rate': 3.0000000000000004e-05, 'epoch': 1.06}\n",
      " 35%|███▌      | 166/468 [29:35<52:23, 10.41s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:04:48,259] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1451.78 | bwd_microstep: 2566.07 | bwd_inner_microstep: 2566.04 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1901\n",
      "[2024-09-15 16:04:54,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:04:54,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.55 | bwd_microstep: 4650.43 | bwd_inner_microstep: 3414.70 | bwd_allreduce_microstep: 1235.67 | step_microstep: 7.63\n",
      "[2024-09-15 16:04:54,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3352.30 | bwd: 7216.51 | bwd_inner: 5980.74 | bwd_allreduce: 1235.70 | step: 7.85\n",
      "{'loss': 0.2093, 'learning_rate': 2.9879641323740505e-05, 'epoch': 1.07}\n",
      " 36%|███▌      | 167/468 [29:46<52:33, 10.48s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:05:00,218] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.16 | bwd_microstep: 3431.95 | bwd_inner_microstep: 3431.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:05:05,577] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:05:05,578] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.12 | bwd_microstep: 3832.54 | bwd_inner_microstep: 2628.18 | bwd_allreduce_microstep: 1204.28 | step_microstep: 7.85\n",
      "[2024-09-15 16:05:05,578] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3401.25 | bwd: 7264.50 | bwd_inner: 6060.10 | bwd_allreduce: 1204.33 | step: 8.06\n",
      "{'loss': 0.2332, 'learning_rate': 2.9758807484302566e-05, 'epoch': 1.07}\n",
      " 36%|███▌      | 168/468 [29:56<52:46, 10.55s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:05:09,658] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.14 | bwd_microstep: 2585.40 | bwd_inner_microstep: 2585.38 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 16:05:16,303] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.38 | optimizer_step: 0.41\n",
      "[2024-09-15 16:05:16,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.22 | bwd_microstep: 5150.13 | bwd_inner_microstep: 2590.45 | bwd_allreduce_microstep: 2559.62 | step_microstep: 7.23\n",
      "[2024-09-15 16:05:16,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2925.34 | bwd: 7735.55 | bwd_inner: 5175.83 | bwd_allreduce: 2559.65 | step: 7.42\n",
      "{'loss': 0.1983, 'learning_rate': 2.963750429321208e-05, 'epoch': 1.08}\n",
      " 36%|███▌      | 169/468 [30:07<52:51, 10.61s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:05:20,375] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.72 | bwd_microstep: 2580.05 | bwd_inner_microstep: 2580.02 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:05:26,975] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:05:26,975] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.57 | bwd_microstep: 4654.52 | bwd_inner_microstep: 3424.90 | bwd_allreduce_microstep: 1229.57 | step_microstep: 7.49\n",
      "[2024-09-15 16:05:26,975] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3370.27 | bwd: 7234.59 | bwd_inner: 6004.92 | bwd_allreduce: 1229.60 | step: 7.74\n",
      "{'loss': 0.2707, 'learning_rate': 2.9515737584568463e-05, 'epoch': 1.09}\n",
      " 36%|███▋      | 170/468 [30:18<52:46, 10.63s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:05:32,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1927.24 | bwd_microstep: 3454.36 | bwd_inner_microstep: 3454.33 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:05:37,773] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:05:37,773] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.00 | bwd_microstep: 3440.29 | bwd_inner_microstep: 3424.99 | bwd_allreduce_microstep: 15.25 | step_microstep: 8.16\n",
      "[2024-09-15 16:05:37,773] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3837.22 | bwd: 6894.66 | bwd_inner: 6879.33 | bwd_allreduce: 15.27 | step: 8.34\n",
      "{'loss': 0.2485, 'learning_rate': 2.939351321476412e-05, 'epoch': 1.09}\n",
      " 37%|███▋      | 171/468 [30:29<52:51, 10.68s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:05:43,113] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.59 | bwd_microstep: 3412.59 | bwd_inner_microstep: 3412.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:05:48,426] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:05:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.49 | bwd_microstep: 3793.80 | bwd_inner_microstep: 2625.49 | bwd_allreduce_microstep: 1168.25 | step_microstep: 7.73\n",
      "[2024-09-15 16:05:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3386.05 | bwd: 7206.41 | bwd_inner: 6038.06 | bwd_allreduce: 1168.28 | step: 7.77\n",
      "{'loss': 0.1947, 'learning_rate': 2.927083706220274e-05, 'epoch': 1.1}\n",
      " 37%|███▋      | 172/468 [30:39<52:38, 10.67s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1876\n",
      "[2024-09-15 16:05:53,734] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1882.98 | bwd_microstep: 3394.15 | bwd_inner_microstep: 3394.13 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:05:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:05:59,176] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1451.02 | bwd_microstep: 3956.21 | bwd_inner_microstep: 2569.25 | bwd_allreduce_microstep: 1386.91 | step_microstep: 7.33\n",
      "[2024-09-15 16:05:59,177] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3333.97 | bwd: 7350.38 | bwd_inner: 5963.38 | bwd_allreduce: 1386.93 | step: 7.47\n",
      "{'loss': 0.1949, 'learning_rate': 2.9147715027016593e-05, 'epoch': 1.11}\n",
      " 37%|███▋      | 173/468 [30:50<52:34, 10.69s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:06:03,257] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.95 | bwd_microstep: 2585.34 | bwd_inner_microstep: 2585.31 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:06:09,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.37\n",
      "[2024-09-15 16:06:09,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.28 | bwd_microstep: 5087.23 | bwd_inner_microstep: 2623.72 | bwd_allreduce_microstep: 2463.45 | step_microstep: 7.21\n",
      "[2024-09-15 16:06:09,870] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2955.20 | bwd: 7672.58 | bwd_inner: 5209.03 | bwd_allreduce: 2463.48 | step: 7.43\n",
      "{'loss': 0.1907, 'learning_rate': 2.902415303078275e-05, 'epoch': 1.11}\n",
      " 37%|███▋      | 174/468 [31:01<52:23, 10.69s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:06:13,911] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1448.29 | bwd_microstep: 2562.83 | bwd_inner_microstep: 2562.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:06:20,659] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.40 | optimizer_step: 0.39\n",
      "[2024-09-15 16:06:20,660] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1487.01 | bwd_microstep: 5226.84 | bwd_inner_microstep: 2623.00 | bwd_allreduce_microstep: 2603.77 | step_microstep: 7.22\n",
      "[2024-09-15 16:06:20,660] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2935.28 | bwd: 7789.70 | bwd_inner: 5185.81 | bwd_allreduce: 2603.80 | step: 7.44\n",
      "{'loss': 0.1801, 'learning_rate': 2.8900157016238296e-05, 'epoch': 1.12}\n",
      " 37%|███▋      | 175/468 [31:12<52:21, 10.72s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1368\n",
      "[2024-09-15 16:06:24,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1456.13 | bwd_microstep: 2570.42 | bwd_inner_microstep: 2570.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.12\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1878\n",
      "[2024-09-15 16:06:31,473] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:06:31,474] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1888.23 | bwd_microstep: 4834.89 | bwd_inner_microstep: 3403.05 | bwd_allreduce_microstep: 1431.77 | step_microstep: 7.18\n",
      "[2024-09-15 16:06:31,474] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3344.33 | bwd: 7405.32 | bwd_inner: 5973.45 | bwd_allreduce: 1431.80 | step: 7.33\n",
      "{'loss': 0.2489, 'learning_rate': 2.8775732946994508e-05, 'epoch': 1.12}\n",
      " 38%|███▊      | 176/468 [31:22<52:19, 10.75s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:06:36,785] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1881.44 | bwd_microstep: 3400.15 | bwd_inner_microstep: 3400.13 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:06:42,109] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:06:42,110] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1486.70 | bwd_microstep: 3801.65 | bwd_inner_microstep: 2618.68 | bwd_allreduce_microstep: 1182.91 | step_microstep: 7.43\n",
      "[2024-09-15 16:06:42,110] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3368.12 | bwd: 7201.81 | bwd_inner: 6018.81 | bwd_allreduce: 1182.94 | step: 7.54\n",
      "{'loss': 0.1969, 'learning_rate': 2.8650886807250024e-05, 'epoch': 1.13}\n",
      " 38%|███▊      | 177/468 [31:33<51:58, 10.72s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:06:46,183] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.73 | bwd_microstep: 2580.63 | bwd_inner_microstep: 2580.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:06:51,577] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:06:51,578] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.78 | bwd_microstep: 3446.98 | bwd_inner_microstep: 3432.30 | bwd_allreduce_microstep: 14.64 | step_microstep: 7.58\n",
      "[2024-09-15 16:06:51,578] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.48 | bwd: 6027.62 | bwd_inner: 6012.90 | bwd_allreduce: 14.66 | step: 7.67\n",
      "{'loss': 0.1724, 'learning_rate': 2.8525624601503055e-05, 'epoch': 1.14}\n",
      " 38%|███▊      | 178/468 [31:42<49:59, 10.34s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:06:56,955] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.46 | bwd_microstep: 3434.63 | bwd_inner_microstep: 3434.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:07:01,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.73 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:01,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.22 | bwd_microstep: 2644.73 | bwd_inner_microstep: 2632.24 | bwd_allreduce_microstep: 12.45 | step_microstep: 7.90\n",
      "[2024-09-15 16:07:01,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3401.66 | bwd: 6079.38 | bwd_inner: 6066.84 | bwd_allreduce: 12.47 | step: 8.05\n",
      "{'loss': 0.1797, 'learning_rate': 2.8399952354262566e-05, 'epoch': 1.14}\n",
      " 38%|███▊      | 179/468 [31:52<48:39, 10.10s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:07:06,551] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1930.56 | bwd_microstep: 3456.84 | bwd_inner_microstep: 3456.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:07:11,956] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:11,956] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.00 | bwd_microstep: 3452.29 | bwd_inner_microstep: 3436.80 | bwd_allreduce_microstep: 15.45 | step_microstep: 8.25\n",
      "[2024-09-15 16:07:11,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3847.53 | bwd: 6909.14 | bwd_inner: 6893.61 | bwd_allreduce: 15.47 | step: 8.38\n",
      "{'loss': 0.1341, 'learning_rate': 2.8273876109758568e-05, 'epoch': 1.15}\n",
      " 38%|███▊      | 180/468 [32:03<49:32, 10.32s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:07:16,042] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.59 | bwd_microstep: 2587.26 | bwd_inner_microstep: 2587.23 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:07:21,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.63 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:21,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.06 | bwd_microstep: 3466.14 | bwd_inner_microstep: 3442.07 | bwd_allreduce_microstep: 24.02 | step_microstep: 7.87\n",
      "[2024-09-15 16:07:21,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3383.63 | bwd: 6053.41 | bwd_inner: 6029.30 | bwd_allreduce: 24.04 | step: 8.04\n",
      "{'loss': 0.2223, 'learning_rate': 2.8147401931651363e-05, 'epoch': 1.16}\n",
      " 39%|███▊      | 181/468 [32:12<48:11, 10.08s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:07:25,610] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.32 | bwd_microstep: 2628.48 | bwd_inner_microstep: 2628.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.09\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:07:30,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:30,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.72 | bwd_microstep: 3824.99 | bwd_inner_microstep: 2627.56 | bwd_allreduce_microstep: 1197.37 | step_microstep: 7.46\n",
      "[2024-09-15 16:07:30,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2985.01 | bwd: 6453.49 | bwd_inner: 5256.02 | bwd_allreduce: 1197.40 | step: 7.58\n",
      "{'loss': 0.2221, 'learning_rate': 2.802053590273997e-05, 'epoch': 1.16}\n",
      " 39%|███▉      | 182/468 [32:22<47:12,  9.90s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:07:36,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.70 | bwd_microstep: 3435.32 | bwd_inner_microstep: 3435.30 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:07:41,795] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.63 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.76 | bwd_microstep: 3499.15 | bwd_inner_microstep: 3435.21 | bwd_allreduce_microstep: 63.89 | step_microstep: 7.77\n",
      "[2024-09-15 16:07:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.44 | bwd: 6934.49 | bwd_inner: 6870.51 | bwd_allreduce: 63.92 | step: 7.97\n",
      "{'loss': 0.2019, 'learning_rate': 2.789328412466953e-05, 'epoch': 1.17}\n",
      " 39%|███▉      | 183/468 [32:33<48:22, 10.18s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:07:45,883] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.59 | bwd_microstep: 2588.58 | bwd_inner_microstep: 2588.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1388\n",
      "[2024-09-15 16:07:52,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:07:52,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.81 | bwd_microstep: 5162.99 | bwd_inner_microstep: 2600.48 | bwd_allreduce_microstep: 2562.45 | step_microstep: 7.32\n",
      "[2024-09-15 16:07:52,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2940.37 | bwd: 7751.58 | bwd_inner: 5189.04 | bwd_allreduce: 2562.47 | step: 7.43\n",
      "{'loss': 0.1336, 'learning_rate': 2.7765652717637873e-05, 'epoch': 1.18}\n",
      " 39%|███▉      | 184/468 [32:43<49:00, 10.36s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:07:57,930] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.23 | bwd_microstep: 3434.42 | bwd_inner_microstep: 3434.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:08:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.64 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:08:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.05 | bwd_microstep: 3449.56 | bwd_inner_microstep: 3436.12 | bwd_allreduce_microstep: 13.39 | step_microstep: 7.93\n",
      "[2024-09-15 16:08:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3827.26 | bwd: 6883.99 | bwd_inner: 6870.52 | bwd_allreduce: 13.42 | step: 8.11\n",
      "{'loss': 0.2361, 'learning_rate': 2.763764782010116e-05, 'epoch': 1.18}\n",
      " 40%|███▉      | 185/468 [32:54<49:26, 10.48s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:08:08,712] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.40 | bwd_microstep: 3435.99 | bwd_inner_microstep: 3435.96 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 16:08:12,849] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.34 | optimizer_step: 0.37\n",
      "[2024-09-15 16:08:12,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1477.86 | bwd_microstep: 2624.53 | bwd_inner_microstep: 2609.43 | bwd_allreduce_microstep: 15.06 | step_microstep: 7.78\n",
      "[2024-09-15 16:08:12,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3393.23 | bwd: 6060.53 | bwd_inner: 6045.39 | bwd_allreduce: 15.08 | step: 8.01\n",
      "{'loss': 0.2023, 'learning_rate': 2.7509275588478606e-05, 'epoch': 1.19}\n",
      " 40%|███▉      | 186/468 [33:04<47:54, 10.19s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:08:16,944] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.38 | bwd_microstep: 2590.58 | bwd_inner_microstep: 2590.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 16:08:22,310] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:08:22,310] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.99 | bwd_microstep: 3430.22 | bwd_inner_microstep: 3415.51 | bwd_allreduce_microstep: 14.66 | step_microstep: 7.80\n",
      "[2024-09-15 16:08:22,311] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3371.35 | bwd: 6020.80 | bwd_inner: 6006.06 | bwd_allreduce: 14.68 | step: 8.01\n",
      "{'loss': 0.2428, 'learning_rate': 2.738054219685647e-05, 'epoch': 1.19}\n",
      " 40%|███▉      | 187/468 [33:13<46:42,  9.97s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:08:26,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.42 | bwd_microstep: 2592.84 | bwd_inner_microstep: 2592.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:08:31,853] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:08:31,854] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.43 | bwd_microstep: 3479.57 | bwd_inner_microstep: 3467.12 | bwd_allreduce_microstep: 12.41 | step_microstep: 7.88\n",
      "[2024-09-15 16:08:31,854] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.82 | bwd: 6072.42 | bwd_inner: 6059.93 | bwd_allreduce: 12.43 | step: 8.04\n",
      "{'loss': 0.2394, 'learning_rate': 2.725145383669106e-05, 'epoch': 1.2}\n",
      " 40%|████      | 188/468 [33:23<45:56,  9.84s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:08:37,284] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.97 | bwd_microstep: 3464.73 | bwd_inner_microstep: 3464.71 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:08:42,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.35 | optimizer_step: 0.38\n",
      "[2024-09-15 16:08:42,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1933.44 | bwd_microstep: 3479.11 | bwd_inner_microstep: 3464.37 | bwd_allreduce_microstep: 14.69 | step_microstep: 8.28\n",
      "[2024-09-15 16:08:42,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3868.38 | bwd: 6943.85 | bwd_inner: 6929.08 | bwd_allreduce: 14.71 | step: 8.51\n",
      "{'loss': 0.1464, 'learning_rate': 2.712201671651094e-05, 'epoch': 1.21}\n",
      " 40%|████      | 189/468 [33:34<47:13, 10.15s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1880\n",
      "[2024-09-15 16:08:48,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.48 | bwd_microstep: 3441.15 | bwd_inner_microstep: 3441.12 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:08:53,409] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:08:53,410] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.84 | bwd_microstep: 3760.77 | bwd_inner_microstep: 2630.87 | bwd_allreduce_microstep: 1129.84 | step_microstep: 7.42\n",
      "[2024-09-15 16:08:53,410] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3410.30 | bwd: 7201.93 | bwd_inner: 6071.99 | bwd_allreduce: 1129.87 | step: 7.64\n",
      "{'loss': 0.2485, 'learning_rate': 2.699223706161839e-05, 'epoch': 1.21}\n",
      " 41%|████      | 190/468 [33:44<47:46, 10.31s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:08:57,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.38 | bwd_microstep: 2591.60 | bwd_inner_microstep: 2591.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:09:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:09:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.44 | bwd_microstep: 4868.93 | bwd_inner_microstep: 2574.80 | bwd_allreduce_microstep: 2294.07 | step_microstep: 7.24\n",
      "[2024-09-15 16:09:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2923.80 | bwd: 7460.54 | bwd_inner: 5166.37 | bwd_allreduce: 2294.09 | step: 7.47\n",
      "{'loss': 0.3039, 'learning_rate': 2.6862121113789917e-05, 'epoch': 1.22}\n",
      " 41%|████      | 191/468 [33:55<47:47, 10.35s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:09:09,189] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1893.23 | bwd_microstep: 3403.88 | bwd_inner_microstep: 3403.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:09:14,632] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.62 | optimizer_gradients: 0.33 | optimizer_step: 0.41\n",
      "[2024-09-15 16:09:14,632] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1929.96 | bwd_microstep: 3475.59 | bwd_inner_microstep: 3460.97 | bwd_allreduce_microstep: 14.57 | step_microstep: 7.96\n",
      "[2024-09-15 16:09:14,632] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3823.16 | bwd: 6879.49 | bwd_inner: 6864.82 | bwd_allreduce: 14.59 | step: 8.18\n",
      "{'loss': 0.1387, 'learning_rate': 2.673167513097613e-05, 'epoch': 1.23}\n",
      " 41%|████      | 192/468 [34:06<48:12, 10.48s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 16:09:20,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.83 | bwd_microstep: 3462.09 | bwd_inner_microstep: 3462.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1388\n",
      "[2024-09-15 16:09:25,447] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:09:25,448] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.64 | bwd_microstep: 3888.61 | bwd_inner_microstep: 2590.93 | bwd_allreduce_microstep: 1297.62 | step_microstep: 7.86\n",
      "[2024-09-15 16:09:25,448] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.44 | bwd: 7350.72 | bwd_inner: 6052.99 | bwd_allreduce: 1297.65 | step: 7.96\n",
      "{'loss': 0.2657, 'learning_rate': 2.6600905387000716e-05, 'epoch': 1.23}\n",
      " 41%|████      | 193/468 [34:16<48:29, 10.58s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:09:30,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.59 | bwd_microstep: 3437.84 | bwd_inner_microstep: 3437.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1901\n",
      "[2024-09-15 16:09:36,328] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:09:36,328] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1955.26 | bwd_microstep: 3506.07 | bwd_inner_microstep: 3491.13 | bwd_allreduce_microstep: 14.85 | step_microstep: 7.86\n",
      "[2024-09-15 16:09:36,329] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3869.82 | bwd: 6943.94 | bwd_inner: 6928.95 | bwd_allreduce: 14.89 | step: 8.02\n",
      "{'loss': 0.176, 'learning_rate': 2.6469818171258723e-05, 'epoch': 1.24}\n",
      " 41%|████▏     | 194/468 [34:27<48:43, 10.67s/it]dynamic ViT batch size: 48, images per sample: 6.0, dynamic token length: 1878\n",
      "[2024-09-15 16:09:41,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1969.53 | bwd_microstep: 3507.52 | bwd_inner_microstep: 3507.50 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1908\n",
      "[2024-09-15 16:09:47,384] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:09:47,384] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1971.54 | bwd_microstep: 3540.79 | bwd_inner_microstep: 3526.02 | bwd_allreduce_microstep: 14.72 | step_microstep: 7.77\n",
      "[2024-09-15 16:09:47,384] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3941.04 | bwd: 7048.32 | bwd_inner: 7033.52 | bwd_allreduce: 14.74 | step: 7.88\n",
      "{'loss': 0.1876, 'learning_rate': 2.633841978841406e-05, 'epoch': 1.25}\n",
      " 42%|████▏     | 195/468 [34:38<49:04, 10.79s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:09:51,413] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.09 | bwd_microstep: 2558.21 | bwd_inner_microstep: 2558.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 16:09:58,168] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:09:58,168] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1925.70 | bwd_microstep: 4793.04 | bwd_inner_microstep: 3453.32 | bwd_allreduce_microstep: 1339.66 | step_microstep: 7.29\n",
      "[2024-09-15 16:09:58,169] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3365.77 | bwd: 7351.29 | bwd_inner: 6011.50 | bwd_allreduce: 1339.69 | step: 7.52\n",
      "{'loss': 0.1726, 'learning_rate': 2.620671655809627e-05, 'epoch': 1.25}\n",
      " 42%|████▏     | 196/468 [34:49<48:53, 10.79s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:10:02,255] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.28 | bwd_microstep: 2589.23 | bwd_inner_microstep: 2589.20 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:10:08,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.33 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:10:08,817] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1887.74 | bwd_microstep: 4639.37 | bwd_inner_microstep: 3404.96 | bwd_allreduce_microstep: 1234.35 | step_microstep: 7.36\n",
      "[2024-09-15 16:10:08,817] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3355.00 | bwd: 7228.61 | bwd_inner: 5994.17 | bwd_allreduce: 1234.38 | step: 7.57\n",
      "{'loss': 0.2352, 'learning_rate': 2.60747148145966e-05, 'epoch': 1.26}\n",
      " 42%|████▏     | 197/468 [35:00<48:31, 10.74s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:10:12,900] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.11 | bwd_microstep: 2586.48 | bwd_inner_microstep: 2586.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:10:19,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:10:19,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1887.88 | bwd_microstep: 4659.02 | bwd_inner_microstep: 3401.38 | bwd_allreduce_microstep: 1257.58 | step_microstep: 7.84\n",
      "[2024-09-15 16:10:19,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3353.96 | bwd: 7245.51 | bwd_inner: 5987.83 | bwd_allreduce: 1257.61 | step: 8.08\n",
      "{'loss': 0.254, 'learning_rate': 2.594242090656335e-05, 'epoch': 1.27}\n",
      " 42%|████▏     | 198/468 [35:10<48:14, 10.72s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:10:24,903] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1930.05 | bwd_microstep: 3459.92 | bwd_inner_microstep: 3459.89 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.12\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1870\n",
      "[2024-09-15 16:10:30,280] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.37\n",
      "[2024-09-15 16:10:30,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1883.97 | bwd_microstep: 3458.54 | bwd_inner_microstep: 3400.03 | bwd_allreduce_microstep: 58.46 | step_microstep: 8.04\n",
      "[2024-09-15 16:10:30,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3814.00 | bwd: 6918.47 | bwd_inner: 6859.92 | bwd_allreduce: 58.48 | step: 8.19\n",
      "{'loss': 0.2125, 'learning_rate': 2.5809841196696504e-05, 'epoch': 1.27}\n",
      " 43%|████▎     | 199/468 [35:21<48:10, 10.74s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1879\n",
      "[2024-09-15 16:10:35,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.87 | bwd_microstep: 3414.85 | bwd_inner_microstep: 3414.83 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1388\n",
      "[2024-09-15 16:10:41,066] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.33 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:10:41,067] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1478.35 | bwd_microstep: 3925.63 | bwd_inner_microstep: 2610.56 | bwd_allreduce_microstep: 1315.02 | step_microstep: 8.32\n",
      "[2024-09-15 16:10:41,067] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3378.20 | bwd: 7340.50 | bwd_inner: 6025.39 | bwd_allreduce: 1315.05 | step: 8.53\n",
      "{'loss': 0.2049, 'learning_rate': 2.5676982061441763e-05, 'epoch': 1.28}\n",
      " 43%|████▎     | 200/468 [35:32<48:02, 10.76s/it][INFO|trainer.py:2936] 2024-09-15 16:10:48,754 >> Saving model checkpoint to work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200\n",
      "[INFO|configuration_utils.py:473] 2024-09-15 16:10:48,756 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/config.json\n",
      "[INFO|configuration_utils.py:594] 2024-09-15 16:10:48,756 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/generation_config.json\n",
      "[INFO|modeling_utils.py:2501] 2024-09-15 16:11:02,093 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2433] 2024-09-15 16:11:02,095 >> tokenizer config file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2442] 2024-09-15 16:11:02,095 >> Special tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2493] 2024-09-15 16:11:02,095 >> added tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/added_tokens.json\n",
      "[2024-09-15 16:11:02,728] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!\n",
      "[2024-09-15 16:11:02,755] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt\n",
      "[2024-09-15 16:11:02,755] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt...\n",
      "[2024-09-15 16:11:18,868] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt.\n",
      "[2024-09-15 16:11:18,871] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2024-09-15 16:11:19,023] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2024-09-15 16:11:19,024] [INFO] [engine.py:3488:_save_zero_checkpoint] zero checkpoint saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2024-09-15 16:11:19,024] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:11:24,334] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1888.77 | bwd_microstep: 3398.08 | bwd_inner_microstep: 3398.05 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:11:29,718] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:11:29,719] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.78 | bwd_microstep: 3438.14 | bwd_inner_microstep: 3423.26 | bwd_allreduce_microstep: 14.83 | step_microstep: 7.87\n",
      "[2024-09-15 16:11:29,719] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3798.52 | bwd: 6836.23 | bwd_inner: 6821.32 | bwd_allreduce: 14.85 | step: 8.07\n",
      "{'loss': 0.1865, 'learning_rate': 2.5543849890683813e-05, 'epoch': 1.28}\n",
      " 43%|████▎     | 201/468 [36:21<1:38:27, 22.13s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:11:35,046] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1897.09 | bwd_microstep: 3399.42 | bwd_inner_microstep: 3399.39 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:11:39,191] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.70 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 16:11:39,192] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1481.94 | bwd_microstep: 2627.42 | bwd_inner_microstep: 2612.37 | bwd_allreduce_microstep: 15.00 | step_microstep: 7.97\n",
      "[2024-09-15 16:11:39,192] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.00 | bwd: 6026.85 | bwd_inner: 6011.77 | bwd_allreduce: 15.02 | step: 8.18\n",
      "{'loss': 0.2203, 'learning_rate': 2.5410451087439075e-05, 'epoch': 1.29}\n",
      " 43%|████▎     | 202/468 [36:30<1:21:15, 18.33s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:11:44,541] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.99 | bwd_microstep: 3413.54 | bwd_inner_microstep: 3413.51 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:11:49,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.42 | optimizer_step: 0.39\n",
      "[2024-09-15 16:11:49,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1485.10 | bwd_microstep: 3663.35 | bwd_inner_microstep: 2617.09 | bwd_allreduce_microstep: 1046.20 | step_microstep: 7.82\n",
      "[2024-09-15 16:11:49,729] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.06 | bwd: 7076.90 | bwd_inner: 6030.60 | bwd_allreduce: 1046.23 | step: 8.04\n",
      "{'loss': 0.2002, 'learning_rate': 2.5276792067547672e-05, 'epoch': 1.3}\n",
      " 43%|████▎     | 203/468 [36:41<1:10:37, 15.99s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:11:55,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.03 | bwd_microstep: 3420.18 | bwd_inner_microstep: 3420.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:12:00,414] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:12:00,415] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1449.37 | bwd_microstep: 3845.98 | bwd_inner_microstep: 2563.93 | bwd_allreduce_microstep: 1281.99 | step_microstep: 7.80\n",
      "[2024-09-15 16:12:00,415] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3354.37 | bwd: 7266.17 | bwd_inner: 5984.08 | bwd_allreduce: 1282.02 | step: 8.04\n",
      "{'loss': 0.1524, 'learning_rate': 2.514287925936492e-05, 'epoch': 1.3}\n",
      " 44%|████▎     | 204/468 [36:51<1:03:21, 14.40s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:12:05,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1927.69 | bwd_microstep: 3450.13 | bwd_inner_microstep: 3450.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:12:11,213] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.40 | optimizer_step: 0.39\n",
      "[2024-09-15 16:12:11,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.64 | bwd_microstep: 3441.08 | bwd_inner_microstep: 3426.04 | bwd_allreduce_microstep: 15.00 | step_microstep: 8.34\n",
      "[2024-09-15 16:12:11,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3840.31 | bwd: 6891.22 | bwd_inner: 6876.14 | bwd_allreduce: 15.01 | step: 8.55\n",
      "{'loss': 0.2059, 'learning_rate': 2.500871910345212e-05, 'epoch': 1.31}\n",
      " 44%|████▍     | 205/468 [37:02<58:23, 13.32s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:12:15,293] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.02 | bwd_microstep: 2577.56 | bwd_inner_microstep: 2577.54 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:12:21,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:12:21,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1485.53 | bwd_microstep: 5083.45 | bwd_inner_microstep: 2617.76 | bwd_allreduce_microstep: 2465.61 | step_microstep: 7.55\n",
      "[2024-09-15 16:12:21,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2948.52 | bwd: 7661.03 | bwd_inner: 5195.29 | bwd_allreduce: 2465.66 | step: 7.60\n",
      "{'loss': 0.1885, 'learning_rate': 2.4874318052266794e-05, 'epoch': 1.32}\n",
      " 44%|████▍     | 206/468 [37:13<54:42, 12.53s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:12:25,973] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.21 | bwd_microstep: 2578.06 | bwd_inner_microstep: 2578.04 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:12:32,544] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:12:32,545] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1486.51 | bwd_microstep: 5051.05 | bwd_inner_microstep: 2618.45 | bwd_allreduce_microstep: 2432.54 | step_microstep: 7.87\n",
      "[2024-09-15 16:12:32,545] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2951.70 | bwd: 7629.13 | bwd_inner: 5196.49 | bwd_allreduce: 2432.57 | step: 8.01\n",
      "{'loss': 0.1837, 'learning_rate': 2.473968256985238e-05, 'epoch': 1.32}\n",
      " 44%|████▍     | 207/468 [37:23<52:02, 11.96s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:12:37,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1930.49 | bwd_microstep: 3442.51 | bwd_inner_microstep: 3442.48 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:12:43,333] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.64 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:12:43,333] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.89 | bwd_microstep: 3440.34 | bwd_inner_microstep: 3424.89 | bwd_allreduce_microstep: 15.40 | step_microstep: 8.64\n",
      "[2024-09-15 16:12:43,333] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3838.33 | bwd: 6882.85 | bwd_inner: 6867.37 | bwd_allreduce: 15.42 | step: 8.82\n",
      "{'loss': 0.1938, 'learning_rate': 2.460481913152734e-05, 'epoch': 1.33}\n",
      " 44%|████▍     | 208/468 [37:34<50:18, 11.61s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:12:47,372] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1448.32 | bwd_microstep: 2560.37 | bwd_inner_microstep: 2560.26 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1901\n",
      "[2024-09-15 16:12:54,232] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:12:54,232] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.65 | bwd_microstep: 4928.88 | bwd_inner_microstep: 3409.12 | bwd_allreduce_microstep: 1519.70 | step_microstep: 7.36\n",
      "[2024-09-15 16:12:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3344.95 | bwd: 7489.29 | bwd_inner: 5969.39 | bwd_allreduce: 1519.78 | step: 7.59\n",
      "{'loss': 0.1497, 'learning_rate': 2.4469734223573703e-05, 'epoch': 1.34}\n",
      " 45%|████▍     | 209/468 [37:45<49:12, 11.40s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:12:58,306] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.24 | bwd_microstep: 2580.32 | bwd_inner_microstep: 2580.30 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1877\n",
      "[2024-09-15 16:13:04,965] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.31 | optimizer_gradients: 0.43 | optimizer_step: 0.38\n",
      "[2024-09-15 16:13:04,966] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1867.51 | bwd_microstep: 4753.66 | bwd_inner_microstep: 3384.61 | bwd_allreduce_microstep: 1368.99 | step_microstep: 10.62\n",
      "[2024-09-15 16:13:04,966] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3329.72 | bwd: 7334.00 | bwd_inner: 5964.91 | bwd_allreduce: 1369.02 | step: 10.84\n",
      "{'loss': 0.2644, 'learning_rate': 2.4334434342925133e-05, 'epoch': 1.34}\n",
      " 45%|████▍     | 210/468 [37:56<48:09, 11.20s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:13:10,332] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.95 | bwd_microstep: 3428.14 | bwd_inner_microstep: 3428.11 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:13:15,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.42 | optimizer_step: 0.38\n",
      "[2024-09-15 16:13:15,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.35 | bwd_microstep: 3792.19 | bwd_inner_microstep: 2623.09 | bwd_allreduce_microstep: 1169.04 | step_microstep: 7.63\n",
      "[2024-09-15 16:13:15,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3396.28 | bwd: 7220.34 | bwd_inner: 6051.20 | bwd_allreduce: 1169.07 | step: 7.88\n",
      "{'loss': 0.1937, 'learning_rate': 2.4198925996854422e-05, 'epoch': 1.35}\n",
      " 45%|████▌     | 211/468 [38:07<47:18, 11.04s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:13:19,722] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.75 | bwd_microstep: 2581.94 | bwd_inner_microstep: 2581.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:13:26,313] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.28 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:13:26,314] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.66 | bwd_microstep: 4639.89 | bwd_inner_microstep: 3435.09 | bwd_allreduce_microstep: 1204.74 | step_microstep: 10.22\n",
      "[2024-09-15 16:13:26,314] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.39 | bwd: 7221.84 | bwd_inner: 6017.01 | bwd_allreduce: 1204.77 | step: 10.45\n",
      "{'loss': 0.2791, 'learning_rate': 2.4063215702660564e-05, 'epoch': 1.35}\n",
      " 45%|████▌     | 212/468 [38:17<46:38, 10.93s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:13:30,391] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.49 | bwd_microstep: 2582.70 | bwd_inner_microstep: 2582.68 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:13:37,010] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:13:37,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.02 | bwd_microstep: 4670.40 | bwd_inner_microstep: 3436.67 | bwd_allreduce_microstep: 1233.67 | step_microstep: 7.47\n",
      "[2024-09-15 16:13:37,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3378.49 | bwd: 7253.11 | bwd_inner: 6019.34 | bwd_allreduce: 1233.70 | step: 7.69\n",
      "{'loss': 0.24, 'learning_rate': 2.392730998735529e-05, 'epoch': 1.36}\n",
      " 46%|████▌     | 213/468 [38:28<46:09, 10.86s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:13:41,089] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.30 | bwd_microstep: 2584.98 | bwd_inner_microstep: 2584.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:13:47,735] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.37 | optimizer_step: 0.40\n",
      "[2024-09-15 16:13:47,735] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.33 | bwd_microstep: 4700.18 | bwd_inner_microstep: 3432.19 | bwd_allreduce_microstep: 1267.93 | step_microstep: 7.24\n",
      "[2024-09-15 16:13:47,735] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3373.61 | bwd: 7285.21 | bwd_inner: 6017.11 | bwd_allreduce: 1267.96 | step: 7.48\n",
      "{'loss': 0.1574, 'learning_rate': 2.379121538734912e-05, 'epoch': 1.37}\n",
      " 46%|████▌     | 214/468 [38:39<45:48, 10.82s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1373\n",
      "[2024-09-15 16:13:51,815] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.96 | bwd_microstep: 2584.33 | bwd_inner_microstep: 2584.30 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:13:57,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.65 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:13:57,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.29 | bwd_microstep: 3436.46 | bwd_inner_microstep: 3421.46 | bwd_allreduce_microstep: 14.95 | step_microstep: 7.83\n",
      "[2024-09-15 16:13:57,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3374.23 | bwd: 6020.80 | bwd_inner: 6005.77 | bwd_allreduce: 14.97 | step: 8.01\n",
      "{'loss': 0.1896, 'learning_rate': 2.3654938448137062e-05, 'epoch': 1.37}\n",
      " 46%|████▌     | 215/468 [38:48<43:54, 10.41s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:14:01,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.61 | bwd_microstep: 2582.80 | bwd_inner_microstep: 2582.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:14:06,665] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.64 | optimizer_gradients: 0.34 | optimizer_step: 0.37\n",
      "[2024-09-15 16:14:06,666] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.47 | bwd_microstep: 3446.49 | bwd_inner_microstep: 3431.73 | bwd_allreduce_microstep: 14.71 | step_microstep: 7.99\n",
      "[2024-09-15 16:14:06,666] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.05 | bwd: 6029.29 | bwd_inner: 6014.50 | bwd_allreduce: 14.73 | step: 8.22\n",
      "{'loss': 0.1865, 'learning_rate': 2.351848572398371e-05, 'epoch': 1.38}\n",
      " 46%|████▌     | 216/468 [38:58<42:32, 10.13s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1367\n",
      "[2024-09-15 16:14:10,743] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.14 | bwd_microstep: 2578.63 | bwd_inner_microstep: 2578.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:14:17,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:14:17,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.65 | bwd_microstep: 5111.97 | bwd_inner_microstep: 2626.37 | bwd_allreduce_microstep: 2485.54 | step_microstep: 7.59\n",
      "[2024-09-15 16:14:17,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2950.76 | bwd: 7690.62 | bwd_inner: 5204.97 | bwd_allreduce: 2485.58 | step: 7.84\n",
      "{'loss': 0.1336, 'learning_rate': 2.338186377760811e-05, 'epoch': 1.39}\n",
      " 46%|████▋     | 217/468 [39:08<43:06, 10.31s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:14:21,456] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.53 | bwd_microstep: 2581.25 | bwd_inner_microstep: 2581.22 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:14:28,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:14:28,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.09 | bwd_microstep: 5085.47 | bwd_inner_microstep: 2625.43 | bwd_allreduce_microstep: 2459.98 | step_microstep: 7.53\n",
      "[2024-09-15 16:14:28,065] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2953.59 | bwd: 7666.73 | bwd_inner: 5206.66 | bwd_allreduce: 2460.01 | step: 7.76\n",
      "{'loss': 0.2047, 'learning_rate': 2.3245079179868054e-05, 'epoch': 1.39}\n",
      " 47%|████▋     | 218/468 [39:19<43:24, 10.42s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:14:32,139] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.15 | bwd_microstep: 2578.45 | bwd_inner_microstep: 2578.42 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:14:38,794] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.41 | optimizer_step: 0.38\n",
      "[2024-09-15 16:14:38,794] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.65 | bwd_microstep: 4707.21 | bwd_inner_microstep: 3431.82 | bwd_allreduce_microstep: 1275.32 | step_microstep: 7.51\n",
      "[2024-09-15 16:14:38,794] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3374.77 | bwd: 7285.66 | bwd_inner: 6010.24 | bwd_allreduce: 1275.35 | step: 7.73\n",
      "{'loss': 0.31, 'learning_rate': 2.31081385094441e-05, 'epoch': 1.4}\n",
      " 47%|████▋     | 219/468 [39:30<43:37, 10.51s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:14:42,868] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.28 | bwd_microstep: 2582.30 | bwd_inner_microstep: 2582.19 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:14:49,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:14:49,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.10 | bwd_microstep: 5271.56 | bwd_inner_microstep: 2587.27 | bwd_allreduce_microstep: 2684.23 | step_microstep: 7.28\n",
      "[2024-09-15 16:14:49,641] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2927.36 | bwd: 7853.90 | bwd_inner: 5169.47 | bwd_allreduce: 2684.30 | step: 7.45\n",
      "{'loss': 0.2096, 'learning_rate': 2.297104835252314e-05, 'epoch': 1.41}\n",
      " 47%|████▋     | 220/468 [39:41<43:51, 10.61s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:14:53,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.19 | bwd_microstep: 2577.99 | bwd_inner_microstep: 2577.96 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 16:14:59,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.67 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:14:59,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.35 | bwd_microstep: 3455.39 | bwd_inner_microstep: 3440.55 | bwd_allreduce_microstep: 14.80 | step_microstep: 7.96\n",
      "[2024-09-15 16:14:59,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3382.51 | bwd: 6033.40 | bwd_inner: 6018.52 | bwd_allreduce: 14.82 | step: 8.18\n",
      "{'loss': 0.2593, 'learning_rate': 2.283381530248165e-05, 'epoch': 1.41}\n",
      " 47%|████▋     | 221/468 [39:50<42:17, 10.27s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:15:03,173] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1451.15 | bwd_microstep: 2565.63 | bwd_inner_microstep: 2565.51 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:15:09,775] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:15:09,776] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.84 | bwd_microstep: 4629.06 | bwd_inner_microstep: 3469.00 | bwd_allreduce_microstep: 1159.99 | step_microstep: 7.07\n",
      "[2024-09-15 16:15:09,776] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3387.96 | bwd: 7194.73 | bwd_inner: 6034.52 | bwd_allreduce: 1160.08 | step: 7.34\n",
      "{'loss': 0.1585, 'learning_rate': 2.2696445959568577e-05, 'epoch': 1.42}\n",
      " 47%|████▋     | 222/468 [40:01<42:35, 10.39s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:15:13,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.07 | bwd_microstep: 2585.49 | bwd_inner_microstep: 2585.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:15:20,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.20 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 16:15:20,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.95 | bwd_microstep: 4716.70 | bwd_inner_microstep: 3457.85 | bwd_allreduce_microstep: 1258.78 | step_microstep: 7.44\n",
      "[2024-09-15 16:15:20,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3397.00 | bwd: 7302.21 | bwd_inner: 6043.32 | bwd_allreduce: 1258.82 | step: 7.63\n",
      "{'loss': 0.1781, 'learning_rate': 2.2558946930587907e-05, 'epoch': 1.42}\n",
      " 48%|████▊     | 223/468 [40:11<42:52, 10.50s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:15:25,956] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1929.33 | bwd_microstep: 3456.91 | bwd_inner_microstep: 3456.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.29\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:15:31,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:15:31,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.92 | bwd_microstep: 3819.40 | bwd_inner_microstep: 2626.52 | bwd_allreduce_microstep: 1192.82 | step_microstep: 7.49\n",
      "[2024-09-15 16:15:31,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3421.23 | bwd: 7276.36 | bwd_inner: 6083.38 | bwd_allreduce: 1192.85 | step: 7.78\n",
      "{'loss': 0.1462, 'learning_rate': 2.2421324828580877e-05, 'epoch': 1.43}\n",
      " 48%|████▊     | 224/468 [40:22<43:01, 10.58s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:15:35,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.55 | bwd_microstep: 2583.18 | bwd_inner_microstep: 2583.06 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:15:42,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:15:42,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.47 | bwd_microstep: 5175.76 | bwd_inner_microstep: 2624.19 | bwd_allreduce_microstep: 2551.50 | step_microstep: 7.44\n",
      "[2024-09-15 16:15:42,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2956.99 | bwd: 7758.97 | bwd_inner: 5207.26 | bwd_allreduce: 2551.59 | step: 7.68\n",
      "{'loss': 0.1687, 'learning_rate': 2.2283586272507975e-05, 'epoch': 1.44}\n",
      " 48%|████▊     | 225/468 [40:33<43:05, 10.64s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:15:47,462] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.51 | bwd_microstep: 3432.18 | bwd_inner_microstep: 3432.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:15:52,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:15:52,950] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.49 | bwd_microstep: 3552.76 | bwd_inner_microstep: 3417.01 | bwd_allreduce_microstep: 135.69 | step_microstep: 7.58\n",
      "[2024-09-15 16:15:52,951] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3809.98 | bwd: 6984.99 | bwd_inner: 6849.11 | bwd_allreduce: 135.75 | step: 7.84\n",
      "{'loss': 0.1716, 'learning_rate': 2.214573788693054e-05, 'epoch': 1.44}\n",
      " 48%|████▊     | 226/468 [40:44<43:11, 10.71s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:15:56,969] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.09 | bwd_microstep: 2550.26 | bwd_inner_microstep: 2550.18 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:16:02,453] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 16:16:02,454] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.36 | bwd_microstep: 3537.15 | bwd_inner_microstep: 3427.87 | bwd_allreduce_microstep: 109.22 | step_microstep: 7.71\n",
      "[2024-09-15 16:16:02,454] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3352.42 | bwd: 6087.45 | bwd_inner: 5978.06 | bwd_allreduce: 109.29 | step: 7.90\n",
      "{'loss': 0.2694, 'learning_rate': 2.2007786301692205e-05, 'epoch': 1.45}\n",
      " 49%|████▊     | 227/468 [40:53<41:33, 10.35s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:16:07,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.47 | bwd_microstep: 3437.27 | bwd_inner_microstep: 3437.24 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:16:13,241] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.72 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:16:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.50 | bwd_microstep: 3453.21 | bwd_inner_microstep: 3439.63 | bwd_allreduce_microstep: 13.53 | step_microstep: 8.02\n",
      "[2024-09-15 16:16:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.95 | bwd: 6890.49 | bwd_inner: 6876.88 | bwd_allreduce: 13.55 | step: 8.25\n",
      "{'loss': 0.1615, 'learning_rate': 2.18697381516e-05, 'epoch': 1.46}\n",
      " 49%|████▊     | 228/468 [41:04<41:54, 10.48s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:16:17,329] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.14 | bwd_microstep: 2589.30 | bwd_inner_microstep: 2589.27 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:16:22,737] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:16:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.56 | bwd_microstep: 3881.80 | bwd_inner_microstep: 2628.96 | bwd_allreduce_microstep: 1252.78 | step_microstep: 7.20\n",
      "[2024-09-15 16:16:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2959.67 | bwd: 6471.11 | bwd_inner: 5218.23 | bwd_allreduce: 1252.81 | step: 7.40\n",
      "{'loss': 0.1891, 'learning_rate': 2.1731600076105264e-05, 'epoch': 1.46}\n",
      " 49%|████▉     | 229/468 [41:14<40:33, 10.18s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:16:28,113] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.96 | bwd_microstep: 3432.45 | bwd_inner_microstep: 3432.43 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:16:33,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.65 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 16:16:33,568] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.92 | bwd_microstep: 3478.65 | bwd_inner_microstep: 3465.14 | bwd_allreduce_microstep: 13.46 | step_microstep: 7.91\n",
      "[2024-09-15 16:16:33,568] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3850.86 | bwd: 6911.12 | bwd_inner: 6897.57 | bwd_allreduce: 13.49 | step: 8.13\n",
      "{'loss': 0.1321, 'learning_rate': 2.159337871898431e-05, 'epoch': 1.47}\n",
      " 49%|████▉     | 230/468 [41:24<41:09, 10.38s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:16:37,655] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.03 | bwd_microstep: 2589.43 | bwd_inner_microstep: 2589.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:16:43,068] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.67 | optimizer_gradients: 0.37 | optimizer_step: 0.39\n",
      "[2024-09-15 16:16:43,069] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.86 | bwd_microstep: 3449.79 | bwd_inner_microstep: 3434.56 | bwd_allreduce_microstep: 15.18 | step_microstep: 8.04\n",
      "[2024-09-15 16:16:43,069] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3387.84 | bwd: 6039.23 | bwd_inner: 6023.96 | bwd_allreduce: 15.20 | step: 8.27\n",
      "{'loss': 0.1706, 'learning_rate': 2.145508072801888e-05, 'epoch': 1.48}\n",
      " 49%|████▉     | 231/468 [41:34<39:57, 10.11s/it]dynamic ViT batch size: 34, images per sample: 4.25, dynamic token length: 1369\n",
      "[2024-09-15 16:16:47,067] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1429.03 | bwd_microstep: 2539.21 | bwd_inner_microstep: 2539.05 | bwd_allreduce_microstep: 0.08 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:16:52,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.38 | optimizer_step: 0.41\n",
      "[2024-09-15 16:16:52,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.32 | bwd_microstep: 3492.77 | bwd_inner_microstep: 3438.61 | bwd_allreduce_microstep: 54.11 | step_microstep: 7.90\n",
      "[2024-09-15 16:16:52,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3346.33 | bwd: 6032.02 | bwd_inner: 5977.67 | bwd_allreduce: 54.23 | step: 8.15\n",
      "{'loss': 0.2391, 'learning_rate': 2.131671275467647e-05, 'epoch': 1.48}\n",
      " 50%|████▉     | 232/468 [41:43<38:59,  9.91s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:16:57,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1922.43 | bwd_microstep: 3440.12 | bwd_inner_microstep: 3440.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:17:03,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.92 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 16:17:03,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.29 | bwd_microstep: 3481.33 | bwd_inner_microstep: 3466.33 | bwd_allreduce_microstep: 14.96 | step_microstep: 9.84\n",
      "[2024-09-15 16:17:03,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3860.69 | bwd: 6921.47 | bwd_inner: 6906.42 | bwd_allreduce: 14.98 | step: 10.04\n",
      "{'loss': 0.1462, 'learning_rate': 2.1178281453790358e-05, 'epoch': 1.49}\n",
      " 50%|████▉     | 233/468 [41:54<39:55, 10.19s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:17:08,755] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.93 | bwd_microstep: 3440.04 | bwd_inner_microstep: 3440.01 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:17:12,928] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.35 | optimizer_step: 0.39\n",
      "[2024-09-15 16:17:12,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.32 | bwd_microstep: 2644.28 | bwd_inner_microstep: 2631.54 | bwd_allreduce_microstep: 12.70 | step_microstep: 7.90\n",
      "[2024-09-15 16:17:12,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3415.22 | bwd: 6084.33 | bwd_inner: 6071.55 | bwd_allreduce: 12.72 | step: 8.08\n",
      "{'loss': 0.1928, 'learning_rate': 2.1039793483239607e-05, 'epoch': 1.5}\n",
      " 50%|█████     | 234/468 [42:04<39:01, 10.01s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:17:17,023] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.20 | bwd_microstep: 2591.32 | bwd_inner_microstep: 2591.29 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:17:22,391] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 16:17:22,391] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1496.53 | bwd_microstep: 3836.83 | bwd_inner_microstep: 2633.20 | bwd_allreduce_microstep: 1203.57 | step_microstep: 7.44\n",
      "[2024-09-15 16:17:22,392] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2968.70 | bwd: 6428.16 | bwd_inner: 5224.50 | bwd_allreduce: 1203.60 | step: 7.67\n",
      "{'loss': 0.3621, 'learning_rate': 2.090125550362879e-05, 'epoch': 1.5}\n",
      " 50%|█████     | 235/468 [42:13<38:13,  9.84s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:17:27,765] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.23 | bwd_microstep: 3427.94 | bwd_inner_microstep: 3427.91 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:17:31,948] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.66 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:17:31,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.42 | bwd_microstep: 2649.08 | bwd_inner_microstep: 2633.41 | bwd_allreduce_microstep: 15.62 | step_microstep: 8.00\n",
      "[2024-09-15 16:17:31,949] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3410.62 | bwd: 6077.03 | bwd_inner: 6061.33 | bwd_allreduce: 15.64 | step: 8.17\n",
      "{'loss': 0.1987, 'learning_rate': 2.0762674177967676e-05, 'epoch': 1.51}\n",
      " 50%|█████     | 236/468 [42:23<37:43,  9.76s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:17:37,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.67 | bwd_microstep: 3442.75 | bwd_inner_microstep: 3442.72 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:17:42,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.35 | optimizer_step: 0.42\n",
      "[2024-09-15 16:17:42,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1923.86 | bwd_microstep: 3454.49 | bwd_inner_microstep: 3439.41 | bwd_allreduce_microstep: 15.01 | step_microstep: 8.02\n",
      "[2024-09-15 16:17:42,760] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3845.50 | bwd: 6897.25 | bwd_inner: 6882.13 | bwd_allreduce: 15.04 | step: 8.28\n",
      "{'loss': 0.2071, 'learning_rate': 2.0624056171350785e-05, 'epoch': 1.51}\n",
      " 51%|█████     | 237/468 [42:34<38:46, 10.07s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:17:46,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1443.05 | bwd_microstep: 2559.30 | bwd_inner_microstep: 2559.07 | bwd_allreduce_microstep: 0.12 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:17:53,484] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:17:53,484] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.74 | bwd_microstep: 5187.07 | bwd_inner_microstep: 2596.75 | bwd_allreduce_microstep: 2590.25 | step_microstep: 7.48\n",
      "[2024-09-15 16:17:53,484] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2913.77 | bwd: 7746.40 | bwd_inner: 5155.82 | bwd_allreduce: 2590.42 | step: 7.72\n",
      "{'loss': 0.1817, 'learning_rate': 2.0485408150636804e-05, 'epoch': 1.52}\n",
      " 51%|█████     | 238/468 [42:44<39:21, 10.27s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:17:58,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.20 | bwd_microstep: 3457.89 | bwd_inner_microstep: 3457.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:18:04,336] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 16:18:04,336] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.27 | bwd_microstep: 3475.18 | bwd_inner_microstep: 3442.42 | bwd_allreduce_microstep: 32.71 | step_microstep: 8.42\n",
      "[2024-09-15 16:18:04,336] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3851.44 | bwd: 6933.08 | bwd_inner: 6900.28 | bwd_allreduce: 32.73 | step: 8.70\n",
      "{'loss': 0.1615, 'learning_rate': 2.0346736784127955e-05, 'epoch': 1.53}\n",
      " 51%|█████     | 239/468 [42:55<39:51, 10.44s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:18:08,427] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.77 | bwd_microstep: 2589.94 | bwd_inner_microstep: 2589.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1369\n",
      "[2024-09-15 16:18:13,906] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:18:13,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.65 | bwd_microstep: 3980.90 | bwd_inner_microstep: 2580.97 | bwd_allreduce_microstep: 1399.86 | step_microstep: 7.45\n",
      "[2024-09-15 16:18:13,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2934.40 | bwd: 6570.86 | bwd_inner: 5170.89 | bwd_allreduce: 1399.90 | step: 7.72\n",
      "{'loss': 0.1521, 'learning_rate': 2.0208048741249288e-05, 'epoch': 1.53}\n",
      " 51%|█████▏    | 240/468 [43:05<38:41, 10.18s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:18:17,990] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.23 | bwd_microstep: 2584.87 | bwd_inner_microstep: 2584.85 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 16:18:24,630] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:18:24,631] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.41 | bwd_microstep: 4706.68 | bwd_inner_microstep: 3422.92 | bwd_allreduce_microstep: 1283.70 | step_microstep: 7.15\n",
      "[2024-09-15 16:18:24,631] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3366.62 | bwd: 7291.56 | bwd_inner: 6007.77 | bwd_allreduce: 1283.73 | step: 7.24\n",
      "{'loss': 0.156, 'learning_rate': 2.006935069222789e-05, 'epoch': 1.54}\n",
      " 51%|█████▏    | 241/468 [43:16<39:08, 10.34s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:18:28,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.91 | bwd_microstep: 2590.28 | bwd_inner_microstep: 2590.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 32, images per sample: 4.0, dynamic token length: 1876\n",
      "[2024-09-15 16:18:35,428] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.41 | optimizer_step: 0.38\n",
      "[2024-09-15 16:18:35,429] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1841.31 | bwd_microstep: 4837.85 | bwd_inner_microstep: 3358.68 | bwd_allreduce_microstep: 1479.11 | step_microstep: 7.36\n",
      "[2024-09-15 16:18:35,429] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3306.19 | bwd: 7428.14 | bwd_inner: 5948.93 | bwd_allreduce: 1479.14 | step: 7.56\n",
      "{'loss': 0.2438, 'learning_rate': 1.9930649307772114e-05, 'epoch': 1.55}\n",
      " 52%|█████▏    | 242/468 [43:26<39:28, 10.48s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:18:40,807] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.35 | bwd_microstep: 3434.43 | bwd_inner_microstep: 3434.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:18:46,203] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:18:46,203] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.73 | bwd_microstep: 3446.04 | bwd_inner_microstep: 3431.17 | bwd_allreduce_microstep: 14.83 | step_microstep: 8.24\n",
      "[2024-09-15 16:18:46,203] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3827.05 | bwd: 6880.48 | bwd_inner: 6865.57 | bwd_allreduce: 14.85 | step: 8.33\n",
      "{'loss': 0.2432, 'learning_rate': 1.979195125875072e-05, 'epoch': 1.55}\n",
      " 52%|█████▏    | 243/468 [43:37<39:37, 10.57s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:18:50,290] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.64 | bwd_microstep: 2589.70 | bwd_inner_microstep: 2589.68 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 16:18:55,721] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:18:55,721] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.75 | bwd_microstep: 3904.87 | bwd_inner_microstep: 2629.24 | bwd_allreduce_microstep: 1275.57 | step_microstep: 7.22\n",
      "[2024-09-15 16:18:55,722] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.37 | bwd: 6494.58 | bwd_inner: 5218.92 | bwd_allreduce: 1275.60 | step: 7.33\n",
      "{'loss': 0.1292, 'learning_rate': 1.9653263215872048e-05, 'epoch': 1.56}\n",
      " 52%|█████▏    | 244/468 [43:47<38:16, 10.25s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:19:01,142] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.06 | bwd_microstep: 3457.57 | bwd_inner_microstep: 3457.54 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:19:06,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.63 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:19:06,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.89 | bwd_microstep: 3482.87 | bwd_inner_microstep: 3470.59 | bwd_allreduce_microstep: 12.23 | step_microstep: 8.37\n",
      "[2024-09-15 16:19:06,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3869.94 | bwd: 6940.45 | bwd_inner: 6928.13 | bwd_allreduce: 12.25 | step: 8.46\n",
      "{'loss': 0.2293, 'learning_rate': 1.9514591849363203e-05, 'epoch': 1.57}\n",
      " 52%|█████▏    | 245/468 [43:58<38:48, 10.44s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:19:10,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.10 | bwd_microstep: 2589.55 | bwd_inner_microstep: 2589.52 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:19:17,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.37 | optimizer_step: 0.39\n",
      "[2024-09-15 16:19:17,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.64 | bwd_microstep: 5220.79 | bwd_inner_microstep: 2630.21 | bwd_allreduce_microstep: 2590.49 | step_microstep: 7.28\n",
      "[2024-09-15 16:19:17,435] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2959.71 | bwd: 7810.34 | bwd_inner: 5219.73 | bwd_allreduce: 2590.53 | step: 7.37\n",
      "{'loss': 0.1932, 'learning_rate': 1.9375943828649215e-05, 'epoch': 1.57}\n",
      " 53%|█████▎    | 246/468 [44:08<39:04, 10.56s/it]dynamic ViT batch size: 34, images per sample: 4.25, dynamic token length: 1870\n",
      "[2024-09-15 16:19:22,671] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1850.22 | bwd_microstep: 3357.03 | bwd_inner_microstep: 3357.01 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1622\n",
      "[2024-09-15 16:19:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:19:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1664.19 | bwd_microstep: 3649.47 | bwd_inner_microstep: 2988.41 | bwd_allreduce_microstep: 661.00 | step_microstep: 7.64\n",
      "[2024-09-15 16:19:28,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3514.36 | bwd: 7006.54 | bwd_inner: 6345.42 | bwd_allreduce: 661.04 | step: 7.86\n",
      "{'loss': 0.1508, 'learning_rate': 1.923732582203233e-05, 'epoch': 1.58}\n",
      " 53%|█████▎    | 247/468 [44:19<38:55, 10.57s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:19:33,402] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.66 | bwd_microstep: 3432.16 | bwd_inner_microstep: 3432.13 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:19:38,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.62 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:19:38,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.23 | bwd_microstep: 3430.29 | bwd_inner_microstep: 3415.46 | bwd_allreduce_microstep: 14.78 | step_microstep: 8.30\n",
      "[2024-09-15 16:19:38,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3813.86 | bwd: 6862.46 | bwd_inner: 6847.59 | bwd_allreduce: 14.80 | step: 8.40\n",
      "{'loss': 0.2317, 'learning_rate': 1.909874449637122e-05, 'epoch': 1.58}\n",
      " 53%|█████▎    | 248/468 [44:30<38:56, 10.62s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:19:44,188] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.56 | bwd_microstep: 3454.95 | bwd_inner_microstep: 3454.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 16:19:49,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:19:49,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1454.85 | bwd_microstep: 3877.99 | bwd_inner_microstep: 2570.42 | bwd_allreduce_microstep: 1307.52 | step_microstep: 7.79\n",
      "[2024-09-15 16:19:49,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.38 | bwd: 7332.96 | bwd_inner: 6025.34 | bwd_allreduce: 1307.55 | step: 8.03\n",
      "{'loss': 0.218, 'learning_rate': 1.8960206516760396e-05, 'epoch': 1.59}\n",
      " 53%|█████▎    | 249/468 [44:40<38:57, 10.67s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:19:53,638] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.39 | bwd_microstep: 2586.04 | bwd_inner_microstep: 2586.02 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:20:00,277] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:20:00,278] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.56 | bwd_microstep: 5114.77 | bwd_inner_microstep: 2627.83 | bwd_allreduce_microstep: 2486.88 | step_microstep: 7.28\n",
      "[2024-09-15 16:20:00,278] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2955.92 | bwd: 7700.83 | bwd_inner: 5213.84 | bwd_allreduce: 2486.92 | step: 7.52\n",
      "{'loss': 0.1777, 'learning_rate': 1.8821718546209646e-05, 'epoch': 1.6}\n",
      " 53%|█████▎    | 250/468 [44:51<38:49, 10.69s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 16:20:04,326] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1450.51 | bwd_microstep: 2567.64 | bwd_inner_microstep: 2567.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:20:10,956] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:20:10,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.38 | bwd_microstep: 4678.51 | bwd_inner_microstep: 3434.70 | bwd_allreduce_microstep: 1243.76 | step_microstep: 7.51\n",
      "[2024-09-15 16:20:10,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3366.86 | bwd: 7246.20 | bwd_inner: 6002.30 | bwd_allreduce: 1243.79 | step: 7.74\n",
      "{'loss': 0.1577, 'learning_rate': 1.8683287245323536e-05, 'epoch': 1.6}\n",
      " 54%|█████▎    | 251/468 [45:02<38:38, 10.68s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1371\n",
      "[2024-09-15 16:20:15,041] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.68 | bwd_microstep: 2587.14 | bwd_inner_microstep: 2587.12 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:20:20,463] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:20:20,463] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.24 | bwd_microstep: 3471.73 | bwd_inner_microstep: 3437.58 | bwd_allreduce_microstep: 34.10 | step_microstep: 7.72\n",
      "[2024-09-15 16:20:20,464] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3382.89 | bwd: 6058.88 | bwd_inner: 6024.70 | bwd_allreduce: 34.12 | step: 7.95\n",
      "{'loss': 0.2977, 'learning_rate': 1.8544919271981125e-05, 'epoch': 1.61}\n",
      " 54%|█████▍    | 252/468 [45:11<37:11, 10.33s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 16:20:24,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.88 | bwd_microstep: 2549.52 | bwd_inner_microstep: 2549.40 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:20:31,156] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.43 | optimizer_step: 0.41\n",
      "[2024-09-15 16:20:31,157] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.14 | bwd_microstep: 4703.71 | bwd_inner_microstep: 3463.29 | bwd_allreduce_microstep: 1240.36 | step_microstep: 7.65\n",
      "[2024-09-15 16:20:31,157] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3373.99 | bwd: 7253.27 | bwd_inner: 6012.69 | bwd_allreduce: 1240.46 | step: 7.89\n",
      "{'loss': 0.2277, 'learning_rate': 1.84066212810157e-05, 'epoch': 1.62}\n",
      " 54%|█████▍    | 253/468 [45:22<37:24, 10.44s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1372\n",
      "[2024-09-15 16:20:35,181] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1439.40 | bwd_microstep: 2554.83 | bwd_inner_microstep: 2554.80 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:20:41,847] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.42 | optimizer_step: 0.41\n",
      "[2024-09-15 16:20:41,848] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.26 | bwd_microstep: 5140.47 | bwd_inner_microstep: 2625.83 | bwd_allreduce_microstep: 2514.58 | step_microstep: 7.57\n",
      "[2024-09-15 16:20:41,848] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2931.62 | bwd: 7695.32 | bwd_inner: 5180.63 | bwd_allreduce: 2514.62 | step: 7.79\n",
      "{'loss': 0.1574, 'learning_rate': 1.8268399923894736e-05, 'epoch': 1.62}\n",
      " 54%|█████▍    | 254/468 [45:33<37:30, 10.52s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:20:45,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.20 | bwd_microstep: 2584.09 | bwd_inner_microstep: 2584.06 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:20:52,579] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:20:52,580] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.79 | bwd_microstep: 5125.29 | bwd_inner_microstep: 2625.60 | bwd_allreduce_microstep: 2499.63 | step_microstep: 7.48\n",
      "[2024-09-15 16:20:52,580] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2957.96 | bwd: 7709.42 | bwd_inner: 5209.66 | bwd_allreduce: 2499.66 | step: 7.71\n",
      "{'loss': 0.3187, 'learning_rate': 1.8130261848399996e-05, 'epoch': 1.63}\n",
      " 54%|█████▍    | 255/468 [45:43<37:33, 10.58s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:20:56,621] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1449.25 | bwd_microstep: 2561.72 | bwd_inner_microstep: 2561.63 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:21:03,409] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:21:03,410] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.78 | bwd_microstep: 4839.59 | bwd_inner_microstep: 3432.58 | bwd_allreduce_microstep: 1406.95 | step_microstep: 7.53\n",
      "[2024-09-15 16:21:03,410] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3362.01 | bwd: 7401.35 | bwd_inner: 5994.21 | bwd_allreduce: 1407.02 | step: 7.77\n",
      "{'loss': 0.1758, 'learning_rate': 1.7992213698307795e-05, 'epoch': 1.64}\n",
      " 55%|█████▍    | 256/468 [45:54<37:38, 10.66s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 16:21:08,785] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.48 | bwd_microstep: 3431.87 | bwd_inner_microstep: 3431.85 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1387\n",
      "[2024-09-15 16:21:14,206] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:21:14,207] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.19 | bwd_microstep: 3898.96 | bwd_inner_microstep: 2620.66 | bwd_allreduce_microstep: 1278.23 | step_microstep: 7.44\n",
      "[2024-09-15 16:21:14,207] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3402.65 | bwd: 7330.84 | bwd_inner: 6052.51 | bwd_allreduce: 1278.26 | step: 7.52\n",
      "{'loss': 0.2118, 'learning_rate': 1.7854262113069468e-05, 'epoch': 1.64}\n",
      " 55%|█████▍    | 257/468 [46:05<37:37, 10.70s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:21:19,575] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.55 | bwd_microstep: 3427.73 | bwd_inner_microstep: 3427.70 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:21:25,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.38 | optimizer_step: 0.40\n",
      "[2024-09-15 16:21:25,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.06 | bwd_microstep: 3910.98 | bwd_inner_microstep: 2626.17 | bwd_allreduce_microstep: 1284.75 | step_microstep: 7.72\n",
      "[2024-09-15 16:21:25,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3400.58 | bwd: 7338.72 | bwd_inner: 6053.87 | bwd_allreduce: 1284.78 | step: 7.94\n",
      "{'loss': 0.1539, 'learning_rate': 1.7716413727492035e-05, 'epoch': 1.65}\n",
      " 55%|█████▌    | 258/468 [46:16<37:33, 10.73s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:21:29,093] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.51 | bwd_microstep: 2587.34 | bwd_inner_microstep: 2587.32 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:21:34,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.46 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:21:34,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.36 | bwd_microstep: 3862.68 | bwd_inner_microstep: 2628.35 | bwd_allreduce_microstep: 1234.27 | step_microstep: 7.48\n",
      "[2024-09-15 16:21:34,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2952.84 | bwd: 6450.06 | bwd_inner: 5215.67 | bwd_allreduce: 1234.30 | step: 7.71\n",
      "{'loss': 0.1885, 'learning_rate': 1.757867517141913e-05, 'epoch': 1.65}\n",
      " 55%|█████▌    | 259/468 [46:25<36:03, 10.35s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:21:38,562] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.16 | bwd_microstep: 2587.52 | bwd_inner_microstep: 2587.49 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:21:45,212] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.39 | optimizer_step: 0.39\n",
      "[2024-09-15 16:21:45,213] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.31 | bwd_microstep: 5124.55 | bwd_inner_microstep: 2628.01 | bwd_allreduce_microstep: 2496.47 | step_microstep: 9.10\n",
      "[2024-09-15 16:21:45,213] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2951.45 | bwd: 7712.10 | bwd_inner: 5215.50 | bwd_allreduce: 2496.50 | step: 9.37\n",
      "{'loss': 0.1915, 'learning_rate': 1.7441053069412103e-05, 'epoch': 1.66}\n",
      " 56%|█████▌    | 260/468 [46:36<36:16, 10.47s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:21:50,628] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1927.62 | bwd_microstep: 3452.11 | bwd_inner_microstep: 3452.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:21:56,092] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:21:56,093] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1895.36 | bwd_microstep: 3534.30 | bwd_inner_microstep: 3415.17 | bwd_allreduce_microstep: 119.07 | step_microstep: 7.69\n",
      "[2024-09-15 16:21:56,093] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3822.96 | bwd: 6986.43 | bwd_inner: 6867.26 | bwd_allreduce: 119.10 | step: 7.92\n",
      "{'loss': 0.1716, 'learning_rate': 1.7303554040431426e-05, 'epoch': 1.67}\n",
      " 56%|█████▌    | 261/468 [46:47<36:32, 10.59s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:22:01,471] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.47 | bwd_microstep: 3434.54 | bwd_inner_microstep: 3434.51 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 16:22:06,815] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.40 | optimizer_step: 0.38\n",
      "[2024-09-15 16:22:06,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1476.11 | bwd_microstep: 3832.31 | bwd_inner_microstep: 2607.99 | bwd_allreduce_microstep: 1224.26 | step_microstep: 8.20\n",
      "[2024-09-15 16:22:06,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3388.56 | bwd: 7266.86 | bwd_inner: 6042.50 | bwd_allreduce: 1224.29 | step: 8.45\n",
      "{'loss': 0.2217, 'learning_rate': 1.7166184697518352e-05, 'epoch': 1.67}\n",
      " 56%|█████▌    | 262/468 [46:58<36:29, 10.63s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 16:22:10,865] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1450.19 | bwd_microstep: 2568.85 | bwd_inner_microstep: 2568.78 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:22:17,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:22:17,594] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1930.05 | bwd_microstep: 4762.21 | bwd_inner_microstep: 3460.89 | bwd_allreduce_microstep: 1301.26 | step_microstep: 7.28\n",
      "[2024-09-15 16:22:17,594] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3380.22 | bwd: 7331.10 | bwd_inner: 6029.67 | bwd_allreduce: 1301.30 | step: 7.51\n",
      "{'loss': 0.3266, 'learning_rate': 1.7028951647476862e-05, 'epoch': 1.68}\n",
      " 56%|█████▌    | 263/468 [47:08<36:28, 10.67s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:22:22,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.53 | bwd_microstep: 3415.85 | bwd_inner_microstep: 3415.82 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:22:28,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.24 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:22:28,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1929.19 | bwd_microstep: 3476.65 | bwd_inner_microstep: 3461.58 | bwd_allreduce_microstep: 15.02 | step_microstep: 11.85\n",
      "[2024-09-15 16:22:28,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3825.69 | bwd: 6892.51 | bwd_inner: 6877.41 | bwd_allreduce: 15.04 | step: 11.92\n",
      "{'loss': 0.2631, 'learning_rate': 1.6891861490555906e-05, 'epoch': 1.69}\n",
      " 56%|█████▋    | 264/468 [47:19<36:24, 10.71s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:22:32,471] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.71 | bwd_microstep: 2591.00 | bwd_inner_microstep: 2590.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:22:39,075] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:22:39,075] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.76 | bwd_microstep: 4653.12 | bwd_inner_microstep: 3440.73 | bwd_allreduce_microstep: 1212.32 | step_microstep: 7.50\n",
      "[2024-09-15 16:22:39,075] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3382.44 | bwd: 7244.13 | bwd_inner: 6031.70 | bwd_allreduce: 1212.36 | step: 7.72\n",
      "{'loss': 0.2481, 'learning_rate': 1.6754920820131946e-05, 'epoch': 1.69}\n",
      " 57%|█████▋    | 265/468 [47:30<36:12, 10.70s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:22:44,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.35 | bwd_microstep: 3438.35 | bwd_inner_microstep: 3438.32 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1900\n",
      "[2024-09-15 16:22:49,986] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 16:22:49,987] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1967.31 | bwd_microstep: 3527.33 | bwd_inner_microstep: 3512.46 | bwd_allreduce_microstep: 14.82 | step_microstep: 8.09\n",
      "[2024-09-15 16:22:49,987] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3878.64 | bwd: 6965.69 | bwd_inner: 6950.78 | bwd_allreduce: 14.84 | step: 8.36\n",
      "{'loss': 0.2521, 'learning_rate': 1.6618136222391893e-05, 'epoch': 1.7}\n",
      " 57%|█████▋    | 266/468 [47:41<36:14, 10.77s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:22:54,076] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.75 | bwd_microstep: 2591.28 | bwd_inner_microstep: 2591.13 | bwd_allreduce_microstep: 0.07 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:22:59,429] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:22:59,429] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.78 | bwd_microstep: 3825.57 | bwd_inner_microstep: 2632.39 | bwd_allreduce_microstep: 1193.12 | step_microstep: 7.51\n",
      "[2024-09-15 16:22:59,429] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2960.51 | bwd: 6416.89 | bwd_inner: 5223.52 | bwd_allreduce: 1193.24 | step: 7.74\n",
      "{'loss': 0.2022, 'learning_rate': 1.6481514276016297e-05, 'epoch': 1.71}\n",
      " 57%|█████▋    | 267/468 [47:50<34:44, 10.37s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:23:03,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.16 | bwd_microstep: 2591.28 | bwd_inner_microstep: 2591.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:23:08,838] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:23:08,838] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.06 | bwd_microstep: 3816.86 | bwd_inner_microstep: 2595.20 | bwd_allreduce_microstep: 1221.61 | step_microstep: 7.47\n",
      "[2024-09-15 16:23:08,839] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2934.20 | bwd: 6408.16 | bwd_inner: 5186.45 | bwd_allreduce: 1221.64 | step: 7.70\n",
      "{'loss': 0.2055, 'learning_rate': 1.634506155186295e-05, 'epoch': 1.71}\n",
      " 57%|█████▋    | 268/468 [48:00<33:36, 10.08s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:23:12,924] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.98 | bwd_microstep: 2591.38 | bwd_inner_microstep: 2591.34 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1389\n",
      "[2024-09-15 16:23:19,566] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:23:19,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.41 | bwd_microstep: 5146.82 | bwd_inner_microstep: 2595.77 | bwd_allreduce_microstep: 2550.99 | step_microstep: 7.51\n",
      "[2024-09-15 16:23:19,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2924.37 | bwd: 7738.24 | bwd_inner: 5187.11 | bwd_allreduce: 2551.01 | step: 7.74\n",
      "{'loss': 0.2257, 'learning_rate': 1.6208784612650883e-05, 'epoch': 1.72}\n",
      " 57%|█████▋    | 269/468 [48:10<34:04, 10.28s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:23:24,878] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1881.65 | bwd_microstep: 3399.46 | bwd_inner_microstep: 3399.43 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:23:30,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.74 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:23:30,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.13 | bwd_microstep: 3453.78 | bwd_inner_microstep: 3438.73 | bwd_allreduce_microstep: 15.00 | step_microstep: 8.00\n",
      "[2024-09-15 16:23:30,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3794.75 | bwd: 6853.27 | bwd_inner: 6838.17 | bwd_allreduce: 15.03 | step: 8.23\n",
      "{'loss': 0.2634, 'learning_rate': 1.6072690012644717e-05, 'epoch': 1.73}\n",
      " 58%|█████▊    | 270/468 [48:21<34:20, 10.41s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:23:35,660] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.89 | bwd_microstep: 3435.28 | bwd_inner_microstep: 3435.26 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1390\n",
      "[2024-09-15 16:23:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.69 | optimizer_gradients: 0.33 | optimizer_step: 0.40\n",
      "[2024-09-15 16:23:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1478.06 | bwd_microstep: 2624.48 | bwd_inner_microstep: 2609.43 | bwd_allreduce_microstep: 15.00 | step_microstep: 7.92\n",
      "[2024-09-15 16:23:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3389.92 | bwd: 6059.77 | bwd_inner: 6044.69 | bwd_allreduce: 15.02 | step: 8.18\n",
      "{'loss': 0.2195, 'learning_rate': 1.593678429733944e-05, 'epoch': 1.73}\n",
      " 58%|█████▊    | 271/468 [48:31<33:17, 10.14s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:23:43,888] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.10 | bwd_microstep: 2592.67 | bwd_inner_microstep: 2592.64 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:23:50,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:23:50,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.78 | bwd_microstep: 4659.90 | bwd_inner_microstep: 3440.25 | bwd_allreduce_microstep: 1219.60 | step_microstep: 7.21\n",
      "[2024-09-15 16:23:50,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3385.85 | bwd: 7252.61 | bwd_inner: 6032.89 | bwd_allreduce: 1219.63 | step: 7.43\n",
      "{'loss': 0.2063, 'learning_rate': 1.5801074003145585e-05, 'epoch': 1.74}\n",
      " 58%|█████▊    | 272/468 [48:41<33:40, 10.31s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:23:54,525] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1437.33 | bwd_microstep: 2556.19 | bwd_inner_microstep: 2556.09 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:24:01,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:24:01,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.58 | bwd_microstep: 4745.28 | bwd_inner_microstep: 3425.19 | bwd_allreduce_microstep: 1320.03 | step_microstep: 7.60\n",
      "[2024-09-15 16:24:01,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3336.89 | bwd: 7301.51 | bwd_inner: 5981.28 | bwd_allreduce: 1320.10 | step: 7.82\n",
      "{'loss': 0.2601, 'learning_rate': 1.5665565657074874e-05, 'epoch': 1.74}\n",
      " 58%|█████▊    | 273/468 [48:52<33:53, 10.43s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:24:06,569] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1908.38 | bwd_microstep: 3425.33 | bwd_inner_microstep: 3425.30 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1387\n",
      "[2024-09-15 16:24:11,928] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.24 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:24:11,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.56 | bwd_microstep: 3833.44 | bwd_inner_microstep: 2628.83 | bwd_allreduce_microstep: 1204.55 | step_microstep: 7.51\n",
      "[2024-09-15 16:24:11,929] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3397.92 | bwd: 7258.78 | bwd_inner: 6054.14 | bwd_allreduce: 1204.58 | step: 7.74\n",
      "{'loss': 0.1633, 'learning_rate': 1.5530265776426294e-05, 'epoch': 1.75}\n",
      " 59%|█████▊    | 274/468 [49:03<34:00, 10.52s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:24:17,355] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.72 | bwd_microstep: 3459.21 | bwd_inner_microstep: 3459.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:24:22,755] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.25 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:24:22,756] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.35 | bwd_microstep: 3448.09 | bwd_inner_microstep: 3433.14 | bwd_allreduce_microstep: 14.91 | step_microstep: 11.43\n",
      "[2024-09-15 16:24:22,756] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3848.05 | bwd: 6907.31 | bwd_inner: 6892.32 | bwd_allreduce: 14.92 | step: 11.66\n",
      "{'loss': 0.2333, 'learning_rate': 1.5395180868472662e-05, 'epoch': 1.76}\n",
      " 59%|█████▉    | 275/468 [49:14<34:07, 10.61s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:24:28,185] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.06 | bwd_microstep: 3464.28 | bwd_inner_microstep: 3464.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 16:24:33,392] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.29 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:24:33,392] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1441.92 | bwd_microstep: 3729.41 | bwd_inner_microstep: 2558.73 | bwd_allreduce_microstep: 1170.62 | step_microstep: 7.57\n",
      "[2024-09-15 16:24:33,392] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3376.96 | bwd: 7193.70 | bwd_inner: 6022.98 | bwd_allreduce: 1170.65 | step: 7.66\n",
      "{'loss': 0.149, 'learning_rate': 1.5260317430147627e-05, 'epoch': 1.76}\n",
      " 59%|█████▉    | 276/468 [49:24<33:58, 10.62s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:24:37,448] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1453.66 | bwd_microstep: 2572.05 | bwd_inner_microstep: 2571.96 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:24:44,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:24:44,118] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.00 | bwd_microstep: 4693.81 | bwd_inner_microstep: 3471.86 | bwd_allreduce_microstep: 1221.89 | step_microstep: 7.46\n",
      "[2024-09-15 16:24:44,118] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3394.64 | bwd: 7265.92 | bwd_inner: 6043.82 | bwd_allreduce: 1221.95 | step: 7.68\n",
      "{'loss': 0.2587, 'learning_rate': 1.512568194773322e-05, 'epoch': 1.77}\n",
      " 59%|█████▉    | 277/468 [49:35<33:54, 10.65s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:24:48,206] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.20 | bwd_microstep: 2590.33 | bwd_inner_microstep: 2590.31 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:24:53,650] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.66 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:24:53,651] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.36 | bwd_microstep: 3475.76 | bwd_inner_microstep: 3460.82 | bwd_allreduce_microstep: 14.90 | step_microstep: 7.86\n",
      "[2024-09-15 16:24:53,651] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.52 | bwd: 6066.11 | bwd_inner: 6051.13 | bwd_allreduce: 14.92 | step: 7.92\n",
      "{'loss': 0.1951, 'learning_rate': 1.4991280896547893e-05, 'epoch': 1.78}\n",
      " 59%|█████▉    | 278/468 [49:45<32:39, 10.31s/it]dynamic ViT batch size: 48, images per sample: 6.0, dynamic token length: 1879\n",
      "[2024-09-15 16:24:59,156] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1965.62 | bwd_microstep: 3507.94 | bwd_inner_microstep: 3507.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:25:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:25:03,331] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.23 | bwd_microstep: 2646.31 | bwd_inner_microstep: 2631.14 | bwd_allreduce_microstep: 15.12 | step_microstep: 7.94\n",
      "[2024-09-15 16:25:03,331] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3458.84 | bwd: 6154.27 | bwd_inner: 6139.06 | bwd_allreduce: 15.14 | step: 8.20\n",
      "{'loss': 0.2757, 'learning_rate': 1.4857120740635084e-05, 'epoch': 1.78}\n",
      " 60%|█████▉    | 279/468 [49:54<31:53, 10.12s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 16:25:08,757] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.30 | bwd_microstep: 3460.26 | bwd_inner_microstep: 3460.24 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:25:14,224] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:25:14,224] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.68 | bwd_microstep: 3488.02 | bwd_inner_microstep: 3473.04 | bwd_allreduce_microstep: 14.93 | step_microstep: 8.30\n",
      "[2024-09-15 16:25:14,224] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3876.97 | bwd: 6948.29 | bwd_inner: 6933.28 | bwd_allreduce: 14.95 | step: 8.53\n",
      "{'loss': 0.2321, 'learning_rate': 1.472320793245233e-05, 'epoch': 1.79}\n",
      " 60%|█████▉    | 280/468 [50:05<32:26, 10.36s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:25:18,321] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.96 | bwd_microstep: 2593.94 | bwd_inner_microstep: 2593.91 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:25:24,844] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.82 | optimizer_gradients: 0.42 | optimizer_step: 0.41\n",
      "[2024-09-15 16:25:24,844] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.07 | bwd_microstep: 4991.37 | bwd_inner_microstep: 2633.57 | bwd_allreduce_microstep: 2357.74 | step_microstep: 10.55\n",
      "[2024-09-15 16:25:24,845] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2967.01 | bwd: 7585.35 | bwd_inner: 5227.48 | bwd_allreduce: 2357.77 | step: 10.80\n",
      "{'loss': 0.2177, 'learning_rate': 1.4589548912560932e-05, 'epoch': 1.8}\n",
      " 60%|██████    | 281/468 [50:16<32:31, 10.43s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:25:30,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.02 | bwd_microstep: 3425.62 | bwd_inner_microstep: 3425.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:25:35,588] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:25:35,588] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.69 | bwd_microstep: 3435.61 | bwd_inner_microstep: 3420.44 | bwd_allreduce_microstep: 15.12 | step_microstep: 8.26\n",
      "[2024-09-15 16:25:35,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3815.68 | bwd: 6861.24 | bwd_inner: 6846.03 | bwd_allreduce: 15.15 | step: 8.44\n",
      "{'loss': 0.1363, 'learning_rate': 1.4456150109316192e-05, 'epoch': 1.8}\n",
      " 60%|██████    | 282/468 [50:26<32:38, 10.53s/it]dynamic ViT batch size: 34, images per sample: 4.25, dynamic token length: 1880\n",
      "[2024-09-15 16:25:40,859] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1862.89 | bwd_microstep: 3377.19 | bwd_inner_microstep: 3376.95 | bwd_allreduce_microstep: 0.14 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:25:46,266] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:25:46,266] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.98 | bwd_microstep: 3451.42 | bwd_inner_microstep: 3436.46 | bwd_allreduce_microstep: 14.91 | step_microstep: 8.10\n",
      "[2024-09-15 16:25:46,266] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3782.85 | bwd: 6828.65 | bwd_inner: 6813.41 | bwd_allreduce: 15.07 | step: 8.34\n",
      "{'loss': 0.1428, 'learning_rate': 1.4323017938558245e-05, 'epoch': 1.81}\n",
      " 60%|██████    | 283/468 [50:37<32:35, 10.57s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 16:25:51,700] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.91 | bwd_microstep: 3463.31 | bwd_inner_microstep: 3463.29 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.31\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:25:57,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.36 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:25:57,080] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.37 | bwd_microstep: 3439.46 | bwd_inner_microstep: 3424.64 | bwd_allreduce_microstep: 14.78 | step_microstep: 8.06\n",
      "[2024-09-15 16:25:57,080] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3844.25 | bwd: 6902.79 | bwd_inner: 6887.93 | bwd_allreduce: 14.80 | step: 8.40\n",
      "{'loss': 0.2112, 'learning_rate': 1.4190158803303498e-05, 'epoch': 1.81}\n",
      " 61%|██████    | 284/468 [50:48<32:38, 10.64s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:26:01,178] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.60 | bwd_microstep: 2595.56 | bwd_inner_microstep: 2595.46 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:26:07,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:26:07,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.30 | bwd_microstep: 4655.48 | bwd_inner_microstep: 3442.48 | bwd_allreduce_microstep: 1212.95 | step_microstep: 7.80\n",
      "[2024-09-15 16:26:07,789] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.88 | bwd: 7251.08 | bwd_inner: 6037.94 | bwd_allreduce: 1213.01 | step: 8.04\n",
      "{'loss': 0.2269, 'learning_rate': 1.4057579093436653e-05, 'epoch': 1.82}\n",
      " 61%|██████    | 285/468 [50:59<32:31, 10.66s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:26:13,176] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.23 | bwd_microstep: 3438.48 | bwd_inner_microstep: 3438.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:26:18,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.37 | optimizer_gradients: 0.38 | optimizer_step: 0.40\n",
      "[2024-09-15 16:26:18,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.62 | bwd_microstep: 3839.42 | bwd_inner_microstep: 2631.24 | bwd_allreduce_microstep: 1208.12 | step_microstep: 7.76\n",
      "[2024-09-15 16:26:18,543] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3410.83 | bwd: 7277.94 | bwd_inner: 6069.65 | bwd_allreduce: 1208.17 | step: 8.00\n",
      "{'loss': 0.1712, 'learning_rate': 1.3925285185403406e-05, 'epoch': 1.83}\n",
      " 61%|██████    | 286/468 [51:09<32:25, 10.69s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:26:22,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.34 | bwd_microstep: 2591.51 | bwd_inner_microstep: 2591.48 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.34\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:26:29,216] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:26:29,217] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.09 | bwd_microstep: 5051.04 | bwd_inner_microstep: 2630.83 | bwd_allreduce_microstep: 2420.15 | step_microstep: 7.76\n",
      "[2024-09-15 16:26:29,217] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2966.39 | bwd: 7642.58 | bwd_inner: 5222.31 | bwd_allreduce: 2420.18 | step: 8.11\n",
      "{'loss': 0.1182, 'learning_rate': 1.3793283441903737e-05, 'epoch': 1.83}\n",
      " 61%|██████▏   | 287/468 [51:20<32:14, 10.69s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:26:33,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.32 | bwd_microstep: 2588.99 | bwd_inner_microstep: 2588.94 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:26:39,943] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 16:26:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1890.14 | bwd_microstep: 4714.75 | bwd_inner_microstep: 3399.82 | bwd_allreduce_microstep: 1314.87 | step_microstep: 7.90\n",
      "[2024-09-15 16:26:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3357.42 | bwd: 7303.78 | bwd_inner: 5988.76 | bwd_allreduce: 1314.90 | step: 8.16\n",
      "{'loss': 0.1667, 'learning_rate': 1.3661580211585947e-05, 'epoch': 1.84}\n",
      " 62%|██████▏   | 288/468 [51:31<32:05, 10.70s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1880\n",
      "[2024-09-15 16:26:45,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.70 | bwd_microstep: 3456.86 | bwd_inner_microstep: 3456.83 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:26:50,808] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.60 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:26:50,808] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.41 | bwd_microstep: 3472.38 | bwd_inner_microstep: 3457.56 | bwd_allreduce_microstep: 14.78 | step_microstep: 7.93\n",
      "[2024-09-15 16:26:50,808] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3869.07 | bwd: 6929.25 | bwd_inner: 6914.39 | bwd_allreduce: 14.80 | step: 8.16\n",
      "{'loss': 0.2887, 'learning_rate': 1.3530181828741285e-05, 'epoch': 1.85}\n",
      " 62%|██████▏   | 289/468 [51:42<32:03, 10.75s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:26:56,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.28 | bwd_microstep: 3438.92 | bwd_inner_microstep: 3438.88 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.30\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 16:27:01,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:01,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1890.66 | bwd_microstep: 3420.55 | bwd_inner_microstep: 3404.82 | bwd_allreduce_microstep: 15.67 | step_microstep: 8.52\n",
      "[2024-09-15 16:27:01,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3807.90 | bwd: 6859.50 | bwd_inner: 6843.71 | bwd_allreduce: 15.70 | step: 8.82\n",
      "{'loss': 0.1624, 'learning_rate': 1.3399094612999291e-05, 'epoch': 1.85}\n",
      " 62%|██████▏   | 290/468 [51:52<31:52, 10.74s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:27:06,895] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.96 | bwd_microstep: 3420.08 | bwd_inner_microstep: 3419.90 | bwd_allreduce_microstep: 0.09 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:27:12,308] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:12,309] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.53 | bwd_microstep: 3456.11 | bwd_inner_microstep: 3441.29 | bwd_allreduce_microstep: 14.78 | step_microstep: 8.59\n",
      "[2024-09-15 16:27:12,309] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3821.44 | bwd: 6876.23 | bwd_inner: 6861.19 | bwd_allreduce: 14.92 | step: 8.84\n",
      "{'loss': 0.2356, 'learning_rate': 1.3268324869023878e-05, 'epoch': 1.86}\n",
      " 62%|██████▏   | 291/468 [52:03<31:42, 10.75s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:27:16,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.35 | bwd_microstep: 2592.63 | bwd_inner_microstep: 2592.61 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:27:21,744] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.41 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:21,745] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1473.35 | bwd_microstep: 3833.16 | bwd_inner_microstep: 2595.77 | bwd_allreduce_microstep: 1237.34 | step_microstep: 7.56\n",
      "[2024-09-15 16:27:21,745] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2944.67 | bwd: 6425.81 | bwd_inner: 5188.37 | bwd_allreduce: 1237.37 | step: 7.79\n",
      "{'loss': 0.2557, 'learning_rate': 1.313787888621009e-05, 'epoch': 1.87}\n",
      " 62%|██████▏   | 292/468 [52:13<30:22, 10.36s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:27:27,130] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.19 | bwd_microstep: 3437.21 | bwd_inner_microstep: 3437.14 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:27:32,541] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:32,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.56 | bwd_microstep: 3454.98 | bwd_inner_microstep: 3439.66 | bwd_allreduce_microstep: 15.28 | step_microstep: 7.88\n",
      "[2024-09-15 16:27:32,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3837.72 | bwd: 6892.23 | bwd_inner: 6876.80 | bwd_allreduce: 15.31 | step: 8.13\n",
      "{'loss': 0.2203, 'learning_rate': 1.3007762938381619e-05, 'epoch': 1.87}\n",
      " 63%|██████▎   | 293/468 [52:23<30:35, 10.49s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:27:37,973] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.69 | bwd_microstep: 3463.36 | bwd_inner_microstep: 3463.33 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:27:43,335] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.66 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:43,335] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.99 | bwd_microstep: 3427.06 | bwd_inner_microstep: 3411.81 | bwd_allreduce_microstep: 15.21 | step_microstep: 8.00\n",
      "[2024-09-15 16:27:43,336] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3837.65 | bwd: 6890.44 | bwd_inner: 6875.14 | bwd_allreduce: 15.23 | step: 8.25\n",
      "{'loss': 0.3142, 'learning_rate': 1.2877983283489062e-05, 'epoch': 1.88}\n",
      " 63%|██████▎   | 294/468 [52:34<30:40, 10.58s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:27:48,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1922.01 | bwd_microstep: 3444.34 | bwd_inner_microstep: 3444.22 | bwd_allreduce_microstep: 0.04 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1876\n",
      "[2024-09-15 16:27:54,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:27:54,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.01 | bwd_microstep: 3437.07 | bwd_inner_microstep: 3422.35 | bwd_allreduce_microstep: 14.65 | step_microstep: 8.14\n",
      "[2024-09-15 16:27:54,109] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3826.00 | bwd: 6881.45 | bwd_inner: 6866.57 | bwd_allreduce: 14.75 | step: 8.37\n",
      "{'loss': 0.16, 'learning_rate': 1.2748546163308947e-05, 'epoch': 1.88}\n",
      " 63%|██████▎   | 295/468 [52:45<30:40, 10.64s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:27:59,507] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.93 | bwd_microstep: 3445.40 | bwd_inner_microstep: 3445.35 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:28:04,968] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:28:04,968] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.45 | bwd_microstep: 3483.19 | bwd_inner_microstep: 3468.04 | bwd_allreduce_microstep: 15.10 | step_microstep: 8.72\n",
      "[2024-09-15 16:28:04,969] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3863.35 | bwd: 6928.62 | bwd_inner: 6913.39 | bwd_allreduce: 15.12 | step: 8.97\n",
      "{'loss': 0.1647, 'learning_rate': 1.261945780314354e-05, 'epoch': 1.89}\n",
      " 63%|██████▎   | 296/468 [52:56<30:41, 10.70s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:28:09,064] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.38 | bwd_microstep: 2592.22 | bwd_inner_microstep: 2592.10 | bwd_allreduce_microstep: 0.04 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:28:14,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 16:28:14,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1458.05 | bwd_microstep: 3811.62 | bwd_inner_microstep: 2577.30 | bwd_allreduce_microstep: 1234.26 | step_microstep: 7.55\n",
      "[2024-09-15 16:28:14,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2930.41 | bwd: 6403.88 | bwd_inner: 5169.40 | bwd_allreduce: 1234.36 | step: 7.82\n",
      "{'loss': 0.2373, 'learning_rate': 1.2490724411521406e-05, 'epoch': 1.9}\n",
      " 63%|██████▎   | 297/468 [53:05<29:23, 10.31s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:28:18,462] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.07 | bwd_microstep: 2592.64 | bwd_inner_microstep: 2592.62 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 16:28:25,084] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.39 | optimizer_step: 0.39\n",
      "[2024-09-15 16:28:25,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1483.35 | bwd_microstep: 5103.65 | bwd_inner_microstep: 2613.21 | bwd_allreduce_microstep: 2490.38 | step_microstep: 7.83\n",
      "[2024-09-15 16:28:25,085] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2953.39 | bwd: 7696.30 | bwd_inner: 5205.82 | bwd_allreduce: 2490.41 | step: 8.03\n",
      "{'loss': 0.1701, 'learning_rate': 1.2362352179898855e-05, 'epoch': 1.9}\n",
      " 64%|██████▎   | 298/468 [53:16<29:33, 10.43s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:28:29,170] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.55 | bwd_microstep: 2586.13 | bwd_inner_microstep: 2586.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 16:28:34,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:28:34,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.96 | bwd_microstep: 3459.40 | bwd_inner_microstep: 3443.82 | bwd_allreduce_microstep: 15.54 | step_microstep: 7.94\n",
      "[2024-09-15 16:28:34,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3388.48 | bwd: 6045.55 | bwd_inner: 6029.92 | bwd_allreduce: 15.56 | step: 8.18\n",
      "{'loss': 0.1522, 'learning_rate': 1.2234347282362129e-05, 'epoch': 1.91}\n",
      " 64%|██████▍   | 299/468 [53:25<28:36, 10.15s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:28:39,973] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.80 | bwd_microstep: 3436.63 | bwd_inner_microstep: 3436.61 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 16:28:45,432] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:28:45,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1941.63 | bwd_microstep: 3482.97 | bwd_inner_microstep: 3468.05 | bwd_allreduce_microstep: 14.87 | step_microstep: 8.59\n",
      "[2024-09-15 16:28:45,433] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3861.41 | bwd: 6919.62 | bwd_inner: 6904.65 | bwd_allreduce: 14.90 | step: 8.82\n",
      "{'loss': 0.1613, 'learning_rate': 1.2106715875330475e-05, 'epoch': 1.92}\n",
      " 64%|██████▍   | 300/468 [53:36<29:00, 10.36s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:28:50,825] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.95 | bwd_microstep: 3442.01 | bwd_inner_microstep: 3441.89 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1388\n",
      "[2024-09-15 16:28:54,984] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:28:54,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.36 | bwd_microstep: 2637.07 | bwd_inner_microstep: 2621.65 | bwd_allreduce_microstep: 15.37 | step_microstep: 7.92\n",
      "[2024-09-15 16:28:54,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3407.29 | bwd: 6079.12 | bwd_inner: 6063.55 | bwd_allreduce: 15.45 | step: 8.16\n",
      "{'loss': 0.1883, 'learning_rate': 1.1979464097260039e-05, 'epoch': 1.92}\n",
      " 64%|██████▍   | 301/468 [53:46<28:09, 10.12s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:28:59,078] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.20 | bwd_microstep: 2591.80 | bwd_inner_microstep: 2591.71 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 45, images per sample: 5.625, dynamic token length: 1901\n",
      "[2024-09-15 16:29:05,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:29:05,793] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1969.42 | bwd_microstep: 4708.98 | bwd_inner_microstep: 3510.22 | bwd_allreduce_microstep: 1198.70 | step_microstep: 7.50\n",
      "[2024-09-15 16:29:05,793] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3440.60 | bwd: 7300.82 | bwd_inner: 6101.93 | bwd_allreduce: 1198.77 | step: 7.75\n",
      "{'loss': 0.2338, 'learning_rate': 1.1852598068348642e-05, 'epoch': 1.93}\n",
      " 65%|██████▍   | 302/468 [53:57<28:34, 10.33s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:29:11,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.97 | bwd_microstep: 3441.17 | bwd_inner_microstep: 3441.14 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:29:15,362] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 16:29:15,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1496.79 | bwd_microstep: 2646.90 | bwd_inner_microstep: 2631.76 | bwd_allreduce_microstep: 15.10 | step_microstep: 7.99\n",
      "[2024-09-15 16:29:15,363] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3415.74 | bwd: 6088.15 | bwd_inner: 6072.90 | bwd_allreduce: 15.12 | step: 8.26\n",
      "{'loss': 0.2248, 'learning_rate': 1.1726123890241439e-05, 'epoch': 1.94}\n",
      " 65%|██████▍   | 303/468 [54:06<27:46, 10.10s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 16:29:19,384] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.55 | bwd_microstep: 2553.49 | bwd_inner_microstep: 2553.23 | bwd_allreduce_microstep: 0.13 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:29:26,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.41 | optimizer_step: 0.42\n",
      "[2024-09-15 16:29:26,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1903.94 | bwd_microstep: 4820.79 | bwd_inner_microstep: 3424.10 | bwd_allreduce_microstep: 1396.62 | step_microstep: 7.52\n",
      "[2024-09-15 16:29:26,144] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3342.46 | bwd: 7374.32 | bwd_inner: 5977.34 | bwd_allreduce: 1396.78 | step: 7.76\n",
      "{'loss': 0.1811, 'learning_rate': 1.1600047645737433e-05, 'epoch': 1.94}\n",
      " 65%|██████▍   | 304/468 [54:17<28:09, 10.30s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:29:30,231] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.09 | bwd_microstep: 2589.19 | bwd_inner_microstep: 2589.05 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:29:36,758] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:29:36,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.09 | bwd_microstep: 4997.41 | bwd_inner_microstep: 2630.23 | bwd_allreduce_microstep: 2367.11 | step_microstep: 7.48\n",
      "[2024-09-15 16:29:36,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2963.16 | bwd: 7586.64 | bwd_inner: 5219.28 | bwd_allreduce: 2367.23 | step: 7.72\n",
      "{'loss': 0.1893, 'learning_rate': 1.1474375398496948e-05, 'epoch': 1.95}\n",
      " 65%|██████▌   | 305/468 [54:28<28:14, 10.40s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:29:40,846] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.16 | bwd_microstep: 2587.71 | bwd_inner_microstep: 2587.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:29:46,232] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:29:46,232] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.87 | bwd_microstep: 3858.80 | bwd_inner_microstep: 2626.43 | bwd_allreduce_microstep: 1232.31 | step_microstep: 7.59\n",
      "[2024-09-15 16:29:46,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2961.01 | bwd: 6446.56 | bwd_inner: 5214.09 | bwd_allreduce: 1232.34 | step: 7.83\n",
      "{'loss': 0.203, 'learning_rate': 1.1349113192749986e-05, 'epoch': 1.96}\n",
      " 65%|██████▌   | 306/468 [54:37<27:19, 10.12s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:29:50,317] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.30 | bwd_microstep: 2587.91 | bwd_inner_microstep: 2587.84 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 16:29:57,024] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:29:57,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1940.36 | bwd_microstep: 4730.97 | bwd_inner_microstep: 3464.08 | bwd_allreduce_microstep: 1266.83 | step_microstep: 7.53\n",
      "[2024-09-15 16:29:57,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3406.62 | bwd: 7318.92 | bwd_inner: 6051.92 | bwd_allreduce: 1266.88 | step: 7.78\n",
      "{'loss': 0.1425, 'learning_rate': 1.1224267053005504e-05, 'epoch': 1.96}\n",
      " 66%|██████▌   | 307/468 [54:48<27:41, 10.32s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:30:02,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1929.58 | bwd_microstep: 3458.23 | bwd_inner_microstep: 3458.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:30:07,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:30:07,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.03 | bwd_microstep: 3888.51 | bwd_inner_microstep: 2589.86 | bwd_allreduce_microstep: 1298.59 | step_microstep: 7.51\n",
      "[2024-09-15 16:30:07,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.58 | bwd: 7346.79 | bwd_inner: 6048.04 | bwd_allreduce: 1298.63 | step: 7.75\n",
      "{'loss': 0.1337, 'learning_rate': 1.1099842983761712e-05, 'epoch': 1.97}\n",
      " 66%|██████▌   | 308/468 [54:59<27:54, 10.47s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:30:11,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.17 | bwd_microstep: 2586.80 | bwd_inner_microstep: 2586.62 | bwd_allreduce_microstep: 0.10 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:30:18,540] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:30:18,540] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.45 | bwd_microstep: 4672.12 | bwd_inner_microstep: 3430.12 | bwd_allreduce_microstep: 1241.94 | step_microstep: 7.51\n",
      "[2024-09-15 16:30:18,540] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.60 | bwd: 7258.96 | bwd_inner: 6016.74 | bwd_allreduce: 1242.09 | step: 7.76\n",
      "{'loss': 0.1684, 'learning_rate': 1.0975846969217258e-05, 'epoch': 1.97}\n",
      " 66%|██████▌   | 309/468 [55:09<27:55, 10.54s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:30:23,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.70 | bwd_microstep: 3432.48 | bwd_inner_microstep: 3432.45 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:30:29,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.39 | optimizer_step: 0.41\n",
      "[2024-09-15 16:30:29,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.29 | bwd_microstep: 3685.70 | bwd_inner_microstep: 2629.68 | bwd_allreduce_microstep: 1055.96 | step_microstep: 7.45\n",
      "[2024-09-15 16:30:29,127] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.96 | bwd: 7118.20 | bwd_inner: 6062.13 | bwd_allreduce: 1055.99 | step: 7.64\n",
      "{'loss': 0.165, 'learning_rate': 1.0852284972983415e-05, 'epoch': 1.98}\n",
      " 66%|██████▌   | 310/468 [55:20<27:47, 10.55s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:30:34,508] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.96 | bwd_microstep: 3434.26 | bwd_inner_microstep: 3434.23 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:30:39,912] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:30:39,912] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.16 | bwd_microstep: 3452.32 | bwd_inner_microstep: 3437.44 | bwd_allreduce_microstep: 14.84 | step_microstep: 8.29\n",
      "[2024-09-15 16:30:39,913] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3833.09 | bwd: 6886.62 | bwd_inner: 6871.66 | bwd_allreduce: 14.86 | step: 8.56\n",
      "{'loss': 0.2462, 'learning_rate': 1.0729162937797257e-05, 'epoch': 1.99}\n",
      " 66%|██████▋   | 311/468 [55:31<27:47, 10.62s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:30:44,000] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.67 | bwd_microstep: 2588.25 | bwd_inner_microstep: 2588.03 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:30:50,730] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.74 | optimizer_gradients: 0.41 | optimizer_step: 0.41\n",
      "[2024-09-15 16:30:50,730] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.75 | bwd_microstep: 4793.11 | bwd_inner_microstep: 3412.72 | bwd_allreduce_microstep: 1380.33 | step_microstep: 10.63\n",
      "[2024-09-15 16:30:50,731] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3368.40 | bwd: 7381.41 | bwd_inner: 6000.75 | bwd_allreduce: 1380.52 | step: 10.89\n",
      "{'loss': 0.2298, 'learning_rate': 1.0606486785235879e-05, 'epoch': 1.99}\n",
      " 67%|██████▋   | 312/468 [55:42<27:46, 10.68s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "[2024-09-15 16:30:56,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.72 | bwd_microstep: 3437.20 | bwd_inner_microstep: 3437.10 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.24\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:31:02,474] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.34 | optimizer_step: 0.41\n",
      "[2024-09-15 16:31:02,475] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.93 | bwd_microstep: 3448.45 | bwd_inner_microstep: 3433.22 | bwd_allreduce_microstep: 15.18 | step_microstep: 7.94\n",
      "[2024-09-15 16:31:02,475] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3829.62 | bwd: 6885.69 | bwd_inner: 6870.32 | bwd_allreduce: 15.25 | step: 8.19\n",
      "{'loss': 0.2047, 'learning_rate': 1.0484262415431536e-05, 'epoch': 2.0}\n",
      " 67%|██████▋   | 313/468 [55:53<28:25, 11.00s/it][2024-09-15 16:31:04,793] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:04,816] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:04,816] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:04,825] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:08,575] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:08,712] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:08,730] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:08,730] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:12,269] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:12,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:12,554] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:12,572] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:16,009] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:16,153] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:16,227] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-15 16:31:16,309] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:31:23,670] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1887.95 | bwd_microstep: 3400.97 | bwd_inner_microstep: 3400.88 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1372\n",
      "[2024-09-15 16:31:28,116] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:31:28,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1453.96 | bwd_microstep: 2957.88 | bwd_inner_microstep: 2568.75 | bwd_allreduce_microstep: 389.07 | step_microstep: 7.37\n",
      "[2024-09-15 16:31:28,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3341.88 | bwd: 6358.89 | bwd_inner: 5969.63 | bwd_allreduce: 389.13 | step: 7.62\n",
      "{'loss': 0.2365, 'learning_rate': 1.0362495706787923e-05, 'epoch': 2.01}\n",
      " 67%|██████▋   | 314/468 [56:19<39:30, 15.39s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:31:32,196] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.18 | bwd_microstep: 2584.16 | bwd_inner_microstep: 2584.13 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:31:38,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.39 | optimizer_step: 0.42\n",
      "[2024-09-15 16:31:38,729] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.22 | bwd_microstep: 5032.01 | bwd_inner_microstep: 2584.18 | bwd_allreduce_microstep: 2447.77 | step_microstep: 7.75\n",
      "[2024-09-15 16:31:38,729] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2930.37 | bwd: 7616.18 | bwd_inner: 5168.32 | bwd_allreduce: 2447.80 | step: 7.96\n",
      "{'loss': 0.1738, 'learning_rate': 1.0241192515697432e-05, 'epoch': 2.01}\n",
      " 67%|██████▋   | 315/468 [56:30<35:35, 13.96s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:31:44,062] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1894.56 | bwd_microstep: 3407.84 | bwd_inner_microstep: 3407.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:31:49,450] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:31:49,451] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.08 | bwd_microstep: 3435.64 | bwd_inner_microstep: 3420.32 | bwd_allreduce_microstep: 15.27 | step_microstep: 8.13\n",
      "[2024-09-15 16:31:49,451] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3810.62 | bwd: 6843.53 | bwd_inner: 6828.09 | bwd_allreduce: 15.30 | step: 8.38\n",
      "{'loss': 0.2467, 'learning_rate': 1.0120358676259508e-05, 'epoch': 2.02}\n",
      " 68%|██████▊   | 316/468 [56:40<32:54, 12.99s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:31:53,582] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1485.88 | bwd_microstep: 2613.65 | bwd_inner_microstep: 2613.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:32:00,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:32:00,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.92 | bwd_microstep: 5043.00 | bwd_inner_microstep: 2581.96 | bwd_allreduce_microstep: 2460.98 | step_microstep: 7.53\n",
      "[2024-09-15 16:32:00,126] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2950.78 | bwd: 7656.68 | bwd_inner: 5195.53 | bwd_allreduce: 2461.02 | step: 7.78\n",
      "{'loss': 0.1459, 'learning_rate': 1.0000000000000006e-05, 'epoch': 2.03}\n",
      " 68%|██████▊   | 317/468 [56:51<30:56, 12.29s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:32:04,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.23 | bwd_microstep: 2618.81 | bwd_inner_microstep: 2618.78 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:32:09,488] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:32:09,488] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.09 | bwd_microstep: 3722.95 | bwd_inner_microstep: 2581.90 | bwd_allreduce_microstep: 1141.00 | step_microstep: 7.48\n",
      "[2024-09-15 16:32:09,489] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2956.30 | bwd: 6341.78 | bwd_inner: 5200.68 | bwd_allreduce: 1141.03 | step: 7.53\n",
      "{'loss': 0.1594, 'learning_rate': 9.880122275591752e-06, 'epoch': 2.03}\n",
      " 68%|██████▊   | 318/468 [57:00<28:32, 11.41s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:32:14,936] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1946.46 | bwd_microstep: 3469.60 | bwd_inner_microstep: 3469.58 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:32:19,032] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 16:32:19,033] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1465.44 | bwd_microstep: 2596.79 | bwd_inner_microstep: 2581.42 | bwd_allreduce_microstep: 15.32 | step_microstep: 7.93\n",
      "[2024-09-15 16:32:19,033] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3411.88 | bwd: 6066.41 | bwd_inner: 6051.00 | bwd_allreduce: 15.35 | step: 8.17\n",
      "{'loss': 0.1145, 'learning_rate': 9.760731268576095e-06, 'epoch': 2.04}\n",
      " 68%|██████▊   | 319/468 [57:10<26:57, 10.85s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1390\n",
      "[2024-09-15 16:32:23,139] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.84 | bwd_microstep: 2601.19 | bwd_inner_microstep: 2601.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:32:29,741] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:32:29,742] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1929.34 | bwd_microstep: 4637.85 | bwd_inner_microstep: 3458.78 | bwd_allreduce_microstep: 1179.00 | step_microstep: 7.29\n",
      "[2024-09-15 16:32:29,742] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.16 | bwd: 7239.05 | bwd_inner: 6059.95 | bwd_allreduce: 1179.03 | step: 7.57\n",
      "{'loss': 0.1485, 'learning_rate': 9.64183272108562e-06, 'epoch': 2.04}\n",
      " 68%|██████▊   | 320/468 [57:21<26:39, 10.81s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:32:33,883] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.05 | bwd_microstep: 2621.91 | bwd_inner_microstep: 2621.89 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:32:40,443] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 16:32:40,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.65 | bwd_microstep: 4612.33 | bwd_inner_microstep: 3432.27 | bwd_allreduce_microstep: 1179.98 | step_microstep: 7.46\n",
      "[2024-09-15 16:32:40,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3400.67 | bwd: 7234.26 | bwd_inner: 6054.16 | bwd_allreduce: 1180.04 | step: 7.62\n",
      "{'loss': 0.0932, 'learning_rate': 9.523432351567979e-06, 'epoch': 2.05}\n",
      " 69%|██████▊   | 321/468 [57:31<26:24, 10.78s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1388\n",
      "[2024-09-15 16:32:44,548] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1475.44 | bwd_microstep: 2598.86 | bwd_inner_microstep: 2598.69 | bwd_allreduce_microstep: 0.09 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1367\n",
      "[2024-09-15 16:32:51,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.24 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:32:51,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.74 | bwd_microstep: 5104.20 | bwd_inner_microstep: 2549.39 | bwd_allreduce_microstep: 2554.75 | step_microstep: 7.58\n",
      "[2024-09-15 16:32:51,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2914.16 | bwd: 7703.10 | bwd_inner: 5148.08 | bwd_allreduce: 2554.87 | step: 7.83\n",
      "{'loss': 0.1819, 'learning_rate': 9.405535854510863e-06, 'epoch': 2.06}\n",
      " 69%|██████▉   | 322/468 [57:42<26:09, 10.75s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:32:56,483] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.94 | bwd_microstep: 3418.51 | bwd_inner_microstep: 3418.48 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:33:01,877] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.33 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:33:01,878] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.28 | bwd_microstep: 3446.27 | bwd_inner_microstep: 3431.45 | bwd_allreduce_microstep: 14.77 | step_microstep: 7.70\n",
      "[2024-09-15 16:33:01,878] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3821.20 | bwd: 6864.79 | bwd_inner: 6849.93 | bwd_allreduce: 14.79 | step: 7.95\n",
      "{'loss': 0.1534, 'learning_rate': 9.288148900168122e-06, 'epoch': 2.06}\n",
      " 69%|██████▉   | 323/468 [57:53<25:58, 10.75s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:33:07,193] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1884.07 | bwd_microstep: 3400.93 | bwd_inner_microstep: 3400.87 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1387\n",
      "[2024-09-15 16:33:12,602] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.13 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:33:12,603] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.21 | bwd_microstep: 3882.04 | bwd_inner_microstep: 2624.54 | bwd_allreduce_microstep: 1257.44 | step_microstep: 7.46\n",
      "[2024-09-15 16:33:12,603] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3375.25 | bwd: 7283.01 | bwd_inner: 6025.41 | bwd_allreduce: 1257.48 | step: 7.71\n",
      "{'loss': 0.1875, 'learning_rate': 9.171277134287057e-06, 'epoch': 2.07}\n",
      " 69%|██████▉   | 324/468 [58:04<25:46, 10.74s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1374\n",
      "[2024-09-15 16:33:16,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1453.35 | bwd_microstep: 2570.34 | bwd_inner_microstep: 2570.27 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:33:23,393] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:33:23,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.00 | bwd_microstep: 4785.58 | bwd_inner_microstep: 3436.78 | bwd_allreduce_microstep: 1348.74 | step_microstep: 7.45\n",
      "[2024-09-15 16:33:23,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3368.33 | bwd: 7355.97 | bwd_inner: 6007.05 | bwd_allreduce: 1348.79 | step: 7.69\n",
      "{'loss': 0.1416, 'learning_rate': 9.054926177836878e-06, 'epoch': 2.08}\n",
      " 69%|██████▉   | 325/468 [58:14<25:38, 10.76s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:33:27,532] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.60 | bwd_microstep: 2619.29 | bwd_inner_microstep: 2619.20 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:33:32,932] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.34 | optimizer_step: 0.41\n",
      "[2024-09-15 16:33:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.30 | bwd_microstep: 3449.93 | bwd_inner_microstep: 3435.09 | bwd_allreduce_microstep: 14.79 | step_microstep: 7.69\n",
      "[2024-09-15 16:33:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.87 | bwd: 6069.26 | bwd_inner: 6054.29 | bwd_allreduce: 14.84 | step: 7.93\n",
      "{'loss': 0.1717, 'learning_rate': 8.939101626738395e-06, 'epoch': 2.08}\n",
      " 70%|██████▉   | 326/468 [58:24<24:35, 10.39s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:33:37,075] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.04 | bwd_microstep: 2621.66 | bwd_inner_microstep: 2621.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1884\n",
      "[2024-09-15 16:33:43,642] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.24 | optimizer_gradients: 0.39 | optimizer_step: 0.43\n",
      "[2024-09-15 16:33:43,642] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1949.86 | bwd_microstep: 4581.95 | bwd_inner_microstep: 3483.13 | bwd_allreduce_microstep: 1098.76 | step_microstep: 7.50\n",
      "[2024-09-15 16:33:43,643] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3439.88 | bwd: 7203.66 | bwd_inner: 6104.72 | bwd_allreduce: 1098.79 | step: 7.75\n",
      "{'loss': 0.1975, 'learning_rate': 8.823809051594816e-06, 'epoch': 2.09}\n",
      " 70%|██████▉   | 327/468 [58:35<24:38, 10.49s/it]dynamic ViT batch size: 50, images per sample: 6.25, dynamic token length: 1900\n",
      "[2024-09-15 16:33:49,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 2001.28 | bwd_microstep: 3555.57 | bwd_inner_microstep: 3555.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:33:54,625] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:33:54,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.98 | bwd_microstep: 3444.63 | bwd_inner_microstep: 3429.28 | bwd_allreduce_microstep: 15.31 | step_microstep: 8.09\n",
      "[2024-09-15 16:33:54,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3916.24 | bwd: 7000.21 | bwd_inner: 6984.82 | bwd_allreduce: 15.33 | step: 8.32\n",
      "{'loss': 0.1706, 'learning_rate': 8.70905399742389e-06, 'epoch': 2.1}\n",
      " 70%|███████   | 328/468 [58:46<24:49, 10.64s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1908\n",
      "[2024-09-15 16:34:00,068] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1938.04 | bwd_microstep: 3472.99 | bwd_inner_microstep: 3472.96 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1880\n",
      "[2024-09-15 16:34:05,459] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 16:34:05,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.21 | bwd_microstep: 3445.41 | bwd_inner_microstep: 3430.38 | bwd_allreduce_microstep: 14.97 | step_microstep: 7.79\n",
      "[2024-09-15 16:34:05,460] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3851.22 | bwd: 6918.42 | bwd_inner: 6903.34 | bwd_allreduce: 15.00 | step: 8.05\n",
      "{'loss': 0.1869, 'learning_rate': 8.594841983391196e-06, 'epoch': 2.1}\n",
      " 70%|███████   | 329/468 [58:56<24:46, 10.70s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:34:09,612] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.61 | bwd_microstep: 2627.93 | bwd_inner_microstep: 2627.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:34:16,119] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:34:16,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.17 | bwd_microstep: 4999.58 | bwd_inner_microstep: 2592.44 | bwd_allreduce_microstep: 2407.07 | step_microstep: 7.49\n",
      "[2024-09-15 16:34:16,120] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2964.75 | bwd: 7627.55 | bwd_inner: 5220.25 | bwd_allreduce: 2407.16 | step: 7.74\n",
      "{'loss': 0.2313, 'learning_rate': 8.481178502544684e-06, 'epoch': 2.11}\n",
      " 71%|███████   | 330/468 [59:07<24:34, 10.68s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:34:20,141] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1437.65 | bwd_microstep: 2552.45 | bwd_inner_microstep: 2552.18 | bwd_allreduce_microstep: 0.14 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:34:26,863] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.43 | optimizer_step: 0.40\n",
      "[2024-09-15 16:34:26,864] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.40 | bwd_microstep: 5220.41 | bwd_inner_microstep: 2590.15 | bwd_allreduce_microstep: 2630.20 | step_microstep: 7.54\n",
      "[2024-09-15 16:34:26,864] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2906.02 | bwd: 7772.90 | bwd_inner: 5142.34 | bwd_allreduce: 2630.36 | step: 7.79\n",
      "{'loss': 0.1843, 'learning_rate': 8.368069021550516e-06, 'epoch': 2.12}\n",
      " 71%|███████   | 331/468 [59:18<24:26, 10.70s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1900\n",
      "[2024-09-15 16:34:32,226] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.06 | bwd_microstep: 3426.68 | bwd_inner_microstep: 3426.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:34:37,621] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.30 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:34:37,621] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.23 | bwd_microstep: 3447.24 | bwd_inner_microstep: 3432.32 | bwd_allreduce_microstep: 14.87 | step_microstep: 7.62\n",
      "[2024-09-15 16:34:37,621] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3822.27 | bwd: 6873.93 | bwd_inner: 6858.98 | bwd_allreduce: 14.89 | step: 7.67\n",
      "{'loss': 0.2359, 'learning_rate': 8.255518980430115e-06, 'epoch': 2.12}\n",
      " 71%|███████   | 332/468 [59:29<24:17, 10.72s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:34:43,004] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.97 | bwd_microstep: 3434.79 | bwd_inner_microstep: 3434.76 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:34:48,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:34:48,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.03 | bwd_microstep: 3879.54 | bwd_inner_microstep: 2589.49 | bwd_allreduce_microstep: 1289.98 | step_microstep: 7.55\n",
      "[2024-09-15 16:34:48,389] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3385.96 | bwd: 7314.34 | bwd_inner: 6024.25 | bwd_allreduce: 1290.02 | step: 7.62\n",
      "{'loss': 0.1243, 'learning_rate': 8.143533792298545e-06, 'epoch': 2.13}\n",
      " 71%|███████   | 333/468 [59:39<24:09, 10.73s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:34:53,812] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.48 | bwd_microstep: 3457.41 | bwd_inner_microstep: 3457.39 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:34:59,244] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:34:59,245] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.74 | bwd_microstep: 3926.45 | bwd_inner_microstep: 2589.85 | bwd_allreduce_microstep: 1336.54 | step_microstep: 7.45\n",
      "[2024-09-15 16:34:59,245] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.19 | bwd: 7383.87 | bwd_inner: 6047.24 | bwd_allreduce: 1336.57 | step: 7.74\n",
      "{'loss': 0.1325, 'learning_rate': 8.032118843104164e-06, 'epoch': 2.13}\n",
      " 71%|███████▏  | 334/468 [59:50<24:03, 10.77s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1390\n",
      "[2024-09-15 16:35:03,325] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1460.93 | bwd_microstep: 2588.63 | bwd_inner_microstep: 2588.49 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 16:35:08,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.44 | optimizer_step: 0.40\n",
      "[2024-09-15 16:35:08,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.35 | bwd_microstep: 3870.36 | bwd_inner_microstep: 2552.32 | bwd_allreduce_microstep: 1317.98 | step_microstep: 7.48\n",
      "[2024-09-15 16:35:08,668] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2899.25 | bwd: 6459.03 | bwd_inner: 5140.81 | bwd_allreduce: 1318.09 | step: 7.74\n",
      "{'loss': 0.099, 'learning_rate': 7.921279491369575e-06, 'epoch': 2.14}\n",
      " 72%|███████▏  | 335/468 [1:00:00<22:58, 10.37s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:35:14,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.20 | bwd_microstep: 3435.38 | bwd_inner_microstep: 3435.35 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:35:19,305] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:35:19,306] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.36 | bwd_microstep: 3753.24 | bwd_inner_microstep: 2586.56 | bwd_allreduce_microstep: 1166.62 | step_microstep: 7.81\n",
      "[2024-09-15 16:35:19,306] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3382.54 | bwd: 7188.63 | bwd_inner: 6021.91 | bwd_allreduce: 1166.65 | step: 8.06\n",
      "{'loss': 0.2295, 'learning_rate': 7.811021067933919e-06, 'epoch': 2.15}\n",
      " 72%|███████▏  | 336/468 [1:00:10<22:59, 10.45s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1901\n",
      "[2024-09-15 16:35:24,715] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1923.76 | bwd_microstep: 3454.65 | bwd_inner_microstep: 3454.61 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:35:28,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:35:28,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.88 | bwd_microstep: 2604.14 | bwd_inner_microstep: 2589.00 | bwd_allreduce_microstep: 15.07 | step_microstep: 7.67\n",
      "[2024-09-15 16:35:28,822] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.61 | bwd: 6058.84 | bwd_inner: 6043.61 | bwd_allreduce: 15.10 | step: 7.91\n",
      "{'loss': 0.1494, 'learning_rate': 7.701348875696486e-06, 'epoch': 2.15}\n",
      " 72%|███████▏  | 337/468 [1:00:20<22:12, 10.17s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1390\n",
      "[2024-09-15 16:35:32,902] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.01 | bwd_microstep: 2587.76 | bwd_inner_microstep: 2587.73 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:35:38,317] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:35:38,318] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.44 | bwd_microstep: 3459.67 | bwd_inner_microstep: 3444.00 | bwd_allreduce_microstep: 15.60 | step_microstep: 7.88\n",
      "[2024-09-15 16:35:38,318] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3381.43 | bwd: 6047.47 | bwd_inner: 6031.72 | bwd_allreduce: 15.64 | step: 8.10\n",
      "{'loss': 0.1063, 'learning_rate': 7.59226818936166e-06, 'epoch': 2.16}\n",
      " 72%|███████▏  | 338/468 [1:00:29<21:35,  9.97s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:35:43,694] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.04 | bwd_microstep: 3426.54 | bwd_inner_microstep: 3426.51 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:35:49,183] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.38 | optimizer_step: 0.43\n",
      "[2024-09-15 16:35:49,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1951.06 | bwd_microstep: 3501.52 | bwd_inner_microstep: 3486.38 | bwd_allreduce_microstep: 15.10 | step_microstep: 8.11\n",
      "[2024-09-15 16:35:49,184] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3865.07 | bwd: 6928.07 | bwd_inner: 6912.89 | bwd_allreduce: 15.12 | step: 8.24\n",
      "{'loss': 0.1389, 'learning_rate': 7.483784255185249e-06, 'epoch': 2.17}\n",
      " 72%|███████▏  | 339/468 [1:00:40<22:00, 10.24s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1374\n",
      "[2024-09-15 16:35:53,282] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1473.84 | bwd_microstep: 2593.15 | bwd_inner_microstep: 2593.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1373\n",
      "[2024-09-15 16:35:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.39\n",
      "[2024-09-15 16:35:59,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.91 | bwd_microstep: 5076.75 | bwd_inner_microstep: 2597.50 | bwd_allreduce_microstep: 2479.18 | step_microstep: 7.45\n",
      "[2024-09-15 16:35:59,870] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2948.72 | bwd: 7669.94 | bwd_inner: 5190.59 | bwd_allreduce: 2479.22 | step: 7.70\n",
      "{'loss': 0.176, 'learning_rate': 7.375902290722146e-06, 'epoch': 2.17}\n",
      " 73%|███████▎  | 340/468 [1:00:51<22:07, 10.37s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1870\n",
      "[2024-09-15 16:36:05,167] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1881.34 | bwd_microstep: 3386.29 | bwd_inner_microstep: 3386.26 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:36:10,550] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.37 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:36:10,550] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.24 | bwd_microstep: 3910.17 | bwd_inner_microstep: 2553.18 | bwd_allreduce_microstep: 1356.92 | step_microstep: 7.69\n",
      "[2024-09-15 16:36:10,551] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3321.56 | bwd: 7296.47 | bwd_inner: 5939.44 | bwd_allreduce: 1356.96 | step: 7.93\n",
      "{'loss': 0.142, 'learning_rate': 7.268627484575406e-06, 'epoch': 2.18}\n",
      " 73%|███████▎  | 341/468 [1:01:01<22:08, 10.46s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1388\n",
      "[2024-09-15 16:36:14,629] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.44 | bwd_microstep: 2586.98 | bwd_inner_microstep: 2586.85 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:36:19,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:36:19,999] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.16 | bwd_microstep: 3839.03 | bwd_inner_microstep: 2626.77 | bwd_allreduce_microstep: 1212.20 | step_microstep: 7.50\n",
      "[2024-09-15 16:36:19,999] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2955.58 | bwd: 6426.04 | bwd_inner: 5213.62 | bwd_allreduce: 1212.30 | step: 7.75\n",
      "{'loss': 0.2029, 'learning_rate': 7.161964996146689e-06, 'epoch': 2.19}\n",
      " 73%|███████▎  | 342/468 [1:01:11<21:20, 10.16s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:36:25,373] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.41 | bwd_microstep: 3429.40 | bwd_inner_microstep: 3429.37 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:36:30,775] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.44 | optimizer_step: 0.44\n",
      "[2024-09-15 16:36:30,776] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.93 | bwd_microstep: 3451.04 | bwd_inner_microstep: 3435.95 | bwd_allreduce_microstep: 15.05 | step_microstep: 7.85\n",
      "[2024-09-15 16:36:30,776] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.31 | bwd: 6880.45 | bwd_inner: 6865.32 | bwd_allreduce: 15.07 | step: 8.07\n",
      "{'loss': 0.1416, 'learning_rate': 7.055919955388122e-06, 'epoch': 2.19}\n",
      " 73%|███████▎  | 343/468 [1:01:22<21:33, 10.34s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:36:36,159] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.07 | bwd_microstep: 3435.85 | bwd_inner_microstep: 3435.83 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:36:40,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:36:40,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.94 | bwd_microstep: 2605.07 | bwd_inner_microstep: 2590.67 | bwd_allreduce_microstep: 14.35 | step_microstep: 7.77\n",
      "[2024-09-15 16:36:40,269] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3385.98 | bwd: 6040.93 | bwd_inner: 6026.50 | bwd_allreduce: 14.37 | step: 8.01\n",
      "{'loss': 0.1515, 'learning_rate': 6.95049746255557e-06, 'epoch': 2.2}\n",
      " 74%|███████▎  | 344/468 [1:01:31<20:51, 10.09s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:36:45,653] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.47 | bwd_microstep: 3435.65 | bwd_inner_microstep: 3435.63 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:36:51,035] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.38 | optimizer_step: 0.40\n",
      "[2024-09-15 16:36:51,036] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.91 | bwd_microstep: 3441.38 | bwd_inner_microstep: 3426.40 | bwd_allreduce_microstep: 14.93 | step_microstep: 8.15\n",
      "[2024-09-15 16:36:51,036] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3823.36 | bwd: 6877.04 | bwd_inner: 6862.03 | bwd_allreduce: 14.95 | step: 8.41\n",
      "{'loss': 0.1573, 'learning_rate': 6.845702587963352e-06, 'epoch': 2.2}\n",
      " 74%|███████▎  | 345/468 [1:01:42<21:05, 10.29s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1388\n",
      "[2024-09-15 16:36:55,121] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.86 | bwd_microstep: 2590.22 | bwd_inner_microstep: 2590.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:37:01,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:37:01,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.37 | bwd_microstep: 4663.44 | bwd_inner_microstep: 3441.11 | bwd_allreduce_microstep: 1222.27 | step_microstep: 7.48\n",
      "[2024-09-15 16:37:01,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3384.20 | bwd: 7253.70 | bwd_inner: 6031.26 | bwd_allreduce: 1222.31 | step: 7.73\n",
      "{'loss': 0.2249, 'learning_rate': 6.741540371740347e-06, 'epoch': 2.21}\n",
      " 74%|███████▍  | 346/468 [1:01:53<21:10, 10.42s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:37:07,090] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.43 | bwd_microstep: 3419.86 | bwd_inner_microstep: 3419.84 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:37:12,385] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:37:12,386] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.76 | bwd_microstep: 3791.30 | bwd_inner_microstep: 2591.95 | bwd_allreduce_microstep: 1199.29 | step_microstep: 7.74\n",
      "[2024-09-15 16:37:12,386] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3370.17 | bwd: 7211.19 | bwd_inner: 6011.79 | bwd_allreduce: 1199.32 | step: 7.99\n",
      "{'loss': 0.2207, 'learning_rate': 6.6380158235876335e-06, 'epoch': 2.22}\n",
      " 74%|███████▍  | 347/468 [1:02:03<21:08, 10.49s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:37:16,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.46 | bwd_microstep: 2626.55 | bwd_inner_microstep: 2626.52 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:37:23,177] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:37:23,178] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.29 | bwd_microstep: 5135.34 | bwd_inner_microstep: 2590.35 | bwd_allreduce_microstep: 2544.93 | step_microstep: 7.48\n",
      "[2024-09-15 16:37:23,178] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.72 | bwd: 7761.90 | bwd_inner: 5216.87 | bwd_allreduce: 2544.96 | step: 7.71\n",
      "{'loss': 0.1194, 'learning_rate': 6.535133922537513e-06, 'epoch': 2.22}\n",
      " 74%|███████▍  | 348/468 [1:02:14<21:09, 10.58s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:37:28,549] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.14 | bwd_microstep: 3430.95 | bwd_inner_microstep: 3430.92 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:37:33,897] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.39 | optimizer_step: 0.39\n",
      "[2024-09-15 16:37:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.36 | bwd_microstep: 3846.70 | bwd_inner_microstep: 2587.97 | bwd_allreduce_microstep: 1258.67 | step_microstep: 7.48\n",
      "[2024-09-15 16:37:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3378.47 | bwd: 7277.66 | bwd_inner: 6018.89 | bwd_allreduce: 1258.70 | step: 7.66\n",
      "{'loss': 0.1655, 'learning_rate': 6.4328996167140786e-06, 'epoch': 2.23}\n",
      " 75%|███████▍  | 349/468 [1:02:25<21:03, 10.62s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:37:39,316] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1930.70 | bwd_microstep: 3456.30 | bwd_inner_microstep: 3456.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:37:44,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:37:44,616] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.88 | bwd_microstep: 3797.45 | bwd_inner_microstep: 2588.53 | bwd_allreduce_microstep: 1208.86 | step_microstep: 7.47\n",
      "[2024-09-15 16:37:44,616] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3398.54 | bwd: 7253.79 | bwd_inner: 6044.78 | bwd_allreduce: 1208.89 | step: 7.72\n",
      "{'loss': 0.1652, 'learning_rate': 6.331317823095184e-06, 'epoch': 2.24}\n",
      " 75%|███████▍  | 350/468 [1:02:36<20:56, 10.65s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1374\n",
      "[2024-09-15 16:37:48,704] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.70 | bwd_microstep: 2589.07 | bwd_inner_microstep: 2588.95 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.34\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:37:54,147] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.18 | optimizer_gradients: 0.39 | optimizer_step: 0.42\n",
      "[2024-09-15 16:37:54,147] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.53 | bwd_microstep: 3941.29 | bwd_inner_microstep: 2586.49 | bwd_allreduce_microstep: 1354.74 | step_microstep: 7.41\n",
      "[2024-09-15 16:37:54,147] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2935.20 | bwd: 6530.39 | bwd_inner: 5175.44 | bwd_allreduce: 1354.82 | step: 7.75\n",
      "{'loss': 0.2378, 'learning_rate': 6.230393427276e-06, 'epoch': 2.24}\n",
      " 75%|███████▌  | 351/468 [1:02:45<20:06, 10.31s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1390\n",
      "[2024-09-15 16:37:58,227] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.33 | bwd_microstep: 2588.43 | bwd_inner_microstep: 2588.36 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:38:03,670] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:38:03,671] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.74 | bwd_microstep: 3492.64 | bwd_inner_microstep: 3429.12 | bwd_allreduce_microstep: 63.47 | step_microstep: 7.62\n",
      "[2024-09-15 16:38:03,671] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3377.05 | bwd: 6081.10 | bwd_inner: 6017.48 | bwd_allreduce: 63.51 | step: 7.85\n",
      "{'loss': 0.229, 'learning_rate': 6.130131283234031e-06, 'epoch': 2.25}\n",
      " 75%|███████▌  | 352/468 [1:02:55<19:28, 10.08s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:38:09,039] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.67 | bwd_microstep: 3423.00 | bwd_inner_microstep: 3422.97 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:38:13,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.40 | optimizer_step: 0.41\n",
      "[2024-09-15 16:38:13,156] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.81 | bwd_microstep: 2612.71 | bwd_inner_microstep: 2591.08 | bwd_allreduce_microstep: 21.58 | step_microstep: 7.90\n",
      "[2024-09-15 16:38:13,156] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3384.46 | bwd: 6035.72 | bwd_inner: 6014.05 | bwd_allreduce: 21.61 | step: 8.14\n",
      "{'loss': 0.1397, 'learning_rate': 6.0305362130956504e-06, 'epoch': 2.26}\n",
      " 75%|███████▌  | 353/468 [1:03:04<18:58,  9.90s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:38:17,309] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.78 | bwd_microstep: 2629.02 | bwd_inner_microstep: 2628.95 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:38:23,938] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.32 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:38:23,939] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.27 | bwd_microstep: 4673.70 | bwd_inner_microstep: 3442.50 | bwd_allreduce_microstep: 1231.14 | step_microstep: 7.64\n",
      "[2024-09-15 16:38:23,939] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3413.03 | bwd: 7302.76 | bwd_inner: 6071.45 | bwd_allreduce: 1231.19 | step: 7.89\n",
      "{'loss': 0.1139, 'learning_rate': 5.931613006904196e-06, 'epoch': 2.26}\n",
      " 76%|███████▌  | 354/468 [1:03:15<19:18, 10.16s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:38:28,031] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.76 | bwd_microstep: 2591.72 | bwd_inner_microstep: 2591.66 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:38:33,359] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.45 | optimizer_step: 0.41\n",
      "[2024-09-15 16:38:33,360] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.71 | bwd_microstep: 3826.98 | bwd_inner_microstep: 2593.09 | bwd_allreduce_microstep: 1233.83 | step_microstep: 7.50\n",
      "[2024-09-15 16:38:33,360] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2938.44 | bwd: 6418.74 | bwd_inner: 5184.75 | bwd_allreduce: 1233.87 | step: 7.75\n",
      "{'loss': 0.1611, 'learning_rate': 5.8333664223895906e-06, 'epoch': 2.27}\n",
      " 76%|███████▌  | 355/468 [1:03:24<18:43,  9.94s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:38:37,505] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.21 | bwd_microstep: 2624.64 | bwd_inner_microstep: 2624.61 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:38:44,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.36 | optimizer_step: 0.39\n",
      "[2024-09-15 16:38:44,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.69 | bwd_microstep: 5084.88 | bwd_inner_microstep: 2593.08 | bwd_allreduce_microstep: 2491.74 | step_microstep: 7.35\n",
      "[2024-09-15 16:38:44,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.87 | bwd: 7709.53 | bwd_inner: 5217.69 | bwd_allreduce: 2491.77 | step: 7.60\n",
      "{'loss': 0.1784, 'learning_rate': 5.735801184739489e-06, 'epoch': 2.27}\n",
      " 76%|███████▌  | 356/468 [1:03:35<19:00, 10.18s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1387\n",
      "[2024-09-15 16:38:48,200] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.10 | bwd_microstep: 2600.57 | bwd_inner_microstep: 2600.54 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.27\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:38:54,718] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.31 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:38:54,719] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.57 | bwd_microstep: 4582.26 | bwd_inner_microstep: 3420.33 | bwd_allreduce_microstep: 1161.86 | step_microstep: 7.51\n",
      "[2024-09-15 16:38:54,719] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3374.64 | bwd: 7182.85 | bwd_inner: 6020.88 | bwd_allreduce: 1161.89 | step: 7.78\n",
      "{'loss': 0.2004, 'learning_rate': 5.638921986372064e-06, 'epoch': 2.28}\n",
      " 76%|███████▋  | 357/468 [1:03:46<19:04, 10.31s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1870\n",
      "[2024-09-15 16:39:00,062] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.23 | bwd_microstep: 3410.34 | bwd_inner_microstep: 3410.31 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.11\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:39:05,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:39:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1466.59 | bwd_microstep: 3794.28 | bwd_inner_microstep: 2588.35 | bwd_allreduce_microstep: 1205.87 | step_microstep: 7.48\n",
      "[2024-09-15 16:39:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3368.79 | bwd: 7204.63 | bwd_inner: 5998.66 | bwd_allreduce: 1205.90 | step: 7.62\n",
      "{'loss': 0.1553, 'learning_rate': 5.542733486710299e-06, 'epoch': 2.29}\n",
      " 76%|███████▋  | 358/468 [1:03:56<19:05, 10.41s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:39:10,723] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.09 | bwd_microstep: 3423.51 | bwd_inner_microstep: 3423.48 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:39:16,170] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:39:16,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1934.17 | bwd_microstep: 3477.10 | bwd_inner_microstep: 3461.07 | bwd_allreduce_microstep: 15.98 | step_microstep: 8.07\n",
      "[2024-09-15 16:39:16,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3844.24 | bwd: 6900.62 | bwd_inner: 6884.55 | bwd_allreduce: 16.00 | step: 8.31\n",
      "{'loss': 0.1787, 'learning_rate': 5.447240311957891e-06, 'epoch': 2.29}\n",
      " 77%|███████▋  | 359/468 [1:04:07<19:07, 10.53s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:39:21,551] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.28 | bwd_microstep: 3431.16 | bwd_inner_microstep: 3431.14 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:39:26,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.36 | optimizer_step: 0.42\n",
      "[2024-09-15 16:39:26,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.68 | bwd_microstep: 3445.48 | bwd_inner_microstep: 3429.84 | bwd_allreduce_microstep: 15.58 | step_microstep: 7.88\n",
      "[2024-09-15 16:39:26,948] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3832.93 | bwd: 6876.66 | bwd_inner: 6860.98 | bwd_allreduce: 15.61 | step: 8.13\n",
      "{'loss': 0.1856, 'learning_rate': 5.352447054876755e-06, 'epoch': 2.3}\n",
      " 77%|███████▋  | 360/468 [1:04:18<19:05, 10.60s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:39:31,096] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.73 | bwd_microstep: 2626.96 | bwd_inner_microstep: 2626.90 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1880\n",
      "[2024-09-15 16:39:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.45 | optimizer_gradients: 0.36 | optimizer_step: 0.37\n",
      "[2024-09-15 16:39:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.44 | bwd_microstep: 4628.76 | bwd_inner_microstep: 3462.23 | bwd_allreduce_microstep: 1166.47 | step_microstep: 7.93\n",
      "[2024-09-15 16:39:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3429.14 | bwd: 7255.76 | bwd_inner: 6089.13 | bwd_allreduce: 1166.50 | step: 8.16\n",
      "{'loss': 0.2069, 'learning_rate': 5.258358274566142e-06, 'epoch': 2.31}\n",
      " 77%|███████▋  | 361/468 [1:04:29<18:59, 10.65s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:39:41,788] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.42 | bwd_microstep: 2590.14 | bwd_inner_microstep: 2590.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:39:48,332] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.36 | optimizer_step: 0.38\n",
      "[2024-09-15 16:39:48,332] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.48 | bwd_microstep: 4608.62 | bwd_inner_microstep: 3410.97 | bwd_allreduce_microstep: 1197.59 | step_microstep: 7.34\n",
      "[2024-09-15 16:39:48,332] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3370.86 | bwd: 7198.81 | bwd_inner: 6001.04 | bwd_allreduce: 1197.64 | step: 7.59\n",
      "{'loss': 0.2023, 'learning_rate': 5.164978496243354e-06, 'epoch': 2.31}\n",
      " 77%|███████▋  | 362/468 [1:04:39<18:48, 10.64s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:39:53,753] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1931.41 | bwd_microstep: 3459.42 | bwd_inner_microstep: 3459.39 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:39:59,159] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:39:59,160] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.35 | bwd_microstep: 3451.30 | bwd_inner_microstep: 3436.34 | bwd_allreduce_microstep: 14.91 | step_microstep: 7.61\n",
      "[2024-09-15 16:39:59,160] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3850.73 | bwd: 6910.73 | bwd_inner: 6895.73 | bwd_allreduce: 14.93 | step: 7.82\n",
      "{'loss': 0.1453, 'learning_rate': 5.072312211026125e-06, 'epoch': 2.32}\n",
      " 78%|███████▊  | 363/468 [1:04:50<18:43, 10.70s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:40:03,311] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.51 | bwd_microstep: 2627.24 | bwd_inner_microstep: 2627.14 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:40:08,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:40:08,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.64 | bwd_microstep: 3767.44 | bwd_inner_microstep: 2593.08 | bwd_allreduce_microstep: 1174.31 | step_microstep: 7.45\n",
      "[2024-09-15 16:40:08,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2964.12 | bwd: 6394.73 | bwd_inner: 5220.21 | bwd_allreduce: 1174.38 | step: 7.71\n",
      "{'loss': 0.1377, 'learning_rate': 4.980363875716592e-06, 'epoch': 2.33}\n",
      " 78%|███████▊  | 364/468 [1:04:59<17:52, 10.32s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1877\n",
      "[2024-09-15 16:40:13,909] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1888.39 | bwd_microstep: 3404.61 | bwd_inner_microstep: 3404.52 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:40:19,329] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:40:19,329] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.99 | bwd_microstep: 3465.37 | bwd_inner_microstep: 3438.17 | bwd_allreduce_microstep: 27.15 | step_microstep: 7.69\n",
      "[2024-09-15 16:40:19,329] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3808.34 | bwd: 6870.02 | bwd_inner: 6842.68 | bwd_allreduce: 27.21 | step: 7.96\n",
      "{'loss': 0.1887, 'learning_rate': 4.889137912586972e-06, 'epoch': 2.33}\n",
      " 78%|███████▊  | 365/468 [1:05:10<17:55, 10.45s/it]dynamic ViT batch size: 34, images per sample: 4.25, dynamic token length: 1870\n",
      "[2024-09-15 16:40:24,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1855.53 | bwd_microstep: 3371.39 | bwd_inner_microstep: 3371.24 | bwd_allreduce_microstep: 0.07 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:40:30,054] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:40:30,055] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1456.00 | bwd_microstep: 3978.00 | bwd_inner_microstep: 2572.46 | bwd_allreduce_microstep: 1405.46 | step_microstep: 7.53\n",
      "[2024-09-15 16:40:30,055] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3311.50 | bwd: 7349.43 | bwd_inner: 5943.71 | bwd_allreduce: 1405.58 | step: 7.78\n",
      "{'loss': 0.0932, 'learning_rate': 4.7986387091668365e-06, 'epoch': 2.34}\n",
      " 78%|███████▊  | 366/468 [1:05:21<17:53, 10.53s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:40:34,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.45 | bwd_microstep: 2627.64 | bwd_inner_microstep: 2627.51 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:40:40,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:40:40,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.96 | bwd_microstep: 4565.83 | bwd_inner_microstep: 3439.38 | bwd_allreduce_microstep: 1126.38 | step_microstep: 7.43\n",
      "[2024-09-15 16:40:40,724] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3410.37 | bwd: 7193.51 | bwd_inner: 6066.89 | bwd_allreduce: 1126.48 | step: 7.67\n",
      "{'loss': 0.1506, 'learning_rate': 4.708870618032133e-06, 'epoch': 2.35}\n",
      " 78%|███████▊  | 367/468 [1:05:32<17:47, 10.57s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:40:46,105] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.88 | bwd_microstep: 3434.03 | bwd_inner_microstep: 3434.00 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:40:51,515] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.62 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 16:40:51,515] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.84 | bwd_microstep: 3456.55 | bwd_inner_microstep: 3441.49 | bwd_allreduce_microstep: 15.02 | step_microstep: 8.25\n",
      "[2024-09-15 16:40:51,515] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.69 | bwd: 6890.59 | bwd_inner: 6875.49 | bwd_allreduce: 15.04 | step: 8.48\n",
      "{'loss': 0.1293, 'learning_rate': 4.619837956595825e-06, 'epoch': 2.35}\n",
      " 79%|███████▊  | 368/468 [1:05:42<17:43, 10.64s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:40:56,903] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.98 | bwd_microstep: 3437.30 | bwd_inner_microstep: 3437.28 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.17\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:41:02,254] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.39 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:41:02,255] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1889.14 | bwd_microstep: 3424.04 | bwd_inner_microstep: 3408.87 | bwd_allreduce_microstep: 15.11 | step_microstep: 11.36\n",
      "[2024-09-15 16:41:02,255] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3809.09 | bwd: 6861.36 | bwd_inner: 6846.15 | bwd_allreduce: 15.14 | step: 11.55\n",
      "{'loss': 0.1505, 'learning_rate': 4.531545006900244e-06, 'epoch': 2.36}\n",
      " 79%|███████▉  | 369/468 [1:05:53<17:36, 10.67s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:41:07,687] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.30 | bwd_microstep: 3464.38 | bwd_inner_microstep: 3464.35 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:41:12,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:41:12,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.74 | bwd_microstep: 3794.39 | bwd_inner_microstep: 2594.10 | bwd_allreduce_microstep: 1200.22 | step_microstep: 7.33\n",
      "[2024-09-15 16:41:12,985] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3407.02 | bwd: 7258.77 | bwd_inner: 6058.45 | bwd_allreduce: 1200.25 | step: 7.43\n",
      "{'loss': 0.1176, 'learning_rate': 4.443996015411151e-06, 'epoch': 2.36}\n",
      " 79%|███████▉  | 370/468 [1:06:04<17:27, 10.69s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1901\n",
      "[2024-09-15 16:41:18,424] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1942.39 | bwd_microstep: 3465.91 | bwd_inner_microstep: 3465.88 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:41:23,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:41:23,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.23 | bwd_microstep: 3455.25 | bwd_inner_microstep: 3439.98 | bwd_allreduce_microstep: 15.22 | step_microstep: 8.20\n",
      "[2024-09-15 16:41:23,837] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3862.59 | bwd: 6921.17 | bwd_inner: 6905.87 | bwd_allreduce: 15.24 | step: 8.39\n",
      "{'loss': 0.2187, 'learning_rate': 4.357195192813504e-06, 'epoch': 2.37}\n",
      " 79%|███████▉  | 371/468 [1:06:15<17:21, 10.74s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:41:27,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.27 | bwd_microstep: 2629.80 | bwd_inner_microstep: 2629.62 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:41:33,406] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.38 | optimizer_step: 0.42\n",
      "[2024-09-15 16:41:33,407] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.80 | bwd_microstep: 3474.49 | bwd_inner_microstep: 3433.71 | bwd_allreduce_microstep: 40.73 | step_microstep: 7.61\n",
      "[2024-09-15 16:41:33,407] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3400.05 | bwd: 6104.33 | bwd_inner: 6063.34 | bwd_allreduce: 40.82 | step: 7.87\n",
      "{'loss': 0.1538, 'learning_rate': 4.271146713808927e-06, 'epoch': 2.38}\n",
      " 79%|███████▉  | 372/468 [1:06:24<16:37, 10.39s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:41:37,565] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.89 | bwd_microstep: 2631.95 | bwd_inner_microstep: 2631.83 | bwd_allreduce_microstep: 0.04 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1878\n",
      "[2024-09-15 16:41:42,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.32 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 16:41:42,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1892.44 | bwd_microstep: 3421.97 | bwd_inner_microstep: 3408.15 | bwd_allreduce_microstep: 13.77 | step_microstep: 7.67\n",
      "[2024-09-15 16:41:42,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3388.30 | bwd: 6053.96 | bwd_inner: 6039.99 | bwd_allreduce: 13.85 | step: 7.92\n",
      "{'loss': 0.2165, 'learning_rate': 4.185854716914952e-06, 'epoch': 2.38}\n",
      " 80%|███████▉  | 373/468 [1:06:34<16:01, 10.12s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1902\n",
      "[2024-09-15 16:41:48,360] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1945.27 | bwd_microstep: 3467.13 | bwd_inner_microstep: 3467.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.33\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1369\n",
      "[2024-09-15 16:41:53,665] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:41:53,665] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.08 | bwd_microstep: 3814.07 | bwd_inner_microstep: 2575.31 | bwd_allreduce_microstep: 1238.70 | step_microstep: 7.70\n",
      "[2024-09-15 16:41:53,666] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3404.32 | bwd: 7281.21 | bwd_inner: 6042.41 | bwd_allreduce: 1238.73 | step: 8.03\n",
      "{'loss': 0.1662, 'learning_rate': 4.1013233042659606e-06, 'epoch': 2.39}\n",
      " 80%|███████▉  | 374/468 [1:06:45<16:09, 10.31s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:41:59,057] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.50 | bwd_microstep: 3439.76 | bwd_inner_microstep: 3439.68 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1876\n",
      "[2024-09-15 16:42:04,410] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.35 | optimizer_step: 0.39\n",
      "[2024-09-15 16:42:04,411] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1895.03 | bwd_microstep: 3424.18 | bwd_inner_microstep: 3409.16 | bwd_allreduce_microstep: 14.98 | step_microstep: 8.17\n",
      "[2024-09-15 16:42:04,411] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3815.51 | bwd: 6863.97 | bwd_inner: 6848.83 | bwd_allreduce: 15.02 | step: 8.42\n",
      "{'loss': 0.143, 'learning_rate': 4.017556541415888e-06, 'epoch': 2.4}\n",
      " 80%|████████  | 375/468 [1:06:55<16:11, 10.44s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:42:08,570] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1496.60 | bwd_microstep: 2632.19 | bwd_inner_microstep: 2632.03 | bwd_allreduce_microstep: 0.08 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:42:15,133] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:42:15,134] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.58 | bwd_microstep: 4608.11 | bwd_inner_microstep: 3443.29 | bwd_allreduce_microstep: 1164.76 | step_microstep: 7.48\n",
      "[2024-09-15 16:42:15,134] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3416.15 | bwd: 7240.34 | bwd_inner: 6075.32 | bwd_allreduce: 1164.89 | step: 7.74\n",
      "{'loss': 0.1883, 'learning_rate': 3.9345584571427055e-06, 'epoch': 2.4}\n",
      " 80%|████████  | 376/468 [1:07:06<16:08, 10.53s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:42:19,226] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.75 | bwd_microstep: 2592.15 | bwd_inner_microstep: 2592.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:42:24,590] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:42:24,590] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.59 | bwd_microstep: 3859.26 | bwd_inner_microstep: 2594.41 | bwd_allreduce_microstep: 1264.80 | step_microstep: 7.51\n",
      "[2024-09-15 16:42:24,591] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2938.31 | bwd: 6451.44 | bwd_inner: 5186.48 | bwd_allreduce: 1264.84 | step: 7.76\n",
      "{'loss': 0.1624, 'learning_rate': 3.852333043254639e-06, 'epoch': 2.41}\n",
      " 81%|████████  | 377/468 [1:07:15<15:28, 10.21s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:42:28,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.89 | bwd_microstep: 2625.76 | bwd_inner_microstep: 2625.73 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:42:34,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:42:34,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.59 | bwd_microstep: 3454.08 | bwd_inner_microstep: 3438.21 | bwd_allreduce_microstep: 15.82 | step_microstep: 7.73\n",
      "[2024-09-15 16:42:34,143] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3411.46 | bwd: 6079.85 | bwd_inner: 6063.94 | bwd_allreduce: 15.85 | step: 7.79\n",
      "{'loss': 0.1824, 'learning_rate': 3.7708842543981928e-06, 'epoch': 2.42}\n",
      " 81%|████████  | 378/468 [1:07:25<15:00, 10.01s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:42:38,296] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.69 | bwd_microstep: 2627.58 | bwd_inner_microstep: 2627.47 | bwd_allreduce_microstep: 0.04 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:42:43,714] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.67 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:42:43,715] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.70 | bwd_microstep: 3463.30 | bwd_inner_microstep: 3447.99 | bwd_allreduce_microstep: 15.26 | step_microstep: 7.79\n",
      "[2024-09-15 16:42:43,715] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3415.36 | bwd: 6090.92 | bwd_inner: 6075.45 | bwd_allreduce: 15.34 | step: 8.03\n",
      "{'loss': 0.1933, 'learning_rate': 3.690216007867944e-06, 'epoch': 2.42}\n",
      " 81%|████████  | 379/468 [1:07:35<14:39,  9.88s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:42:47,869] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.19 | bwd_microstep: 2628.85 | bwd_inner_microstep: 2628.82 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:42:53,357] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.34 | optimizer_step: 0.37\n",
      "[2024-09-15 16:42:53,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1950.14 | bwd_microstep: 3504.02 | bwd_inner_microstep: 3488.45 | bwd_allreduce_microstep: 15.52 | step_microstep: 7.67\n",
      "[2024-09-15 16:42:53,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3444.31 | bwd: 6132.89 | bwd_inner: 6117.28 | bwd_allreduce: 15.54 | step: 7.90\n",
      "{'loss': 0.1557, 'learning_rate': 3.6103321834181437e-06, 'epoch': 2.43}\n",
      " 81%|████████  | 380/468 [1:07:44<14:23,  9.81s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1369\n",
      "[2024-09-15 16:42:57,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.96 | bwd_microstep: 2583.74 | bwd_inner_microstep: 2583.71 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:43:02,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.62 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:43:02,841] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.82 | bwd_microstep: 3453.62 | bwd_inner_microstep: 3438.61 | bwd_allreduce_microstep: 14.96 | step_microstep: 7.61\n",
      "[2024-09-15 16:43:02,841] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3380.76 | bwd: 6037.37 | bwd_inner: 6022.32 | bwd_allreduce: 14.99 | step: 7.84\n",
      "{'loss': 0.143, 'learning_rate': 3.5312366230761154e-06, 'epoch': 2.43}\n",
      " 81%|████████▏ | 381/468 [1:07:54<14:04,  9.71s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:43:06,999] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.56 | bwd_microstep: 2632.87 | bwd_inner_microstep: 2632.84 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 48, images per sample: 6.0, dynamic token length: 1901\n",
      "[2024-09-15 16:43:12,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.58 | optimizer_gradients: 0.35 | optimizer_step: 0.41\n",
      "[2024-09-15 16:43:12,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1993.16 | bwd_microstep: 3555.40 | bwd_inner_microstep: 3540.40 | bwd_allreduce_microstep: 14.95 | step_microstep: 7.84\n",
      "[2024-09-15 16:43:12,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3487.70 | bwd: 6188.28 | bwd_inner: 6173.25 | bwd_allreduce: 14.97 | step: 8.07\n",
      "{'loss': 0.1588, 'learning_rate': 3.452933130957481e-06, 'epoch': 2.44}\n",
      " 82%|████████▏ | 382/468 [1:08:03<13:55,  9.72s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:43:17,979] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.90 | bwd_microstep: 3443.21 | bwd_inner_microstep: 3443.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:43:23,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:43:23,358] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.22 | bwd_microstep: 3870.21 | bwd_inner_microstep: 2596.86 | bwd_allreduce_microstep: 1273.28 | step_microstep: 7.54\n",
      "[2024-09-15 16:43:23,359] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3394.10 | bwd: 7313.43 | bwd_inner: 6040.05 | bwd_allreduce: 1273.31 | step: 7.79\n",
      "{'loss': 0.1964, 'learning_rate': 3.375425473083185e-06, 'epoch': 2.45}\n",
      " 82%|████████▏ | 383/468 [1:08:14<14:13, 10.04s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 16:43:27,514] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.38 | bwd_microstep: 2630.47 | bwd_inner_microstep: 2630.44 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:43:32,830] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.23 | optimizer_gradients: 0.38 | optimizer_step: 0.40\n",
      "[2024-09-15 16:43:32,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1473.68 | bwd_microstep: 3807.60 | bwd_inner_microstep: 2596.95 | bwd_allreduce_microstep: 1210.60 | step_microstep: 7.25\n",
      "[2024-09-15 16:43:32,831] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2968.03 | bwd: 6438.08 | bwd_inner: 5227.39 | bwd_allreduce: 1210.62 | step: 7.48\n",
      "{'loss': 0.1688, 'learning_rate': 3.2987173771983816e-06, 'epoch': 2.45}\n",
      " 82%|████████▏ | 384/468 [1:08:24<13:48,  9.87s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:43:38,229] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.75 | bwd_microstep: 3446.84 | bwd_inner_microstep: 3446.81 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:43:43,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:43:43,638] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.19 | bwd_microstep: 3451.13 | bwd_inner_microstep: 3435.91 | bwd_allreduce_microstep: 15.17 | step_microstep: 8.15\n",
      "[2024-09-15 16:43:43,638] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3841.91 | bwd: 6897.98 | bwd_inner: 6882.72 | bwd_allreduce: 15.19 | step: 8.39\n",
      "{'loss': 0.1837, 'learning_rate': 3.2228125325931514e-06, 'epoch': 2.46}\n",
      " 82%|████████▏ | 385/468 [1:08:35<14:02, 10.15s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:43:49,013] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.53 | bwd_microstep: 3428.44 | bwd_inner_microstep: 3428.41 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:43:54,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:43:54,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1902.27 | bwd_microstep: 3436.67 | bwd_inner_microstep: 3424.11 | bwd_allreduce_microstep: 12.51 | step_microstep: 7.39\n",
      "[2024-09-15 16:43:54,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3817.77 | bwd: 6865.15 | bwd_inner: 6852.53 | bwd_allreduce: 12.53 | step: 7.64\n",
      "{'loss': 0.1463, 'learning_rate': 3.1477145899250326e-06, 'epoch': 2.47}\n",
      " 82%|████████▏ | 386/468 [1:08:45<14:07, 10.33s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:43:58,549] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1498.56 | bwd_microstep: 2632.33 | bwd_inner_microstep: 2632.14 | bwd_allreduce_microstep: 0.10 | step_microstep: 0.26\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:44:05,207] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.25 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:05,208] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1458.35 | bwd_microstep: 5164.17 | bwd_inner_microstep: 2577.02 | bwd_allreduce_microstep: 2587.09 | step_microstep: 7.52\n",
      "[2024-09-15 16:44:05,208] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2956.89 | bwd: 7796.54 | bwd_inner: 5209.16 | bwd_allreduce: 2587.24 | step: 7.78\n",
      "{'loss': 0.2133, 'learning_rate': 3.073427161043492e-06, 'epoch': 2.47}\n",
      " 83%|████████▎ | 387/468 [1:08:56<14:08, 10.48s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:44:09,357] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.46 | bwd_microstep: 2626.25 | bwd_inner_microstep: 2626.22 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:44:14,765] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:14,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.31 | bwd_microstep: 3455.06 | bwd_inner_microstep: 3440.01 | bwd_allreduce_microstep: 15.00 | step_microstep: 7.81\n",
      "[2024-09-15 16:44:14,766] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3409.75 | bwd: 6081.31 | bwd_inner: 6066.23 | bwd_allreduce: 15.02 | step: 8.04\n",
      "{'loss': 0.1345, 'learning_rate': 2.9999538188161705e-06, 'epoch': 2.48}\n",
      " 83%|████████▎ | 388/468 [1:09:06<13:36, 10.20s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:44:18,919] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.29 | bwd_microstep: 2629.55 | bwd_inner_microstep: 2629.47 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:44:25,528] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:25,528] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.66 | bwd_microstep: 4652.83 | bwd_inner_microstep: 3442.99 | bwd_allreduce_microstep: 1209.77 | step_microstep: 7.49\n",
      "[2024-09-15 16:44:25,529] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3414.93 | bwd: 7282.42 | bwd_inner: 6072.47 | bwd_allreduce: 1209.82 | step: 7.74\n",
      "{'loss': 0.2226, 'learning_rate': 2.927298096957063e-06, 'epoch': 2.49}\n",
      " 83%|████████▎ | 389/468 [1:09:16<13:39, 10.37s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1905\n",
      "[2024-09-15 16:44:31,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1968.89 | bwd_microstep: 3520.78 | bwd_inner_microstep: 3520.75 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 16:44:36,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:36,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1442.78 | bwd_microstep: 3698.57 | bwd_inner_microstep: 2558.77 | bwd_allreduce_microstep: 1139.73 | step_microstep: 7.51\n",
      "[2024-09-15 16:44:36,225] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3411.64 | bwd: 7219.36 | bwd_inner: 6079.53 | bwd_allreduce: 1139.76 | step: 7.58\n",
      "{'loss': 0.1664, 'learning_rate': 2.8554634898565668e-06, 'epoch': 2.49}\n",
      " 83%|████████▎ | 390/468 [1:09:27<13:36, 10.47s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:44:40,373] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.10 | bwd_microstep: 2625.86 | bwd_inner_microstep: 2625.80 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:44:45,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:45,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.47 | bwd_microstep: 3476.78 | bwd_inner_microstep: 3461.67 | bwd_allreduce_microstep: 15.06 | step_microstep: 7.89\n",
      "[2024-09-15 16:44:45,824] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3429.54 | bwd: 6102.68 | bwd_inner: 6087.47 | bwd_allreduce: 15.09 | step: 8.13\n",
      "{'loss': 0.1388, 'learning_rate': 2.784453452413405e-06, 'epoch': 2.5}\n",
      " 84%|████████▎ | 391/468 [1:09:37<13:05, 10.21s/it]dynamic ViT batch size: 43, images per sample: 5.375, dynamic token length: 1878\n",
      "[2024-09-15 16:44:51,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1928.31 | bwd_microstep: 3451.60 | bwd_inner_microstep: 3451.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1880\n",
      "[2024-09-15 16:44:56,613] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.35 | optimizer_step: 0.40\n",
      "[2024-09-15 16:44:56,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.35 | bwd_microstep: 3438.69 | bwd_inner_microstep: 3423.73 | bwd_allreduce_microstep: 14.92 | step_microstep: 8.54\n",
      "[2024-09-15 16:44:56,614] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3832.63 | bwd: 6890.31 | bwd_inner: 6875.31 | bwd_allreduce: 14.94 | step: 8.78\n",
      "{'loss': 0.2065, 'learning_rate': 2.714271399868473e-06, 'epoch': 2.5}\n",
      " 84%|████████▍ | 392/468 [1:09:48<13:09, 10.38s/it]dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:45:02,083] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1952.48 | bwd_microstep: 3486.77 | bwd_inner_microstep: 3486.74 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.16\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:45:07,485] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.70 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:45:07,486] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.57 | bwd_microstep: 3448.34 | bwd_inner_microstep: 3433.45 | bwd_allreduce_microstep: 14.81 | step_microstep: 8.25\n",
      "[2024-09-15 16:45:07,486] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3871.03 | bwd: 6935.12 | bwd_inner: 6920.19 | bwd_allreduce: 14.85 | step: 8.44\n",
      "{'loss': 0.1353, 'learning_rate': 2.6449207076405857e-06, 'epoch': 2.51}\n",
      " 84%|████████▍ | 393/468 [1:09:58<13:09, 10.53s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:45:12,839] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1903.98 | bwd_microstep: 3417.56 | bwd_inner_microstep: 3417.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:45:18,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.24 | optimizer_gradients: 0.47 | optimizer_step: 0.41\n",
      "[2024-09-15 16:45:18,230] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.62 | bwd_microstep: 3449.65 | bwd_inner_microstep: 3436.72 | bwd_allreduce_microstep: 12.88 | step_microstep: 10.02\n",
      "[2024-09-15 16:45:18,231] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3809.57 | bwd: 6867.21 | bwd_inner: 6854.24 | bwd_allreduce: 12.90 | step: 10.09\n",
      "{'loss': 0.1601, 'learning_rate': 2.57640471116412e-06, 'epoch': 2.52}\n",
      " 84%|████████▍ | 394/468 [1:10:09<13:04, 10.60s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:45:23,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.75 | bwd_microstep: 3451.42 | bwd_inner_microstep: 3451.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:45:29,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:45:29,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.27 | bwd_microstep: 3459.02 | bwd_inner_microstep: 3444.43 | bwd_allreduce_microstep: 14.54 | step_microstep: 8.36\n",
      "[2024-09-15 16:45:29,052] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3839.99 | bwd: 6910.45 | bwd_inner: 6895.83 | bwd_allreduce: 14.56 | step: 8.57\n",
      "{'loss': 0.2478, 'learning_rate': 2.508726705728617e-06, 'epoch': 2.52}\n",
      " 84%|████████▍ | 395/468 [1:10:20<12:58, 10.66s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:45:33,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.15 | bwd_microstep: 2638.98 | bwd_inner_microstep: 2638.95 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:45:38,631] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.09 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:45:38,632] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.59 | bwd_microstep: 3458.62 | bwd_inner_microstep: 3445.35 | bwd_allreduce_microstep: 13.22 | step_microstep: 9.04\n",
      "[2024-09-15 16:45:38,632] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3414.72 | bwd: 6097.61 | bwd_inner: 6084.30 | bwd_allreduce: 13.24 | step: 9.21\n",
      "{'loss': 0.1515, 'learning_rate': 2.441889946320266e-06, 'epoch': 2.53}\n",
      " 85%|████████▍ | 396/468 [1:10:30<12:24, 10.34s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:45:42,795] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.67 | bwd_microstep: 2636.36 | bwd_inner_microstep: 2636.34 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:45:48,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.72 | optimizer_gradients: 0.36 | optimizer_step: 0.37\n",
      "[2024-09-15 16:45:48,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.66 | bwd_microstep: 3762.03 | bwd_inner_microstep: 2597.70 | bwd_allreduce_microstep: 1164.27 | step_microstep: 7.52\n",
      "[2024-09-15 16:45:48,061] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2967.30 | bwd: 6398.41 | bwd_inner: 5234.04 | bwd_allreduce: 1164.30 | step: 7.57\n",
      "{'loss': 0.11, 'learning_rate': 2.3758976474653904e-06, 'epoch': 2.54}\n",
      " 85%|████████▍ | 397/468 [1:10:39<11:54, 10.06s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:45:52,220] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.61 | bwd_microstep: 2632.80 | bwd_inner_microstep: 2632.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:45:57,538] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.26 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:45:57,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.99 | bwd_microstep: 3816.40 | bwd_inner_microstep: 2602.68 | bwd_allreduce_microstep: 1213.65 | step_microstep: 7.48\n",
      "[2024-09-15 16:45:57,539] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2966.58 | bwd: 6449.21 | bwd_inner: 5235.46 | bwd_allreduce: 1213.68 | step: 7.53\n",
      "{'loss': 0.179, 'learning_rate': 2.310752983075819e-06, 'epoch': 2.54}\n",
      " 85%|████████▌ | 398/468 [1:10:48<11:32,  9.89s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:46:02,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.91 | bwd_microstep: 3429.15 | bwd_inner_microstep: 3429.12 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:46:08,275] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.44\n",
      "[2024-09-15 16:46:08,275] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.65 | bwd_microstep: 3856.48 | bwd_inner_microstep: 2594.67 | bwd_allreduce_microstep: 1261.75 | step_microstep: 7.72\n",
      "[2024-09-15 16:46:08,275] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3389.53 | bwd: 7285.64 | bwd_inner: 6023.79 | bwd_allreduce: 1261.78 | step: 7.77\n",
      "{'loss': 0.1746, 'learning_rate': 2.2464590862962443e-06, 'epoch': 2.55}\n",
      " 85%|████████▌ | 399/468 [1:10:59<11:39, 10.14s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1390\n",
      "[2024-09-15 16:46:12,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1495.03 | bwd_microstep: 2634.76 | bwd_inner_microstep: 2634.65 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:46:19,047] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:46:19,048] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.23 | bwd_microstep: 4673.80 | bwd_inner_microstep: 3427.19 | bwd_allreduce_microstep: 1246.54 | step_microstep: 7.53\n",
      "[2024-09-15 16:46:19,048] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3399.24 | bwd: 7308.60 | bwd_inner: 6061.84 | bwd_allreduce: 1246.63 | step: 7.78\n",
      "{'loss': 0.1632, 'learning_rate': 2.1830190493535385e-06, 'epoch': 2.56}\n",
      " 85%|████████▌ | 400/468 [1:11:10<11:42, 10.33s/it][INFO|trainer.py:2936] 2024-09-15 16:46:26,282 >> Saving model checkpoint to work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400\n",
      "[INFO|configuration_utils.py:473] 2024-09-15 16:46:26,284 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/config.json\n",
      "[INFO|configuration_utils.py:594] 2024-09-15 16:46:26,284 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/generation_config.json\n",
      "[INFO|modeling_utils.py:2501] 2024-09-15 16:46:47,703 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2433] 2024-09-15 16:46:47,705 >> tokenizer config file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2442] 2024-09-15 16:46:47,705 >> Special tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2493] 2024-09-15 16:46:47,705 >> added tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/added_tokens.json\n",
      "[2024-09-15 16:46:48,662] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step400 is about to be saved!\n",
      "[2024-09-15 16:46:48,690] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt\n",
      "[2024-09-15 16:46:48,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt...\n",
      "[2024-09-15 16:47:06,164] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt.\n",
      "[2024-09-15 16:47:06,167] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2024-09-15 16:47:06,326] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2024-09-15 16:47:06,326] [INFO] [engine.py:3488:_save_zero_checkpoint] zero checkpoint saved work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tmp-checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2024-09-15 16:47:06,326] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step400 is ready now!\n",
      "[INFO|trainer.py:3028] 2024-09-15 16:47:06,338 >> Deleting older checkpoint [work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/checkpoint-200] due to args.save_total_limit\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:47:13,743] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1870.20 | bwd_microstep: 3387.36 | bwd_inner_microstep: 3387.31 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:47:17,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:47:17,817] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1452.23 | bwd_microstep: 2585.92 | bwd_inner_microstep: 2562.88 | bwd_allreduce_microstep: 23.00 | step_microstep: 8.05\n",
      "[2024-09-15 16:47:17,817] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3322.40 | bwd: 5973.32 | bwd_inner: 5950.18 | bwd_allreduce: 23.02 | step: 8.30\n",
      "{'loss': 0.2318, 'learning_rate': 2.1204359234080196e-06, 'epoch': 2.56}\n",
      " 86%|████████▌ | 401/468 [1:12:09<27:45, 24.86s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:47:23,102] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1878.75 | bwd_microstep: 3375.62 | bwd_inner_microstep: 3375.60 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:47:28,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:47:28,368] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1455.01 | bwd_microstep: 3775.43 | bwd_inner_microstep: 2566.75 | bwd_allreduce_microstep: 1208.63 | step_microstep: 7.84\n",
      "[2024-09-15 16:47:28,369] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3333.73 | bwd: 7151.07 | bwd_inner: 5942.34 | bwd_allreduce: 1208.66 | step: 8.09\n",
      "{'loss': 0.2058, 'learning_rate': 2.058712718406719e-06, 'epoch': 2.57}\n",
      " 86%|████████▌ | 402/468 [1:12:19<22:37, 20.57s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:47:33,743] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.32 | bwd_microstep: 3425.20 | bwd_inner_microstep: 3425.17 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:47:39,148] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.36 | optimizer_gradients: 0.36 | optimizer_step: 0.40\n",
      "[2024-09-15 16:47:39,149] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1921.05 | bwd_microstep: 3447.91 | bwd_inner_microstep: 3433.17 | bwd_allreduce_microstep: 14.69 | step_microstep: 8.50\n",
      "[2024-09-15 16:47:39,149] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3839.32 | bwd: 6873.11 | bwd_inner: 6858.34 | bwd_allreduce: 14.71 | step: 8.75\n",
      "{'loss': 0.1229, 'learning_rate': 1.9978524029386026e-06, 'epoch': 2.58}\n",
      " 86%|████████▌ | 403/468 [1:12:30<19:06, 17.63s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:47:43,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1483.12 | bwd_microstep: 2608.19 | bwd_inner_microstep: 2608.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:47:49,838] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:47:49,838] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.29 | bwd_microstep: 4624.91 | bwd_inner_microstep: 3416.40 | bwd_allreduce_microstep: 1208.45 | step_microstep: 7.90\n",
      "[2024-09-15 16:47:49,839] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.38 | bwd: 7233.13 | bwd_inner: 6024.56 | bwd_allreduce: 1208.48 | step: 8.15\n",
      "{'loss': 0.1819, 'learning_rate': 1.937857904091818e-06, 'epoch': 2.58}\n",
      " 86%|████████▋ | 404/468 [1:12:41<16:35, 15.55s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:47:53,964] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1483.96 | bwd_microstep: 2610.58 | bwd_inner_microstep: 2610.52 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.30\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1881\n",
      "[2024-09-15 16:48:00,523] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.46 | optimizer_gradients: 0.42 | optimizer_step: 0.40\n",
      "[2024-09-15 16:48:00,524] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.45 | bwd_microstep: 4609.68 | bwd_inner_microstep: 3420.48 | bwd_allreduce_microstep: 1189.13 | step_microstep: 11.76\n",
      "[2024-09-15 16:48:00,524] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3396.39 | bwd: 7220.29 | bwd_inner: 6031.00 | bwd_allreduce: 1189.17 | step: 12.01\n",
      "{'loss': 0.1619, 'learning_rate': 1.8787321073128817e-06, 'epoch': 2.59}\n",
      " 87%|████████▋ | 405/468 [1:12:51<14:47, 14.09s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:48:04,562] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1449.55 | bwd_microstep: 2557.73 | bwd_inner_microstep: 2557.62 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:48:11,181] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.35 | optimizer_gradients: 0.39 | optimizer_step: 0.39\n",
      "[2024-09-15 16:48:11,182] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.16 | bwd_microstep: 4673.80 | bwd_inner_microstep: 3425.76 | bwd_allreduce_microstep: 1247.97 | step_microstep: 7.79\n",
      "[2024-09-15 16:48:11,182] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3359.69 | bwd: 7231.56 | bwd_inner: 5983.39 | bwd_allreduce: 1248.05 | step: 8.04\n",
      "{'loss': 0.1799, 'learning_rate': 1.8204778562679437e-06, 'epoch': 2.59}\n",
      " 87%|████████▋ | 406/468 [1:13:02<13:29, 13.06s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1901\n",
      "[2024-09-15 16:48:16,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1949.22 | bwd_microstep: 3474.08 | bwd_inner_microstep: 3474.00 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:48:20,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.81 | optimizer_gradients: 0.45 | optimizer_step: 0.40\n",
      "[2024-09-15 16:48:20,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.32 | bwd_microstep: 2597.06 | bwd_inner_microstep: 2581.63 | bwd_allreduce_microstep: 15.38 | step_microstep: 8.30\n",
      "[2024-09-15 16:48:20,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3412.53 | bwd: 6071.18 | bwd_inner: 6055.63 | bwd_allreduce: 15.42 | step: 8.55\n",
      "{'loss': 0.1823, 'learning_rate': 1.7630979527059877e-06, 'epoch': 2.6}\n",
      " 87%|████████▋ | 407/468 [1:13:12<12:12, 12.01s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1880\n",
      "[2024-09-15 16:48:26,041] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1887.36 | bwd_microstep: 3391.14 | bwd_inner_microstep: 3391.01 | bwd_allreduce_microstep: 0.05 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:48:31,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.34 | optimizer_step: 0.40\n",
      "[2024-09-15 16:48:31,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.45 | bwd_microstep: 3445.07 | bwd_inner_microstep: 3429.93 | bwd_allreduce_microstep: 15.09 | step_microstep: 8.01\n",
      "[2024-09-15 16:48:31,434] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3798.78 | bwd: 6836.24 | bwd_inner: 6820.94 | bwd_allreduce: 15.19 | step: 8.26\n",
      "{'loss': 0.1946, 'learning_rate': 1.7065951563241022e-06, 'epoch': 2.61}\n",
      " 87%|████████▋ | 408/468 [1:13:22<11:36, 11.62s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1388\n",
      "[2024-09-15 16:48:35,542] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1475.73 | bwd_microstep: 2601.75 | bwd_inner_microstep: 2601.69 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:48:42,121] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.32 | optimizer_gradients: 0.38 | optimizer_step: 0.41\n",
      "[2024-09-15 16:48:42,122] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.41 | bwd_microstep: 4629.74 | bwd_inner_microstep: 3434.94 | bwd_allreduce_microstep: 1194.73 | step_microstep: 7.61\n",
      "[2024-09-15 16:48:42,122] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3390.12 | bwd: 7231.53 | bwd_inner: 6036.63 | bwd_allreduce: 1194.77 | step: 7.84\n",
      "{'loss': 0.1903, 'learning_rate': 1.6509721846347382e-06, 'epoch': 2.61}\n",
      " 87%|████████▋ | 409/468 [1:13:33<11:08, 11.34s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:48:47,499] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.93 | bwd_microstep: 3431.68 | bwd_inner_microstep: 3431.65 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:48:52,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.47 | optimizer_gradients: 0.35 | optimizer_step: 0.42\n",
      "[2024-09-15 16:48:52,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.53 | bwd_microstep: 3446.66 | bwd_inner_microstep: 3431.56 | bwd_allreduce_microstep: 15.05 | step_microstep: 8.32\n",
      "[2024-09-15 16:48:52,900] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.44 | bwd: 6878.35 | bwd_inner: 6863.22 | bwd_allreduce: 15.07 | step: 8.56\n",
      "{'loss': 0.1675, 'learning_rate': 1.5962317128350147e-06, 'epoch': 2.62}\n",
      " 88%|████████▊ | 410/468 [1:13:44<10:47, 11.17s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1900\n",
      "[2024-09-15 16:48:58,264] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1908.65 | bwd_microstep: 3425.70 | bwd_inner_microstep: 3425.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:49:03,684] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.39 | optimizer_step: 0.37\n",
      "[2024-09-15 16:49:03,685] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.44 | bwd_microstep: 3473.70 | bwd_inner_microstep: 3434.33 | bwd_allreduce_microstep: 39.31 | step_microstep: 8.20\n",
      "[2024-09-15 16:49:03,685] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3823.06 | bwd: 6899.41 | bwd_inner: 6860.00 | bwd_allreduce: 39.34 | step: 8.25\n",
      "{'loss': 0.1545, 'learning_rate': 1.5423763736780583e-06, 'epoch': 2.63}\n",
      " 88%|████████▊ | 411/468 [1:13:55<10:30, 11.05s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:49:09,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.69 | bwd_microstep: 3409.53 | bwd_inner_microstep: 3409.50 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:49:14,417] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.45 | optimizer_step: 0.42\n",
      "[2024-09-15 16:49:14,417] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.92 | bwd_microstep: 3890.89 | bwd_inner_microstep: 2597.80 | bwd_allreduce_microstep: 1293.02 | step_microstep: 8.73\n",
      "[2024-09-15 16:49:14,418] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3367.59 | bwd: 7300.43 | bwd_inner: 6007.30 | bwd_allreduce: 1293.05 | step: 8.79\n",
      "{'loss': 0.1292, 'learning_rate': 1.4894087573463734e-06, 'epoch': 2.63}\n",
      " 88%|████████▊ | 412/468 [1:14:05<10:13, 10.96s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:49:18,582] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1492.58 | bwd_microstep: 2630.79 | bwd_inner_microstep: 2630.76 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:49:25,240] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.66 | optimizer_gradients: 0.38 | optimizer_step: 0.84\n",
      "[2024-09-15 16:49:25,240] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.85 | bwd_microstep: 4705.93 | bwd_inner_microstep: 3438.64 | bwd_allreduce_microstep: 1267.23 | step_microstep: 8.60\n",
      "[2024-09-15 16:49:25,240] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3409.40 | bwd: 7336.73 | bwd_inner: 6069.40 | bwd_allreduce: 1267.26 | step: 8.82\n",
      "{'loss': 0.1341, 'learning_rate': 1.437331411327274e-06, 'epoch': 2.64}\n",
      " 88%|████████▊ | 413/468 [1:14:16<10:00, 10.92s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:49:30,667] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1937.95 | bwd_microstep: 3458.61 | bwd_inner_microstep: 3458.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:49:35,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.41 | optimizer_gradients: 0.36 | optimizer_step: 0.36\n",
      "[2024-09-15 16:49:35,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.91 | bwd_microstep: 3822.49 | bwd_inner_microstep: 2594.24 | bwd_allreduce_microstep: 1228.19 | step_microstep: 7.44\n",
      "[2024-09-15 16:49:35,992] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3406.83 | bwd: 7281.12 | bwd_inner: 6052.83 | bwd_allreduce: 1228.22 | step: 7.53\n",
      "{'loss': 0.1419, 'learning_rate': 1.3861468402903634e-06, 'epoch': 2.65}\n",
      " 88%|████████▊ | 414/468 [1:14:27<09:46, 10.87s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1900\n",
      "[2024-09-15 16:49:41,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1935.92 | bwd_microstep: 3464.79 | bwd_inner_microstep: 3464.77 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:49:46,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.40 | optimizer_step: 0.45\n",
      "[2024-09-15 16:49:46,759] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.76 | bwd_microstep: 3829.91 | bwd_inner_microstep: 2591.20 | bwd_allreduce_microstep: 1238.65 | step_microstep: 7.63\n",
      "[2024-09-15 16:49:46,760] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3406.66 | bwd: 7294.72 | bwd_inner: 6055.97 | bwd_allreduce: 1238.68 | step: 7.87\n",
      "{'loss': 0.2009, 'learning_rate': 1.3358575059670532e-06, 'epoch': 2.65}\n",
      " 89%|████████▊ | 415/468 [1:14:38<09:34, 10.84s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1388\n",
      "[2024-09-15 16:49:50,836] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1459.37 | bwd_microstep: 2587.13 | bwd_inner_microstep: 2586.88 | bwd_allreduce_microstep: 0.15 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:49:57,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:49:57,502] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.77 | bwd_microstep: 5160.56 | bwd_inner_microstep: 2590.45 | bwd_allreduce_microstep: 2570.06 | step_microstep: 7.54\n",
      "[2024-09-15 16:49:57,502] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2929.12 | bwd: 7747.74 | bwd_inner: 5177.33 | bwd_allreduce: 2570.23 | step: 7.79\n",
      "{'loss': 0.1272, 'learning_rate': 1.2864658270321905e-06, 'epoch': 2.66}\n",
      " 89%|████████▉ | 416/468 [1:14:48<09:22, 10.81s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1877\n",
      "[2024-09-15 16:50:02,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1895.45 | bwd_microstep: 3403.39 | bwd_inner_microstep: 3403.36 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:50:08,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:50:08,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.70 | bwd_microstep: 4003.07 | bwd_inner_microstep: 2588.72 | bwd_allreduce_microstep: 1414.30 | step_microstep: 7.97\n",
      "[2024-09-15 16:50:08,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3363.13 | bwd: 7406.47 | bwd_inner: 5992.08 | bwd_allreduce: 1414.33 | step: 8.19\n",
      "{'loss': 0.1821, 'learning_rate': 1.2379741789877175e-06, 'epoch': 2.66}\n",
      " 89%|████████▉ | 417/468 [1:14:59<09:11, 10.82s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:50:12,421] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1463.62 | bwd_microstep: 2586.35 | bwd_inner_microstep: 2586.32 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:50:19,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:50:19,026] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1464.50 | bwd_microstep: 5104.68 | bwd_inner_microstep: 2587.84 | bwd_allreduce_microstep: 2516.77 | step_microstep: 7.24\n",
      "[2024-09-15 16:50:19,026] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2928.10 | bwd: 7691.04 | bwd_inner: 5174.17 | bwd_allreduce: 2516.80 | step: 7.46\n",
      "{'loss': 0.1756, 'learning_rate': 1.1903848940484241e-06, 'epoch': 2.67}\n",
      " 89%|████████▉ | 418/468 [1:15:10<08:58, 10.78s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:50:24,398] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.15 | bwd_microstep: 3431.46 | bwd_inner_microstep: 3431.43 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1367\n",
      "[2024-09-15 16:50:29,828] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:50:29,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1435.89 | bwd_microstep: 3959.05 | bwd_inner_microstep: 2547.99 | bwd_allreduce_microstep: 1411.00 | step_microstep: 7.66\n",
      "[2024-09-15 16:50:29,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3345.02 | bwd: 7390.52 | bwd_inner: 5979.42 | bwd_allreduce: 1411.03 | step: 7.89\n",
      "{'loss': 0.1342, 'learning_rate': 1.1437002610297787e-06, 'epoch': 2.68}\n",
      " 90%|████████▉ | 419/468 [1:15:21<08:48, 10.79s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:50:35,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1909.26 | bwd_microstep: 3428.96 | bwd_inner_microstep: 3428.94 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1368\n",
      "[2024-09-15 16:50:39,301] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.62 | optimizer_gradients: 0.35 | optimizer_step: 0.38\n",
      "[2024-09-15 16:50:39,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1458.61 | bwd_microstep: 2609.67 | bwd_inner_microstep: 2573.57 | bwd_allreduce_microstep: 36.04 | step_microstep: 7.86\n",
      "[2024-09-15 16:50:39,302] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3367.84 | bwd: 6038.64 | bwd_inner: 6002.51 | bwd_allreduce: 36.07 | step: 8.05\n",
      "{'loss': 0.2193, 'learning_rate': 1.097922525237849e-06, 'epoch': 2.68}\n",
      " 90%|████████▉ | 420/468 [1:15:30<08:18, 10.39s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:50:44,677] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.25 | bwd_microstep: 3430.69 | bwd_inner_microstep: 3430.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1870\n",
      "[2024-09-15 16:50:50,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.35 | optimizer_step: 0.38\n",
      "[2024-09-15 16:50:50,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1882.46 | bwd_microstep: 3425.17 | bwd_inner_microstep: 3386.92 | bwd_allreduce_microstep: 38.20 | step_microstep: 8.16\n",
      "[2024-09-15 16:50:50,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3794.69 | bwd: 6855.88 | bwd_inner: 6817.59 | bwd_allreduce: 38.22 | step: 8.40\n",
      "{'loss': 0.1873, 'learning_rate': 1.0530538883613129e-06, 'epoch': 2.69}\n",
      " 90%|████████▉ | 421/468 [1:15:41<08:13, 10.49s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:50:55,389] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.28 | bwd_microstep: 3423.58 | bwd_inner_microstep: 3423.55 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:51:00,760] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.52 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:51:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1900.15 | bwd_microstep: 3434.64 | bwd_inner_microstep: 3419.88 | bwd_allreduce_microstep: 14.71 | step_microstep: 8.34\n",
      "[2024-09-15 16:51:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3813.41 | bwd: 6858.23 | bwd_inner: 6843.44 | bwd_allreduce: 14.73 | step: 8.55\n",
      "{'loss': 0.2289, 'learning_rate': 1.0090965083655657e-06, 'epoch': 2.7}\n",
      " 90%|█████████ | 422/468 [1:15:52<08:05, 10.56s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1388\n",
      "[2024-09-15 16:51:04,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1461.31 | bwd_microstep: 2588.03 | bwd_inner_microstep: 2587.84 | bwd_allreduce_microstep: 0.10 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 16:51:11,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.36 | optimizer_step: 0.37\n",
      "[2024-09-15 16:51:11,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.53 | bwd_microstep: 5166.57 | bwd_inner_microstep: 2555.92 | bwd_allreduce_microstep: 2610.52 | step_microstep: 7.24\n",
      "[2024-09-15 16:51:11,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2901.82 | bwd: 7754.64 | bwd_inner: 5143.80 | bwd_allreduce: 2610.65 | step: 7.47\n",
      "{'loss': 0.1694, 'learning_rate': 9.660524993889386e-07, 'epoch': 2.7}\n",
      " 90%|█████████ | 423/468 [1:16:02<07:57, 10.61s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 16:51:15,592] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1476.37 | bwd_microstep: 2603.62 | bwd_inner_microstep: 2603.59 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.21\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:51:22,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:51:22,215] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.69 | bwd_microstep: 4676.15 | bwd_inner_microstep: 3434.07 | bwd_allreduce_microstep: 1242.02 | step_microstep: 7.14\n",
      "[2024-09-15 16:51:22,215] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3389.03 | bwd: 7279.78 | bwd_inner: 6037.66 | bwd_allreduce: 1242.05 | step: 7.35\n",
      "{'loss': 0.1551, 'learning_rate': 9.239239316410109e-07, 'epoch': 2.71}\n",
      " 91%|█████████ | 424/468 [1:16:13<07:48, 10.65s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:51:26,259] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1449.72 | bwd_microstep: 2564.19 | bwd_inner_microstep: 2564.16 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:51:31,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.40 | optimizer_step: 0.40\n",
      "[2024-09-15 16:51:31,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1454.29 | bwd_microstep: 3968.27 | bwd_inner_microstep: 2568.99 | bwd_allreduce_microstep: 1399.22 | step_microstep: 7.50\n",
      "[2024-09-15 16:51:31,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2903.98 | bwd: 6532.47 | bwd_inner: 5133.16 | bwd_allreduce: 1399.25 | step: 7.72\n",
      "{'loss': 0.2198, 'learning_rate': 8.827128313030453e-07, 'epoch': 2.72}\n",
      " 91%|█████████ | 425/468 [1:16:23<07:23, 10.30s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:51:35,865] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.97 | bwd_microstep: 2627.42 | bwd_inner_microstep: 2627.28 | bwd_allreduce_microstep: 0.06 | step_microstep: 0.25\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:51:42,552] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.39 | optimizer_step: 0.40\n",
      "[2024-09-15 16:51:42,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.22 | bwd_microstep: 4733.20 | bwd_inner_microstep: 3431.86 | bwd_allreduce_microstep: 1301.27 | step_microstep: 7.48\n",
      "[2024-09-15 16:51:42,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3408.17 | bwd: 7360.66 | bwd_inner: 6059.14 | bwd_allreduce: 1301.39 | step: 7.74\n",
      "{'loss': 0.1434, 'learning_rate': 8.42421180430546e-07, 'epoch': 2.72}\n",
      " 91%|█████████ | 426/468 [1:16:33<07:19, 10.46s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:51:47,915] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1907.38 | bwd_microstep: 3423.59 | bwd_inner_microstep: 3423.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1373\n",
      "[2024-09-15 16:51:53,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.27 | optimizer_gradients: 0.43 | optimizer_step: 0.39\n",
      "[2024-09-15 16:51:53,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.74 | bwd_microstep: 3852.14 | bwd_inner_microstep: 2593.45 | bwd_allreduce_microstep: 1258.64 | step_microstep: 7.43\n",
      "[2024-09-15 16:51:53,274] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.10 | bwd: 7275.75 | bwd_inner: 6017.01 | bwd_allreduce: 1258.67 | step: 7.68\n",
      "{'loss': 0.2212, 'learning_rate': 8.03050916857917e-07, 'epoch': 2.73}\n",
      " 91%|█████████ | 427/468 [1:16:44<07:12, 10.54s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1876\n",
      "[2024-09-15 16:51:58,628] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1904.72 | bwd_microstep: 3419.12 | bwd_inner_microstep: 3419.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:52:02,737] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.63 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:52:02,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.93 | bwd_microstep: 2607.11 | bwd_inner_microstep: 2590.27 | bwd_allreduce_microstep: 16.80 | step_microstep: 7.76\n",
      "[2024-09-15 16:52:02,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3372.63 | bwd: 6026.24 | bwd_inner: 6009.36 | bwd_allreduce: 16.82 | step: 7.99\n",
      "{'loss': 0.214, 'learning_rate': 7.646039341052747e-07, 'epoch': 2.73}\n",
      " 91%|█████████▏| 428/468 [1:16:54<06:48, 10.22s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:52:08,106] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.89 | bwd_microstep: 3424.20 | bwd_inner_microstep: 3424.18 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:52:13,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.36 | optimizer_gradients: 0.33 | optimizer_step: 0.39\n",
      "[2024-09-15 16:52:13,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.35 | bwd_microstep: 3456.82 | bwd_inner_microstep: 3442.16 | bwd_allreduce_microstep: 14.62 | step_microstep: 7.97\n",
      "[2024-09-15 16:52:13,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3831.21 | bwd: 6881.04 | bwd_inner: 6866.33 | bwd_allreduce: 14.64 | step: 8.07\n",
      "{'loss': 0.1959, 'learning_rate': 7.270820812873714e-07, 'epoch': 2.74}\n",
      " 92%|█████████▏| 429/468 [1:17:04<06:45, 10.39s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1366\n",
      "[2024-09-15 16:52:17,574] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1454.77 | bwd_microstep: 2571.14 | bwd_inner_microstep: 2571.11 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:52:24,101] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.28 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:52:24,102] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.16 | bwd_microstep: 4574.58 | bwd_inner_microstep: 3442.44 | bwd_allreduce_microstep: 1132.08 | step_microstep: 7.45\n",
      "[2024-09-15 16:52:24,102] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3371.91 | bwd: 7145.73 | bwd_inner: 6013.56 | bwd_allreduce: 1132.11 | step: 7.69\n",
      "{'loss': 0.1571, 'learning_rate': 6.904871630246646e-07, 'epoch': 2.75}\n",
      " 92%|█████████▏| 430/468 [1:17:15<06:36, 10.45s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:52:29,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1912.88 | bwd_microstep: 3436.11 | bwd_inner_microstep: 3436.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:52:33,599] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.70 | optimizer_gradients: 0.38 | optimizer_step: 0.42\n",
      "[2024-09-15 16:52:33,600] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.09 | bwd_microstep: 2608.36 | bwd_inner_microstep: 2593.14 | bwd_allreduce_microstep: 15.17 | step_microstep: 8.01\n",
      "[2024-09-15 16:52:33,600] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3383.94 | bwd: 6044.48 | bwd_inner: 6029.23 | bwd_allreduce: 15.19 | step: 8.11\n",
      "{'loss': 0.1282, 'learning_rate': 6.548209393565241e-07, 'epoch': 2.75}\n",
      " 92%|█████████▏| 431/468 [1:17:25<06:15, 10.16s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:52:38,953] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1903.24 | bwd_microstep: 3419.45 | bwd_inner_microstep: 3419.40 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:52:44,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.49 | optimizer_gradients: 0.36 | optimizer_step: 0.41\n",
      "[2024-09-15 16:52:44,340] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.12 | bwd_microstep: 3445.32 | bwd_inner_microstep: 3430.35 | bwd_allreduce_microstep: 14.93 | step_microstep: 8.30\n",
      "[2024-09-15 16:52:44,341] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3808.34 | bwd: 6864.81 | bwd_inner: 6849.75 | bwd_allreduce: 14.95 | step: 8.54\n",
      "{'loss': 0.0944, 'learning_rate': 6.200851256565799e-07, 'epoch': 2.76}\n",
      " 92%|█████████▏| 432/468 [1:17:35<06:12, 10.34s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:52:48,437] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.74 | bwd_microstep: 2595.51 | bwd_inner_microstep: 2595.40 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:52:53,723] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.40 | optimizer_step: 0.45\n",
      "[2024-09-15 16:52:53,723] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.08 | bwd_microstep: 3778.52 | bwd_inner_microstep: 2593.46 | bwd_allreduce_microstep: 1185.01 | step_microstep: 7.56\n",
      "[2024-09-15 16:52:53,723] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2942.80 | bwd: 6374.07 | bwd_inner: 5188.86 | bwd_allreduce: 1185.09 | step: 7.81\n",
      "{'loss': 0.1417, 'learning_rate': 5.862813925502209e-07, 'epoch': 2.77}\n",
      " 93%|█████████▎| 433/468 [1:17:45<05:51, 10.05s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:52:59,105] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.13 | bwd_microstep: 3434.25 | bwd_inner_microstep: 3434.23 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.14\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1368\n",
      "[2024-09-15 16:53:04,467] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.42 | optimizer_step: 0.38\n",
      "[2024-09-15 16:53:04,468] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1441.09 | bwd_microstep: 3887.32 | bwd_inner_microstep: 2557.62 | bwd_allreduce_microstep: 1329.64 | step_microstep: 7.54\n",
      "[2024-09-15 16:53:04,468] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3358.19 | bwd: 7321.58 | bwd_inner: 5991.85 | bwd_allreduce: 1329.67 | step: 7.71\n",
      "{'loss': 0.2177, 'learning_rate': 5.53411365834251e-07, 'epoch': 2.77}\n",
      " 93%|█████████▎| 434/468 [1:17:55<05:48, 10.26s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:53:08,617] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.42 | bwd_microstep: 2627.14 | bwd_inner_microstep: 2627.02 | bwd_allreduce_microstep: 0.03 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1881\n",
      "[2024-09-15 16:53:15,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:53:15,094] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1888.53 | bwd_microstep: 4554.88 | bwd_inner_microstep: 3399.28 | bwd_allreduce_microstep: 1155.54 | step_microstep: 7.19\n",
      "[2024-09-15 16:53:15,095] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.92 | bwd: 7182.06 | bwd_inner: 6026.30 | bwd_allreduce: 1155.62 | step: 7.43\n",
      "{'loss': 0.1399, 'learning_rate': 5.214766263986848e-07, 'epoch': 2.78}\n",
      " 93%|█████████▎| 435/468 [1:18:06<05:42, 10.37s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 16:53:20,489] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1920.54 | bwd_microstep: 3443.81 | bwd_inner_microstep: 3443.78 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:53:25,858] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:53:25,859] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1899.96 | bwd_microstep: 3434.30 | bwd_inner_microstep: 3420.47 | bwd_allreduce_microstep: 13.78 | step_microstep: 8.54\n",
      "[2024-09-15 16:53:25,859] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3820.47 | bwd: 6878.11 | bwd_inner: 6864.25 | bwd_allreduce: 13.80 | step: 8.61\n",
      "{'loss': 0.1264, 'learning_rate': 4.904787101507324e-07, 'epoch': 2.79}\n",
      " 93%|█████████▎| 436/468 [1:18:17<05:35, 10.49s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:53:31,243] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.57 | bwd_microstep: 3436.52 | bwd_inner_microstep: 3436.50 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:53:36,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.41\n",
      "[2024-09-15 16:53:36,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.24 | bwd_microstep: 3454.63 | bwd_inner_microstep: 3442.04 | bwd_allreduce_microstep: 12.55 | step_microstep: 8.56\n",
      "[2024-09-15 16:53:36,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3834.78 | bwd: 6891.16 | bwd_inner: 6878.53 | bwd_allreduce: 12.57 | step: 8.61\n",
      "{'loss': 0.1468, 'learning_rate': 4.604191079409126e-07, 'epoch': 2.79}\n",
      " 93%|█████████▎| 437/468 [1:18:28<05:27, 10.58s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1389\n",
      "[2024-09-15 16:53:40,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1478.38 | bwd_microstep: 2611.11 | bwd_inner_microstep: 2611.07 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:53:47,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:53:47,330] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1472.10 | bwd_microstep: 5055.96 | bwd_inner_microstep: 2591.54 | bwd_allreduce_microstep: 2464.36 | step_microstep: 7.15\n",
      "[2024-09-15 16:53:47,331] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2950.45 | bwd: 7667.12 | bwd_inner: 5202.61 | bwd_allreduce: 2464.39 | step: 7.37\n",
      "{'loss': 0.1082, 'learning_rate': 4.3129926549136057e-07, 'epoch': 2.8}\n",
      " 94%|█████████▎| 438/468 [1:18:38<05:18, 10.61s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:53:52,706] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.46 | bwd_microstep: 3430.83 | bwd_inner_microstep: 3430.80 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.19\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1366\n",
      "[2024-09-15 16:53:56,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:53:56,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1467.49 | bwd_microstep: 2606.21 | bwd_inner_microstep: 2591.13 | bwd_allreduce_microstep: 15.04 | step_microstep: 8.31\n",
      "[2024-09-15 16:53:56,816] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3380.92 | bwd: 6037.05 | bwd_inner: 6021.93 | bwd_allreduce: 15.06 | step: 8.53\n",
      "{'loss': 0.1996, 'learning_rate': 4.031205833262863e-07, 'epoch': 2.81}\n",
      " 94%|█████████▍| 439/468 [1:18:48<04:57, 10.27s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1870\n",
      "[2024-09-15 16:54:02,171] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1906.98 | bwd_microstep: 3413.13 | bwd_inner_microstep: 3413.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.24\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:54:07,580] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.59 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:54:07,581] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.16 | bwd_microstep: 3455.85 | bwd_inner_microstep: 3440.91 | bwd_allreduce_microstep: 14.89 | step_microstep: 8.33\n",
      "[2024-09-15 16:54:07,581] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3824.10 | bwd: 6868.99 | bwd_inner: 6854.01 | bwd_allreduce: 14.91 | step: 8.57\n",
      "{'loss': 0.159, 'learning_rate': 3.7588441670462827e-07, 'epoch': 2.81}\n",
      " 94%|█████████▍| 440/468 [1:18:58<04:51, 10.42s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:54:11,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1491.38 | bwd_microstep: 2630.44 | bwd_inner_microstep: 2630.42 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:54:17,078] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.55 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:54:17,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1470.08 | bwd_microstep: 3838.79 | bwd_inner_microstep: 2596.96 | bwd_allreduce_microstep: 1241.77 | step_microstep: 7.63\n",
      "[2024-09-15 16:54:17,079] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2961.42 | bwd: 6469.25 | bwd_inner: 5227.38 | bwd_allreduce: 1241.80 | step: 7.86\n",
      "{'loss': 0.1389, 'learning_rate': 3.4959207555485873e-07, 'epoch': 2.82}\n",
      " 94%|█████████▍| 441/468 [1:19:08<04:33, 10.14s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:54:22,461] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.18 | bwd_microstep: 3437.65 | bwd_inner_microstep: 3437.62 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.20\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1369\n",
      "[2024-09-15 16:54:27,897] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:54:27,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1440.35 | bwd_microstep: 3962.55 | bwd_inner_microstep: 2556.61 | bwd_allreduce_microstep: 1405.88 | step_microstep: 7.88\n",
      "[2024-09-15 16:54:27,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3353.50 | bwd: 7400.21 | bwd_inner: 5994.23 | bwd_allreduce: 1405.91 | step: 8.10\n",
      "{'loss': 0.1808, 'learning_rate': 3.242448244119967e-07, 'epoch': 2.82}\n",
      " 94%|█████████▍| 442/468 [1:19:19<04:28, 10.35s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:54:32,046] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.43 | bwd_microstep: 2627.18 | bwd_inner_microstep: 2627.15 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.07\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1878\n",
      "[2024-09-15 16:54:38,475] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.37 | optimizer_step: 0.40\n",
      "[2024-09-15 16:54:38,475] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1901.09 | bwd_microstep: 4492.62 | bwd_inner_microstep: 3419.48 | bwd_allreduce_microstep: 1073.06 | step_microstep: 7.41\n",
      "[2024-09-15 16:54:38,476] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.49 | bwd: 7119.81 | bwd_inner: 6046.64 | bwd_allreduce: 1073.10 | step: 7.51\n",
      "{'loss': 0.1019, 'learning_rate': 2.99843882356774e-07, 'epoch': 2.83}\n",
      " 95%|█████████▍| 443/468 [1:19:29<04:20, 10.42s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1900\n",
      "[2024-09-15 16:54:43,873] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1919.59 | bwd_microstep: 3447.69 | bwd_inner_microstep: 3447.67 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:54:49,267] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 4.25 | optimizer_gradients: 0.33 | optimizer_step: 0.38\n",
      "[2024-09-15 16:54:49,267] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1914.53 | bwd_microstep: 3439.27 | bwd_inner_microstep: 3424.46 | bwd_allreduce_microstep: 14.76 | step_microstep: 11.66\n",
      "[2024-09-15 16:54:49,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3834.10 | bwd: 6886.97 | bwd_inner: 6872.13 | bwd_allreduce: 14.78 | step: 11.75\n",
      "{'loss': 0.1137, 'learning_rate': 2.7639042295702245e-07, 'epoch': 2.84}\n",
      " 95%|█████████▍| 444/468 [1:19:40<04:12, 10.53s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1901\n",
      "[2024-09-15 16:54:54,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.79 | bwd_microstep: 3439.81 | bwd_inner_microstep: 3439.79 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.13\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:54:59,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:54:59,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.90 | bwd_microstep: 3842.01 | bwd_inner_microstep: 2592.58 | bwd_allreduce_microstep: 1249.37 | step_microstep: 8.30\n",
      "[2024-09-15 16:54:59,998] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3382.66 | bwd: 7281.84 | bwd_inner: 6032.37 | bwd_allreduce: 1249.40 | step: 8.46\n",
      "{'loss': 0.2141, 'learning_rate': 2.5388557421120564e-07, 'epoch': 2.84}\n",
      " 95%|█████████▌| 445/468 [1:19:51<04:03, 10.59s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:55:04,145] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1490.23 | bwd_microstep: 2627.46 | bwd_inner_microstep: 2627.43 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.08\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:55:10,740] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.39 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:55:10,740] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.32 | bwd_microstep: 4642.11 | bwd_inner_microstep: 3439.25 | bwd_allreduce_microstep: 1202.80 | step_microstep: 7.47\n",
      "[2024-09-15 16:55:10,740] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3407.52 | bwd: 7269.58 | bwd_inner: 6066.68 | bwd_allreduce: 1202.83 | step: 7.58\n",
      "{'loss': 0.1763, 'learning_rate': 2.3233041849419547e-07, 'epoch': 2.85}\n",
      " 95%|█████████▌| 446/468 [1:20:02<03:53, 10.64s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1387\n",
      "[2024-09-15 16:55:14,853] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1475.94 | bwd_microstep: 2606.73 | bwd_inner_microstep: 2606.70 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:55:21,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.36 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:55:21,366] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.71 | bwd_microstep: 4560.68 | bwd_inner_microstep: 3439.87 | bwd_allreduce_microstep: 1120.75 | step_microstep: 7.96\n",
      "[2024-09-15 16:55:21,366] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3391.63 | bwd: 7167.42 | bwd_inner: 6046.57 | bwd_allreduce: 1120.78 | step: 8.09\n",
      "{'loss': 0.1588, 'learning_rate': 2.1172599250519398e-07, 'epoch': 2.86}\n",
      " 96%|█████████▌| 447/468 [1:20:12<03:43, 10.63s/it]dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1388\n",
      "[2024-09-15 16:55:25,476] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1474.43 | bwd_microstep: 2605.28 | bwd_inner_microstep: 2605.26 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.15\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:55:30,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.57 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:55:30,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1453.77 | bwd_microstep: 3887.98 | bwd_inner_microstep: 2570.81 | bwd_allreduce_microstep: 1317.11 | step_microstep: 7.66\n",
      "[2024-09-15 16:55:30,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2928.17 | bwd: 6493.28 | bwd_inner: 5176.07 | bwd_allreduce: 1317.14 | step: 7.84\n",
      "{'loss': 0.2067, 'learning_rate': 1.9207328721788653e-07, 'epoch': 2.86}\n",
      " 96%|█████████▌| 448/468 [1:20:22<03:25, 10.29s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1881\n",
      "[2024-09-15 16:55:36,273] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1932.23 | bwd_microstep: 3457.35 | bwd_inner_microstep: 3457.32 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:55:41,675] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.42 | optimizer_step: 0.41\n",
      "[2024-09-15 16:55:41,676] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.27 | bwd_microstep: 3450.88 | bwd_inner_microstep: 3436.11 | bwd_allreduce_microstep: 14.71 | step_microstep: 8.75\n",
      "[2024-09-15 16:55:41,676] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3848.48 | bwd: 6908.23 | bwd_inner: 6893.43 | bwd_allreduce: 14.74 | step: 8.85\n",
      "{'loss': 0.1241, 'learning_rate': 1.7337324783276878e-07, 'epoch': 2.87}\n",
      " 96%|█████████▌| 449/468 [1:20:33<03:18, 10.45s/it]dynamic ViT batch size: 32, images per sample: 4.0, dynamic token length: 1369\n",
      "[2024-09-15 16:55:45,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1407.94 | bwd_microstep: 2516.55 | bwd_inner_microstep: 2516.53 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1877\n",
      "[2024-09-15 16:55:51,169] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.54 | optimizer_gradients: 0.39 | optimizer_step: 0.38\n",
      "[2024-09-15 16:55:51,170] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1910.02 | bwd_microstep: 3591.66 | bwd_inner_microstep: 3426.61 | bwd_allreduce_microstep: 164.99 | step_microstep: 7.67\n",
      "[2024-09-15 16:55:51,170] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3317.92 | bwd: 6108.22 | bwd_inner: 5943.13 | bwd_allreduce: 165.02 | step: 7.79\n",
      "{'loss': 0.1489, 'learning_rate': 1.5562677373169855e-07, 'epoch': 2.88}\n",
      " 96%|█████████▌| 450/468 [1:20:42<03:02, 10.16s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:55:55,322] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1494.36 | bwd_microstep: 2627.59 | bwd_inner_microstep: 2627.56 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1878\n",
      "[2024-09-15 16:56:01,874] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.51 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:56:01,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1936.16 | bwd_microstep: 4580.75 | bwd_inner_microstep: 3466.33 | bwd_allreduce_microstep: 1114.37 | step_microstep: 7.67\n",
      "[2024-09-15 16:56:01,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3430.49 | bwd: 7208.35 | bwd_inner: 6093.89 | bwd_allreduce: 1114.40 | step: 7.90\n",
      "{'loss': 0.136, 'learning_rate': 1.388347184346328e-07, 'epoch': 2.88}\n",
      " 96%|█████████▋| 451/468 [1:20:53<02:55, 10.33s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:56:07,254] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.60 | bwd_microstep: 3432.64 | bwd_inner_microstep: 3432.61 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1367\n",
      "[2024-09-15 16:56:12,635] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.22 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:56:12,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1469.02 | bwd_microstep: 3877.83 | bwd_inner_microstep: 2593.00 | bwd_allreduce_microstep: 1284.77 | step_microstep: 7.21\n",
      "[2024-09-15 16:56:12,636] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3384.59 | bwd: 7310.49 | bwd_inner: 6025.62 | bwd_allreduce: 1284.80 | step: 7.42\n",
      "{'loss': 0.1723, 'learning_rate': 1.2299788955857817e-07, 'epoch': 2.89}\n",
      " 97%|█████████▋| 452/468 [1:21:04<02:47, 10.46s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:56:16,784] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1489.86 | bwd_microstep: 2627.31 | bwd_inner_microstep: 2627.25 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1369\n",
      "[2024-09-15 16:56:22,087] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.38 | optimizer_gradients: 0.42 | optimizer_step: 0.39\n",
      "[2024-09-15 16:56:22,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.85 | bwd_microstep: 3799.95 | bwd_inner_microstep: 2591.84 | bwd_allreduce_microstep: 1208.05 | step_microstep: 7.84\n",
      "[2024-09-15 16:56:22,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2958.69 | bwd: 6427.31 | bwd_inner: 5219.09 | bwd_allreduce: 1208.08 | step: 8.07\n",
      "{'loss': 0.227, 'learning_rate': 1.0811704877875528e-07, 'epoch': 2.89}\n",
      " 97%|█████████▋| 453/468 [1:21:13<02:32, 10.15s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:56:27,462] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.81 | bwd_microstep: 3430.89 | bwd_inner_microstep: 3430.86 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:56:32,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.65 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:56:32,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.60 | bwd_microstep: 3452.58 | bwd_inner_microstep: 3440.22 | bwd_allreduce_microstep: 12.31 | step_microstep: 8.66\n",
      "[2024-09-15 16:56:32,868] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3827.38 | bwd: 6883.48 | bwd_inner: 6871.08 | bwd_allreduce: 12.34 | step: 8.89\n",
      "{'loss': 0.1729, 'learning_rate': 9.419291179195267e-08, 'epoch': 2.9}\n",
      " 97%|█████████▋| 454/468 [1:21:24<02:24, 10.34s/it]dynamic ViT batch size: 37, images per sample: 4.625, dynamic token length: 1366\n",
      "[2024-09-15 16:56:36,907] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1447.58 | bwd_microstep: 2561.77 | bwd_inner_microstep: 2561.74 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:56:43,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:56:43,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1471.30 | bwd_microstep: 5180.67 | bwd_inner_microstep: 2594.48 | bwd_allreduce_microstep: 2586.13 | step_microstep: 8.02\n",
      "[2024-09-15 16:56:43,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2918.86 | bwd: 7742.44 | bwd_inner: 5156.22 | bwd_allreduce: 2586.16 | step: 8.09\n",
      "{'loss': 0.1533, 'learning_rate': 8.122614828211861e-08, 'epoch': 2.91}\n",
      " 97%|█████████▋| 455/468 [1:21:34<02:15, 10.46s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:56:49,006] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1927.42 | bwd_microstep: 3455.13 | bwd_inner_microstep: 3455.10 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.06\n",
      "dynamic ViT batch size: 38, images per sample: 4.75, dynamic token length: 1368\n",
      "[2024-09-15 16:56:54,334] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.50 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:56:54,334] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1454.28 | bwd_microstep: 3838.30 | bwd_inner_microstep: 2572.00 | bwd_allreduce_microstep: 1266.25 | step_microstep: 7.53\n",
      "[2024-09-15 16:56:54,335] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3381.67 | bwd: 7293.44 | bwd_inner: 6027.10 | bwd_allreduce: 1266.28 | step: 7.62\n",
      "{'loss': 0.1285, 'learning_rate': 6.921738188814254e-08, 'epoch': 2.91}\n",
      " 97%|█████████▋| 456/468 [1:21:45<02:06, 10.54s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:56:59,708] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.22 | bwd_microstep: 3431.65 | bwd_inner_microstep: 3431.63 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:57:05,105] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.56 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:57:05,105] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.15 | bwd_microstep: 3448.51 | bwd_inner_microstep: 3433.72 | bwd_allreduce_microstep: 14.72 | step_microstep: 8.31\n",
      "[2024-09-15 16:57:05,106] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3824.35 | bwd: 6880.19 | bwd_inner: 6865.35 | bwd_allreduce: 14.75 | step: 8.43\n",
      "{'loss': 0.2263, 'learning_rate': 5.816719017386785e-08, 'epoch': 2.92}\n",
      " 98%|█████████▊| 457/468 [1:21:56<01:56, 10.61s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1870\n",
      "[2024-09-15 16:57:10,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1896.16 | bwd_microstep: 3403.59 | bwd_inner_microstep: 3403.57 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.10\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:57:15,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.61 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 16:57:15,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1916.36 | bwd_microstep: 3452.04 | bwd_inner_microstep: 3437.22 | bwd_allreduce_microstep: 14.77 | step_microstep: 8.62\n",
      "[2024-09-15 16:57:15,841] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3812.49 | bwd: 6855.65 | bwd_inner: 6840.79 | bwd_allreduce: 14.79 | step: 8.74\n",
      "{'loss': 0.1303, 'learning_rate': 4.807610460030976e-08, 'epoch': 2.93}\n",
      " 98%|█████████▊| 458/468 [1:22:07<01:46, 10.65s/it]dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1366\n",
      "[2024-09-15 16:57:19,861] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1438.47 | bwd_microstep: 2552.65 | bwd_inner_microstep: 2552.63 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:57:25,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.44 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:57:25,394] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.18 | bwd_microstep: 3584.28 | bwd_inner_microstep: 3444.45 | bwd_allreduce_microstep: 139.77 | step_microstep: 7.98\n",
      "[2024-09-15 16:57:25,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3355.62 | bwd: 6136.95 | bwd_inner: 5997.08 | bwd_allreduce: 139.80 | step: 8.03\n",
      "{'loss': 0.1302, 'learning_rate': 3.894461050010012e-08, 'epoch': 2.93}\n",
      " 98%|█████████▊| 459/468 [1:22:16<01:32, 10.32s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:57:29,550] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.47 | bwd_microstep: 2631.11 | bwd_inner_microstep: 2631.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1876\n",
      "[2024-09-15 16:57:36,098] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.40 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:57:36,099] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1933.89 | bwd_microstep: 4583.55 | bwd_inner_microstep: 3461.77 | bwd_allreduce_microstep: 1121.71 | step_microstep: 7.37\n",
      "[2024-09-15 16:57:36,099] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3427.34 | bwd: 7214.68 | bwd_inner: 6092.85 | bwd_allreduce: 1121.75 | step: 7.43\n",
      "{'loss': 0.1507, 'learning_rate': 3.077314705413503e-08, 'epoch': 2.94}\n",
      " 98%|█████████▊| 460/468 [1:22:27<01:23, 10.44s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:57:41,465] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1911.26 | bwd_microstep: 3424.02 | bwd_inner_microstep: 3423.99 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.05\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:57:46,871] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.42 | optimizer_gradients: 0.37 | optimizer_step: 0.40\n",
      "[2024-09-15 16:57:46,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.20 | bwd_microstep: 3455.27 | bwd_inner_microstep: 3440.20 | bwd_allreduce_microstep: 15.03 | step_microstep: 8.41\n",
      "[2024-09-15 16:57:46,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3828.44 | bwd: 6879.30 | bwd_inner: 6864.19 | bwd_allreduce: 15.05 | step: 8.48\n",
      "{'loss': 0.2156, 'learning_rate': 2.356210727046504e-08, 'epoch': 2.95}\n",
      " 99%|█████████▊| 461/468 [1:22:38<01:13, 10.54s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:57:51,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.49 | bwd_microstep: 2629.05 | bwd_inner_microstep: 2629.02 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 36, images per sample: 4.5, dynamic token length: 1367\n",
      "[2024-09-15 16:57:57,484] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.36 | optimizer_gradients: 0.42 | optimizer_step: 0.38\n",
      "[2024-09-15 16:57:57,485] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1439.52 | bwd_microstep: 4983.96 | bwd_inner_microstep: 2557.41 | bwd_allreduce_microstep: 2426.49 | step_microstep: 7.65\n",
      "[2024-09-15 16:57:57,485] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 2932.98 | bwd: 7613.02 | bwd_inner: 5186.43 | bwd_allreduce: 2426.52 | step: 7.88\n",
      "{'loss': 0.2267, 'learning_rate': 1.7311837965379164e-08, 'epoch': 2.95}\n",
      " 99%|█████████▊| 462/468 [1:22:48<01:03, 10.56s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1389\n",
      "[2024-09-15 16:58:01,628] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1488.17 | bwd_microstep: 2624.95 | bwd_inner_microstep: 2624.84 | bwd_allreduce_microstep: 0.02 | step_microstep: 0.23\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1870\n",
      "[2024-09-15 16:58:07,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.34 | optimizer_step: 0.38\n",
      "[2024-09-15 16:58:07,014] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1913.28 | bwd_microstep: 3437.81 | bwd_inner_microstep: 3422.66 | bwd_allreduce_microstep: 15.10 | step_microstep: 7.78\n",
      "[2024-09-15 16:58:07,015] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3401.42 | bwd: 6062.79 | bwd_inner: 6047.50 | bwd_allreduce: 15.17 | step: 8.02\n",
      "{'loss': 0.2884, 'learning_rate': 1.202263974674045e-08, 'epoch': 2.96}\n",
      " 99%|█████████▉| 463/468 [1:22:58<00:51, 10.25s/it]dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:58:12,398] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.49 | bwd_microstep: 3437.11 | bwd_inner_microstep: 3437.09 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.12\n",
      "dynamic ViT batch size: 46, images per sample: 5.75, dynamic token length: 1878\n",
      "[2024-09-15 16:58:17,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.48 | optimizer_gradients: 0.34 | optimizer_step: 0.39\n",
      "[2024-09-15 16:58:17,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1949.19 | bwd_microstep: 3498.57 | bwd_inner_microstep: 3483.62 | bwd_allreduce_microstep: 14.90 | step_microstep: 7.61\n",
      "[2024-09-15 16:58:17,882] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3864.66 | bwd: 6935.70 | bwd_inner: 6920.71 | bwd_allreduce: 14.92 | step: 7.77\n",
      "{'loss': 0.163, 'learning_rate': 7.694766999513104e-09, 'epoch': 2.96}\n",
      " 99%|█████████▉| 464/468 [1:23:09<00:41, 10.44s/it]dynamic ViT batch size: 39, images per sample: 4.875, dynamic token length: 1369\n",
      "[2024-09-15 16:58:21,958] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1462.31 | bwd_microstep: 2582.87 | bwd_inner_microstep: 2582.84 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.04\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1878\n",
      "[2024-09-15 16:58:28,702] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.21 | optimizer_gradients: 0.37 | optimizer_step: 0.38\n",
      "[2024-09-15 16:58:28,702] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1917.02 | bwd_microstep: 4795.97 | bwd_inner_microstep: 3445.55 | bwd_allreduce_microstep: 1350.35 | step_microstep: 7.20\n",
      "[2024-09-15 16:58:28,702] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3379.30 | bwd: 7378.85 | bwd_inner: 6028.39 | bwd_allreduce: 1350.39 | step: 7.25\n",
      "{'loss': 0.1972, 'learning_rate': 4.328427873541152e-09, 'epoch': 2.97}\n",
      " 99%|█████████▉| 465/468 [1:23:20<00:31, 10.55s/it]dynamic ViT batch size: 41, images per sample: 5.125, dynamic token length: 1878\n",
      "[2024-09-15 16:58:34,068] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1905.90 | bwd_microstep: 3428.86 | bwd_inner_microstep: 3428.83 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.31\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1876\n",
      "[2024-09-15 16:58:39,477] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.53 | optimizer_gradients: 0.35 | optimizer_step: 0.39\n",
      "[2024-09-15 16:58:39,478] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1915.20 | bwd_microstep: 3458.78 | bwd_inner_microstep: 3443.79 | bwd_allreduce_microstep: 14.94 | step_microstep: 8.57\n",
      "[2024-09-15 16:58:39,478] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3821.08 | bwd: 6887.65 | bwd_inner: 6872.62 | bwd_allreduce: 14.96 | step: 8.89\n",
      "{'loss': 0.1847, 'learning_rate': 1.9237842735275737e-09, 'epoch': 2.98}\n",
      "100%|█████████▉| 466/468 [1:23:30<00:21, 10.62s/it]dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1388\n",
      "[2024-09-15 16:58:43,634] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1493.78 | bwd_microstep: 2632.13 | bwd_inner_microstep: 2632.11 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.22\n",
      "dynamic ViT batch size: 42, images per sample: 5.25, dynamic token length: 1877\n",
      "[2024-09-15 16:58:50,308] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.43 | optimizer_gradients: 0.38 | optimizer_step: 0.39\n",
      "[2024-09-15 16:58:50,308] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1918.65 | bwd_microstep: 4719.08 | bwd_inner_microstep: 3445.05 | bwd_allreduce_microstep: 1273.97 | step_microstep: 8.04\n",
      "[2024-09-15 16:58:50,308] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3412.41 | bwd: 7351.23 | bwd_inner: 6077.15 | bwd_allreduce: 1274.01 | step: 8.27\n",
      "{'loss': 0.2029, 'learning_rate': 4.809518512494116e-10, 'epoch': 2.98}\n",
      "100%|█████████▉| 467/468 [1:23:41<00:10, 10.68s/it]dynamic ViT batch size: 44, images per sample: 5.5, dynamic token length: 1877\n",
      "[2024-09-15 16:58:55,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1931.11 | bwd_microstep: 3462.44 | bwd_inner_microstep: 3462.41 | bwd_allreduce_microstep: 0.01 | step_microstep: 0.18\n",
      "dynamic ViT batch size: 40, images per sample: 5.0, dynamic token length: 1368\n",
      "[2024-09-15 16:59:00,936] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 3.34 | optimizer_gradients: 0.38 | optimizer_step: 0.38\n",
      "[2024-09-15 16:59:00,936] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1468.85 | bwd_microstep: 3700.56 | bwd_inner_microstep: 2593.14 | bwd_allreduce_microstep: 1107.36 | step_microstep: 7.98\n",
      "[2024-09-15 16:59:00,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3399.93 | bwd: 7163.01 | bwd_inner: 6055.55 | bwd_allreduce: 1107.39 | step: 8.19\n",
      "{'loss': 0.1615, 'learning_rate': 0.0, 'epoch': 2.99}\n",
      "100%|██████████| 468/468 [1:23:52<00:00, 10.67s/it]petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "petrel_client is not installed. If you read data locally instead of from ceph, ignore it.\n",
      "Replace train sampler!!\n",
      "petrel_client is not installed. Using PIL to load images.\n",
      "[INFO|trainer.py:1962] 2024-09-15 16:59:01,963 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 5033.3609, 'train_samples_per_second': 5.958, 'train_steps_per_second': 0.093, 'train_loss': 0.3061195729762061, 'epoch': 2.99}\n",
      "100%|██████████| 468/468 [1:23:53<00:00, 10.76s/it]\n",
      "[INFO|trainer.py:2936] 2024-09-15 16:59:09,984 >> Saving model checkpoint to work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora\n",
      "[INFO|configuration_utils.py:473] 2024-09-15 16:59:09,985 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/config.json\n",
      "[INFO|configuration_utils.py:594] 2024-09-15 16:59:09,986 >> Configuration saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/generation_config.json\n",
      "[INFO|modeling_utils.py:2501] 2024-09-15 16:59:25,737 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2433] 2024-09-15 16:59:25,738 >> tokenizer config file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2442] 2024-09-15 16:59:25,738 >> Special tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2493] 2024-09-15 16:59:25,739 >> added tokens file saved in work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora/added_tokens.json\n",
      "***** train metrics *****\n",
      "  epoch                    =       2.99\n",
      "  train_loss               =     0.3061\n",
      "  train_runtime            = 1:23:53.36\n",
      "  train_samples            =       9996\n",
      "  train_samples_per_second =      5.958\n",
      "  train_steps_per_second   =      0.093\n"
     ]
    }
   ],
   "source": [
    "! GPUS=4 PER_DEVICE_BATCH_SIZE=8 sh /workspace/InternVL/internvl_chat/shell/internvl2.0/2nd_finetune/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fee40b-6a5d-4f4c-824a-4139ca2304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /workspace/InternVL/internvl_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c1323-2eda-4308-bd90-d9f80806f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bccee-7389-4d94-8440-e36b6efbaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !GPUS=1 sh /workspace/Int\n",
    "# ernVL/internvl_chat/evaluate.sh work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora /workspace/work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora amazon-product-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cbdca9-d50e-4710-9336-30561b731fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "trainable params: 37,748,736 || all params: 7,775,531,008 || trainable%: 0.4855\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:08<00:00,  2.18s/it]\n",
      "Loading tokenizer...\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Saving model...\n",
      "Saving tokenizer...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python /workspace/InternVL/internvl_chat/tools/merge_lora.py   /workspace/work_dirs/internvl_chat_v2_0/internvl2_8b_internlm2_7b_dynamic_res_2nd_finetune_lora  /workspace/work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora_amazon_merge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08bca1d-c7e3-408f-8716-c91d92c3bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /workspace/pretrained/InternVL2-8B/*.py /workspace/work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora_amazon_merge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f870c1fb-f37c-4b01-9ca5-93cc53377932",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /workspace/pretrained/InternVL2-8B/config.json /workspace/work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora_amazon_merge/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad6da3-e8da-4cfb-9ccc-d54e3b550698",
   "metadata": {},
   "source": [
    "# Infernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd502c1-14c9-4707-809a-4206ba15479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc16d6b-c301-4ec9-aded-4dda8a2df29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m794.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: flash_attn in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
      "Requirement already satisfied: decord in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, safetensors, regex, tokenizers, accelerate, transformers, timm\n",
      "Successfully installed accelerate-0.34.2 regex-2024.9.11 safetensors-0.4.5 sentencepiece-0.2.0 timm-1.0.9 tokenizers-0.19.1 transformers-4.44.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate timm einops flash_attn decord sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0888c086-7253-48d2-b61a-f0534d3b439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "402f73e0-9843-44a4-a149-7701bc62f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d7c36c-354a-4308-b016-b66755598a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29792aa49e44430595174c7ac7b1d715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: <image>\n",
      "item height in gram, ton, microgram, kilogram, pound, ounce, milligram\n",
      "Assistant: 1400.0 milligram\n"
     ]
    }
   ],
   "source": [
    "# If you have an 80G A100 GPU, you can put the entire model on a single GPU.\n",
    "# Otherwise, you need to load a model using multiple GPUs, please refer to the `Multiple GPUs` section.\n",
    "path = '/workspace/work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora_amazon_merge'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=False)\n",
    "\n",
    "\n",
    "# batch inference, single image per sample (单图批处理)\n",
    "pixel_values = load_image('/workspace/dataset/train/617Tl40LOXL.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "# pixel_values2 = load_image('./examples/image2.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "# num_patches_list = [pixel_values1.size(0), pixel_values2.size(0)]\n",
    "num_patches_list = [pixel_values.size(0)]\n",
    "\n",
    "\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Extract the allowed units for 'item_weight'\n",
    "item_weight_units = ', '.join(entity_unit_map['item_weight'])\n",
    "\n",
    "# Modify the question string by replacing the placeholder with the actual units\n",
    "questions = [f'<image>\\nitem height in {item_weight_units}']\n",
    "\n",
    "responses = model.batch_chat(tokenizer, pixel_values,\n",
    "                             num_patches_list=num_patches_list,\n",
    "                             questions=questions,\n",
    "                             generation_config=generation_config)\n",
    "for question, response in zip(questions, responses):\n",
    "    print(f'User: {question}\\nAssistant: {response}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993d8354-1f0f-4336-bfb7-2bfdd39d3e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7d3b9e35e24c7297238509166c7ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predicted: 13.0 gram\n",
      "  Ground Truth: 13.0 gram\n",
      "  Predicted: 1000.0 milligram\n",
      "  Ground Truth: 1000.0 milligram\n",
      "  Predicted: 264.0 gram\n",
      "  Ground Truth: 264.0 gram\n",
      "Mismatch for 81nyHjPXg-L.jpg:\n",
      "  Predicted: 26.0 kilogram\n",
      "  Ground Truth: 34.0 kilogram\n",
      "  Predicted: 72.57 gram\n",
      "  Ground Truth: 72.57 gram\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Function to load the train.jsonl file and extract image paths, questions, and ground truths\n",
    "def load_data_from_jsonl(jsonl_file):\n",
    "    ground_truths = {}\n",
    "    image_files = []\n",
    "    questions_list = []\n",
    "    \n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            image_path = data['image']  # Extract the image file path\n",
    "            image_files.append(image_path)  # Add image file path to the list\n",
    "            \n",
    "            conversation = data['conversations']\n",
    "            for item in conversation:\n",
    "                if item['from'] == 'gpt':  # Extract the ground truth from gpt's response\n",
    "                    image_name = image_path.split('/')[-1]  # Get the image file name\n",
    "                    ground_truths[image_name] = item['value']\n",
    "                elif item['from'] == 'human':  # Extract the question from the human input\n",
    "                    # Extract the allowed units for 'item_weight'\n",
    "                    key = item['value'].split('\\n')[1]  # This will give 'item_weight'\n",
    "\n",
    "                    # Now use this key to get the corresponding units from entity_unit_map\n",
    "                    item_weight_units = ', '.join(entity_unit_map[key])                    \n",
    "                    \n",
    "                    # Modify the question string by replacing the placeholder with the actual units\n",
    "                    question = f' in one of the following ({item_weight_units}) unit'\n",
    "                    questions_list.append('What is ' + item['value'] + ' of the item' + question)\n",
    "    \n",
    "    return image_files, questions_list, ground_truths\n",
    "\n",
    "# Function to load and preprocess the image (based on your earlier code)\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "def convert_and_append_unit(text):\n",
    "    # Search for a number (with optional decimal) in the text\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', text)\n",
    "    \n",
    "    if match:\n",
    "        # Convert the matched number to float\n",
    "        number = float(match.group())\n",
    "        # Extract the unit (which is the last part of the string)\n",
    "        unit = text.split()[-1]\n",
    "        # Return the formatted result\n",
    "        return f\"{number} {unit}\"\n",
    "    else:\n",
    "        # If no number is found, return just the unit\n",
    "        unit = text.split()[-1] if len(text.split()) > 0 else None\n",
    "        return unit\n",
    "\n",
    "# Function to compare predictions with ground truth and calculate accuracy\n",
    "def compare_predictions_with_ground_truth(predictions, ground_truths):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    \n",
    "    for image_name, predicted_weight in predictions.items():\n",
    "        ground_truth_weight = ground_truths.get(image_name, None)\n",
    "        if ground_truth_weight is not None:\n",
    "            if predicted_weight.strip().lower() == ground_truth_weight.strip().lower():\n",
    "                correct += 1\n",
    "                print(f'  Predicted: {predicted_weight}')\n",
    "                print(f'  Ground Truth: {ground_truth_weight}')                \n",
    "            else:\n",
    "                print(f'Mismatch for {image_name}:')\n",
    "                print(f'  Predicted: {predicted_weight}')\n",
    "                print(f'  Ground Truth: {ground_truth_weight}')\n",
    "        else:\n",
    "            print(f'No ground truth available for {image_name}')\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Assuming model and tokenizer have been defined and loaded\n",
    "def run_inference(model, tokenizer, image_files, questions):\n",
    "    predictions = {}\n",
    "    \n",
    "    for image_file, question in zip(image_files, questions):\n",
    "        # print(question)\n",
    "        pixel_values = load_image(image_file, max_num=12).to(torch.bfloat16).cuda()\n",
    "        responses = model.batch_chat(tokenizer, pixel_values, num_patches_list=[pixel_values.size(0)], generation_config=generation_config, questions=[question])\n",
    "        \n",
    "        # Extract prediction and associate it with the image\n",
    "        predicted_weight = responses[0]  # Assuming a single response per image\n",
    "        image_name = image_file.split('/')[-1]  # Extracting image file name\n",
    "        # convert_and_append_unit = lambda text: f\"{float(re.search(r'\\d+(\\.\\d+)?', text).group())} {text.split()[-1]}\" if re.search(r'\\d+(\\.\\d+)?', text) else None\n",
    "        \n",
    "        predictions[image_name] = convert_and_append_unit(predicted_weight)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# # Function to compare predictions with ground truth and calculate accuracy\n",
    "# def compare_predictions_with_ground_truth(predictions, ground_truths):\n",
    "#     correct = 0\n",
    "#     total = len(predictions)\n",
    "    \n",
    "#     for prediction in predictions:\n",
    "#         image_name = prediction['image_name']\n",
    "#         predicted_weight = prediction['predicted_weight']\n",
    "        \n",
    "#         # Retrieve ground truth for the image\n",
    "#         ground_truth_weight = ground_truths.get(image_name, None)\n",
    "        \n",
    "#         if ground_truth_weight is not None:\n",
    "#             if predicted_weight.strip().lower() == ground_truth_weight.strip().lower():\n",
    "#                 correct += 1\n",
    "#                 print(f'  Predicted: {predicted_weight}')\n",
    "#                 print(f'  Ground Truth: {ground_truth_weight}')\n",
    "#             else:\n",
    "#                 print(f'Mismatch for {image_name}:')\n",
    "#                 print(f'  Predicted: {predicted_weight}')\n",
    "#                 print(f'  Ground Truth: {ground_truth_weight}')\n",
    "#         else:\n",
    "#             print(f'No ground truth available for {image_name}')\n",
    "    \n",
    "#     accuracy = correct / total if total > 0 else 0\n",
    "#     print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Function to run inference on the model and store results in a list\n",
    "# def run_inference(model, tokenizer, image_files, questions):\n",
    "#     predictions = []\n",
    "    \n",
    "#     for image_file, question in zip(image_files, questions):\n",
    "#         # print(question)\n",
    "#         pixel_values = load_image(image_file, max_num=12).to(torch.bfloat16).cuda()\n",
    "#         responses = model.batch_chat(tokenizer, pixel_values, num_patches_list=[pixel_values.size(0)], generation_config=generation_config, questions=[question])\n",
    "        \n",
    "#         # Extract prediction and associate it with the image\n",
    "#         predicted_weight = responses[0]  # Assuming a single response per image\n",
    "#         image_name = image_file.split('/')[-1]  # Extracting image file name\n",
    "        \n",
    "#         # Append the result as a dictionary to the predictions list\n",
    "#         predictions.append({\n",
    "#             'image_name': image_name,\n",
    "#             'predicted_weight': predicted_weight\n",
    "#         })\n",
    "    \n",
    "#     return predictions\n",
    "\n",
    "# Load image paths, questions, and ground truths from the provided JSONL file\n",
    "image_files, questions_list, ground_truths = load_data_from_jsonl('/workspace/dataset/.jsonl')\n",
    "\n",
    "# Load model and tokenizer (from earlier)\n",
    "path = '/workspace/work_dirs/internvl_chat_v2_0/internvl2_2b_internlm2_1_8b_dynamic_res_2nd_finetune_lora_amazon_merge'\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "\n",
    "# Run inference to get predictions\n",
    "predictions = run_inference(model, tokenizer, image_files, questions_list)\n",
    "\n",
    "# Compare predictions with ground truth and calculate accuracy\n",
    "compare_predictions_with_ground_truth(predictions, ground_truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e906270-9959-4ee7-9b6f-21f01a36553f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
